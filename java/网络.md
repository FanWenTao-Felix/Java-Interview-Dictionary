# 网络

### 1.OSI七层网络模型

网络的七层架构从下到上主要包括物理层、数据链路层、网络层、传输层、会话层、表示层和应用层。

- 物理层主要定义物理设备标准，它的主要作用是传输比特流，具体做法是在发送端将1、0转化为电流强弱来进行传输，在到达目的地后再将电流强弱转化为 1、0，也就是我们常说的模数转换与数模转换，这一层的数据叫作比特。
- 数据链路层主要用于对数据包中的MAC 地址进行解析和封装。这一层的数据叫作帧。在这一层工作的设备是网卡、网桥、交换机。
- 网络层主要用于对数据包中的IP 地址进行封装和解析，这一层的数据叫作数据包。在这一层工作的设备有路由器、交换机、防火墙等。
- 传输层定义了传输数据的协议和端口号，主要用于数据的分段、传输和重组。在这一层工作的协议有TCP和UDP 等。TCP 是传输控制协议，传输效率低，可靠性强，用于传输对可靠性要求高、数据量大的数据，比如支付宝转账使用的就是TCP；UDP 是用户数据报协议，与TCP 的特性恰恰相反，用于传输可靠性要求不高、数据量小的数据，例如抖音等视频服务就使用了UDP。
- 会话层在传输层的基础上建立连接和管理会话，具体包括登录验证、断点续传、数据粘包与分包等。在设备之间需要互相识别的可以是IP，也可以是MAC 或者主机名。
- 表示层主要对接收的数据进行解释、加密、解密、压缩、解压缩等，即把计算机能够识别的内容转换成人能够识别的内容（图片、声音、文字等）。
- 应用层基于网络构建具体应用，例如FTP文件上传下载服务、Telnet服务、HTTP服务、DNS服务、SNMP邮件服务等。

### 2.TCP/IP四层网络模型

TCP/IP不是指TCP和IP这两个协议的合称，而是指因特网的整个TCP/IP协议簇。从协议分层模型方面来讲，TCP/IP由 4个层次组成：网络接口层、网络层、传输层和应用层。 TCP/IP中网络接口层、网络层、传输层和应用层的具体工作职责如下。

- 网络接口层（Network Access Layer）：定义了主机间网络连通的协议，具体包括Echernet、FDDI、ATM等通信协议。
- 网络层（Internet Layer）：主要用于数据的传输、路由及地址的解析，以保障主机可以把数据发送给任何网络上的目标。数据经过网络传输，发送的顺序和到达的顺序可能发生变化。在网络层使用IP（Internet Protocol）和地址解析协议（ARP）。
- 传输层（Transport Layer）：使源端和目的端机器上的对等实体可以基于会话相互通信。在这一层定义了两个端到端的协议TCP和UDP。TCP 是面向连接的协议，提供可靠的报文传输和对上层应用的连接服务，除了基本的数据传输，它还有可靠性保证、流量控制、多路复用、优先权和安全性控制等功能。UDP 是面向无连接的不可靠传输的协议，主要用于不需要TCP 的排序和流量控制等功能的应用程序。
- 应用层（Application Layer）：负责具体应用层协议的定义，包括Telnet（TELecommunications NETwork，虚拟终端协议）、FTP （ File Transfer Protocol ， 文件传输协议） 、SMTP （ SimpleMail Transfer Protocol，电子邮件传输协议）、DNS（Domain Name Service，域名服务）、NNTP（Net News Transfer Protocol，网上新闻传输协议）和HTTP（HyperText Transfer Protocol，超文本传输协议）等。

### 3.TCP的数据包结构

对TCP包的数据结构介绍如下。

- 源端口号（16位）：标识源主机的一个应用进程（连同源主机的IP地址）。
- 目的端口号（16 位）：标识目的主机的一个应用进程（连同目的主机的IP 地址）。IP 报头中的源主机IP 地址、目的主机的IP地址和源端口、目的端口确定了唯一一条TCP连接。
- 顺序号seq（32 位）：标识从TCP 源端向TCP目的端发送的数据字节流，表示这个报文段中的第1 个数据字节的顺序号。如果将字节流看作在两个应用程序间的单向流动，则TCP 用顺序号对每个字节进行计数。序号是 32bit的无符号数，序号达到 232-1 后又从 0 开始。在建立一个新的连接时，SYN 标志变为 1，顺序号字段包含由这个主机选择的该连接的初始顺序号ISN （ Initial Sequence Number）。
- 确认号ack（32 位）：存储发送确认的一端所期望收到的下一个顺序号。确认序号是上次已成功收到的数据字节顺序号加 1。只有ACK 标志为 1 时确认序号字段才有效。TCP 为应用层提供全双工服务，这意味着数据能在两个方向上独立进行传输。因此，连接的每一端都必须保持每个方向上的传输数据顺序号。
- TCP 报头长度（4 位）：存储报头中头部数据的长度，实际上指明了数据从哪里开始。需要这个值是因为任选字段的长度是可变的，该字段占 4bit，因此TCP最多有60字节的首部，但没有任选字段，正常的长度是20字节。
- 保留位（6位）：数据保留位，目前必须被设置为0。
- 控制位（control flags：6 位）：在TCP 报头中有 6 个标志比特，它们中的多个可被同时设置为1，
  - URG：为1时表示紧急指针有效，为0时忽略紧急指针的值
  - ACK：为1时表示确认号有效，为0时表示在报文中不包含确认信息，忽略确认号字段
  - PSH：为1时表示是带有PUSH标志的数据，指示接收方应该尽快将这个报文段交给应用层，而不用等待缓冲区装满
  - RST：用于复位由于主机崩溃或其他原因而出现错误的连接，还可以用于拒绝非法的报文段和拒绝连接请求。在一般情况下，如果收到一个RST为1的报文，那么一定发生了某些问题
  - SYN：同步序号，为1时表示连接请求，用于建立连接和使顺序号同步（Synchronize）
  - FIN：用于释放连接，为1时表示发送方已经没有数据要发送了，即关闭本方数据流。
- 窗口大小（16 位）：数据字节数，表示从确认号开始，本报文的源方可以接收的字节数，即源方接收窗口的大小。窗口大小是16bit的字段，因而窗口最大为65535字节。
- 校验和（16 位）：此校验和是对整个的TCP 报文段，包括TCP头部和TCP 数据，以 16 位字符计算所得的。这是一个强制性的字段，一定是由发送端计算和存储的，并由接收端验证。
- 紧急指针（16 位）：只有在URG 标志置为 1 时紧急指针才有效，这时告诉TCP该条数据需要紧急发送。
- 选项： 最常见的可选字段是最长报文大小， 又叫作MSS（Maximum Segment Size）。每个连接方通常都在通信的第1 个报文段（为建立连接而设置SYN 标志的那个段）中指明这个选项，指明该TCP连接能接收的最大长度的报文段。选项长度不一定是32字节的整数倍，所以要加填充位，使得报头长度成为整字节数。
- 数据：TCP 报文段中的数据部分是可选的。在一个连接建立和一个连接终止时，双方交换的报文段仅有TCP 首部。如果一方没有数据要发送，则也使用没有任何数据的首部确认收到的数据。在处理超时的许多情况下也会发送不带任何数据的报文段。

### 4.TCP中的三次握手

TCP是因特网的传输层协议，使用三次握手协议建立连接。在客户端主动发出SYN连接请求后，等待对方回答SYN+ACK，并最终对对方的SYN执行ACK确认。这种建立连接的方式可以防止产生错误的连接，TCP使用的流量控制协议是可变大小的滑动窗口协议。 TCP三次握手的过程如下。 （1）客户端发送SYN（seq=x）报文给服务器端，进入SYN_SEND状态。 （2）服务器端收到SYN 报文， 回应一个SYN （ seq =y ） 和ACK（ack=x+1）报文，进入SYN_RECV状态。 （3）客户端收到服务器端的SYN报文，回应一个ACK（ack=y+1）报文，进入Established状态。 在三次握手完成后，TCP客户端和服务器端成功建立连接，可以开始传输数据了。

### 5.TCP中的四次挥手

TCP在建立连接时要进行三次握手，在断开连接时要进行四次挥手，这是由于TCP的半关闭造成的。因为TCP连接是全双工的（即数据可在两个方向上同时传递），所以在进行关闭时对每个方向都要单独进行关闭，这种单方向的关闭叫作半关闭。在一方完成它的数据发送任务时，就发送一个FIN来向另一方通告将要终止这个方向的连接。TCP断开连接既可以是由客户端发起的，也可以是由服务器端发起的；如果由客户端发起断开连接操作，则称客户端主动断开连接；如 果由服务器端发起断开连接操作，则称服务端主动断开连接。 TCP四次挥手的过程如下。 （1）客户端应用进程调用断开连接的请求，向服务器端发送一个终止标志位FIN=1,seq=u的消息，表示在客户端关闭链路前要发送的数据已经安全发送完毕，可以开始关闭链路操作，并请求服务器端确认关闭客户端到服务器的链路操作。此时客户端处于FIN-WAIT-1状态。 （2）服务器在收到这个FIN消息后返回一个ACK=1,ack=u+1,seq=v的消息给客户端，表示接收到客户端断开链路的操作请求，这时TCP服务器端进程通知高层应用进程释放客户端到服务器端的链路，服务器处于CLOSE-WAIT状态，即半关闭状态。客户端在收到消息后处于FINWAIT-2状态。 （3）服务器端将关闭链路前需要发送给客户端的消息发送给客户端， 在等待该数据发送完成后， 发送一个终止标志位FIN=1,ACK=1,seq=w,ack=u+1的消息给客户端，表示关闭链路前服务器需要向客户端发送的消息已经发送完毕，请求客户端确认关闭从服务器到客户端的链路操作，此时服务器端处于LAST-ACK状态，等待客户端最终断开链路。 （ 4 ） 客户端在接收到这个最终FIN 消息后， 发送一个ACK=1,seq=u+1,ack=w+1的消息给服务器端，表示接收到服务器端的断开连接请求并准备断开服务器端到客户端的链路。此时客户端处于TIM-WAIT状态，TCP连接还没有释放，然后经过等待计时器（2MSL）设置的时间后，客户端将进入CLOSE状态。

## HTTP

### 1.HTTP的原理

HTTP是一个无状态的协议，无状态指在客户端（Web浏览器）和服务器之间不需要建立持久的连接，在一个客户端向服务器端发出请求且服务器收到该请求并返回响应（response）后，本次通信结束，HTTP连接将被关闭，服务器不保留连接的相关信息。 HTTP遵循请求（Request）/应答（Response）模型，客户端向服务器发送请求，服务器处理请求并返回适当的应答。

### 2.HTTP的传输流程

HTTP的传输流程包括地址解析、封装HTTP数据包、封装TCP包、建立TCP连接、客户端发送请求、服务端响应、服务端关闭TCP连接，具体流程如下。 （1）地址解析：地址解析通过域名系统DNS解析服务器域名从而获得主机的IP 地址。例如， 用客户端的浏览器请求http://localhost.com:8080/index.htm，则可从中分解出协议名、主机名、端口、对象路径等部分结果如下。

- 协议名：HTTP。
- 主机名：localhost.com。
- 端口：8080。
- 对象路径：/index.htm。

（2）封装HTTP数据包：解析协议名、主机名、端口、对象路径等并结合本机自己的信息封装成一个HTTP请求数据包。 （3）封装TCP包：将HTTP请求数据包进一步封装成TCP数据包。 （4）建立TCP连接：基于TCP的三次握手机制建立TCP连接。 （5）客户端发送请求：在建立连接后，客户端发送一个请求给服务器。 （6）服务器响应：服务器在接收到请求后，结合业务逻辑进行数据处理，然后向客户端返回相应的响应信息。在响应信息中包含状态行、协议版本号、成功或错误的代码、消息体等内容。 （7）服务器关闭TCP连接：服务器在向浏览器发送请求响应数据后关闭TCP 连接。但如果浏览器或者服务器在消息头中加入了Connection：keep-alive，则TCP连接在请求响应数据发送后仍然保持连接状态，在下一次请求中浏览器可以继续使用相同的连接发送请求。采用keep-alive方式不但减少了请求响应的时间，还节约了网络带宽和系统资源。

### 3.HTTP中的常见状态码

在HTTP请求中，无论是请求成功还是失败都会有对应的状态码返回。状态码是我们定位错误的主要依据，一般“20x”格式的状态码表示成功，“30x”格式的状态码表示网络重定向，“40x”格式的状态码表示客户端请求错误，“50x”格式的状态码表示服务器错误。

- 消息响应
  - 100：Continue(继续)
  - 101：SwitchingProtocol(切换协议)
- 成功响应
  - 200：OK(成功)
  - 201：Create(已创建)
  - 202：Accepted(已创建)
  - 203：Non-Authoritative Information(未授权信息)
  - 204：No Content(无内容)
  - 205：Reset Content(重置内容)
  - 206：Partial Content(部分内容)
- 网络重定向
  - 300：Multiple Choice（多种选择）
  - 301：Moved Permanently（永久移动）
  - 302：Found（临时移动）
  - 303：See Other（查看其他位置）
  - 304：Not Modified（未修改）
  - 305：Use Proxy（使用代理）
  - 306：unused（未使用）
  - 307：Temporary Redirect（临时重定向）
  - 308：Permanent Redirect（永久重定向）
- 客户端错误
  - 400：Bad Request（错误请求）
  - 401：Unauthorized（未授权）
  - 402：Payment Required（需要付款）
  - 403：Forbidden（禁止访问）
  - 404：No Found（未找到）
  - 405：Method Not Allowed（不允许使用该方法）
  - 406：Not Acceptable（无法接收）
  - 407：Proxy Authentication Required（要求代理身份验证）
  - 408：Request Timeout（请求超时）
  - 409：Conflict（冲突）
  - 410：Gone（已失效）
  - 411：Length Required（需要内容的长度）
  - 412：Precondition Failed（预处理失败）
  - 413：Request Entity Too Large（请求实体过长）
  - 414：Request-URI Too Long（请求网址过长）
  - 415：Unsupported Media Type（媒体类型不支持）
  - 416：Requested Range Not Satisfiable（请求范围不合要求）
  - 417：Expectation Failed（预期结果失败）
- 服务器端错误
  - 500：Internal Server Error（内部服务器错误）
  - 501：Implemented（未实现）
  - 502：Bad Gateway（网关错误）
  - 503：Service Unavailable（服务不可用）
  - 504：Gateway Timeout（网关超时）
  - 505：HTTP Version Not Supported（HTTP版本不受支持）

## HTTPS

### 1.HTTPS

HTTPS是以安全为目标的HTTP通道，它在HTTP中加入SSL层以提高数据传输的安全性。HTTP被用于在Web浏览器和网站服务器之间传递信息，但以明文方式发送内容，不提供任何方式的数据加密，如果攻击者截取了We b浏览器和网站服务器之间的传输报文，就可以直接读懂其中的信息，因此HTTP不适合传输一些敏感信息，比如身份证号码、密码等。为了数据传输的安全，HTTPS在HTTP的基础上加入了SSL协议，SSL依靠证书来验证服务器的身份，并对浏览器和服务器之间的通 信进行数据加密，以保障数据传输的安全性，其端口一般是443。

### 2.HTTP的加密流程

（1）发起请求：客户端在通过TCP和服务器建立连接之后（443端口），发出一个请求证书的消息给服务器，在该请求消息里包含自己可实现的算法列表和其他需要的消息。 （2）证书返回：服务器端在收到消息后回应客户端并返回证书，在证书中包含服务器信息、域名、申请证书的公司、公钥、数据加密算法等。 （3）证书验证：客户端在收到证书后，判断证书签发机构是否正确，并使用该签发机构的公钥确认签名是否有效，客户端还会确保在证书中列出的域名就是它正在连接的域名。如果客户端确认证书有效，则生成对称密钥，并使用公钥将对称密钥加密。 （4）密钥交换：客户端将加密后的对称密钥发送给服务器，服务器在接收到对称密钥后使用私钥解密。 （5）数据传输：经过上述步骤，客户端和服务器就完成了密钥对的交换，在之后的数据传输过程中，客户端和服务端就可以基于对称加密（加密和解密使用相同密钥的加密算法）对数据加密后在网络上传输，保证了网络数据传输的安全性。

## CDN

### 1.CDN

CDN（Content Delivery Network，内容分发网络）指基于部署在各地的机房服务器，通过中心平台的负载均衡、内容分发、调度的能力，使用户就近获取所需内容，降低网络延迟，提升用户访问的响应速度和体验度。

### 2.CDN的关键技术

CDN的关键技术包括内容发布、内容路由、内容交换和性能管理，具体如下。

- 内容发布：借助建立索引、缓存、流分裂、组播等技术，将内容发布到网络上距离用户最近的中心机房。
- 内容路由：通过内容路由器中的重定向（DNS）机制，在多个中心机房的服务器上负载均衡用户的请求，使用户从最近的中心机房获取数据。
- 内容交换：根据内容的可用性、服务器的可用性及用户的背景，在缓存服务器上利用应用层交换、流分裂、重定向等技术，智能地平衡负载流量。
- 性能管理：通过内部和外部监控系统，获取网络部件的信息，测量内容发布的端到端性能（包丢失、延时、平均带宽、启动时间、帧速率等），保证网络处于最佳运行状态。

### 3.CDN的主要特点

- 本地缓存（Cache）加速：将用户经常访问的数据（尤其静态数据）缓存在本地，以提升系统的响应速度和稳定性。
- 镜像服务：消除不同运营商之间的网络差异，实现跨运营商的网络加速，保证不同运营商网络中的用户都能得到良好的网络体验。
- 远程加速：利用DNS 负载均衡技术为用户选择服务质量最优的服务器，加快用户远程访问的速度。
- 带宽优化：自动生成服务器的远程镜像缓存服务器，远程用户在访问时从就近的缓存服务器上读取数据，减少远程访问的带宽，分担网络流量，并降低原站点的We b服务器负载等。
- 集群抗攻击：通过网络安全技术和CDN 之间的智能冗余机制，可以有效减少网络攻击对网站的影响。

### 4.内容分发系统

将用户请求的数据分发到就近的各个中心机房，以保障为用户提供快速、高效的内容服务。缓存的内容包括静态图片、视频、文本、用户最近访问的JSON数据等。缓存的技术包括内存环境、分布式缓存、本地文件缓存等。缓存的策略主要考虑缓存更新、缓存淘汰机制。

### 5.负载均衡系统

负载均衡系统是整个CDN系统的核心，负载均衡根据当前网络的流量分布、各中心机房服务器的负载和用户请求的特点将用户的请求负载到不同的中心机房或不同的服务器上，以保障用户内容访问的流畅性。负载均衡系统包括全局负载均衡（ GSLB ） 和本地负载均衡（SLB）。

- 全局负载均衡主要指跨机房的负载均衡，通过DNS 解析或者应用层重定向技术将用户的请求负载到就近的中心机房上。
- 本地负载均衡主要指机房内部的负载均衡，一般通过缓存服务器，基于LVS、Nginx、服务网关等技术实现用户访问的负载。

### 6.管理系统

管理系统分为运营管理和网络管理子系统。网络管理系统主要对整个CDN网络资源的运行状态进行实时监控和管理。运营管理指对CDN日常运维业务的管理，包括用户管理、资源管理、流量计费和流量限流等。

## 负载均衡

### 1.负载均衡

负载均衡建立在现有网络结构之上，提供了一种廉价、有效、透明的方法来扩展网络设备和服务器的带宽，增加了吞吐量，加强了网络数据处理能力，并提高了网络的灵活性和可用性。项目中常用的负载均衡有四层负载均衡和七层负载均衡。

### 2.四层负载均衡

四层负载均衡主要通过修改报文中的目标地址和端口来实现报文的分发和负载均衡。以TCP为例，负载均衡设备在接收到第1个来自客户端的SYN请求后，会根据负载均衡配置和负载均衡策略选择一个最佳的服务器，并将报文中的目标IP地址修改为该服务器的IP直接转发给该服务器。TCP连接的建立（即三次握手过程）是在客户端和服务器端之间完成的，负载均衡设备只起到路由器的转发功能。 四层负载均衡常用的软硬件如下。

- F5：硬件负载均衡器，功能完备，价格昂贵。
- LVS：基于IP+端口实现的四层负载软件，常和Keepalive配合使用。
- Nginx：同时实现四层负载和七层负载均衡，带缓存功能，可基于正则表达式灵活转发。

### 3.七层负载均衡

七层负载均衡又叫作“内容负载均衡”，主要通过解析报文中真正有意义的应用层内容，并根据负载均衡配置和负载均衡策略选择一个最佳的服务器响应用户的请求。 七层应用负载可以使整个网络更智能化，七层负载均衡根据不同的数据类型将数据存储在不同的服务器上来提高网络整体的负载能力。比如将客户端的基本信息存储在内存较大的缓存服务器上，将文件信息存储在磁盘空间较大的文件服务器上，将图片视频存储在网络I/O能力较强的流媒体服务器上。在接收到不同的客户端的请求时从不同的服务器上获取数据并将其返回给客户端，提高客户端的访问效率。 七层负载均衡常用的软件如下。

- HAProxy：支持七层代理、会话保持、标记、路径转移等。
- Nginx：同时实现四层负载和七层负载均衡，在HTTP和Mail协议上功能比较好，性能与HAProxy差不多。
- Apache：使用简单，性能较差。

### 4.四层负载均衡与七层负载均衡的对比

四层负载均衡基于IP和端口的方式实现网络的负载均衡，具体实现为对外提供一个虚拟IP和端口接收所有用户的请求，然后根据负载均衡配置和负载均衡策略将请求发送给真实的服务器。 七层负载均衡基于URL等资源来实现应用层基于内容的负载均衡，具体实现为通过虚拟的URL或主机名接收所有用户的请求，然后将请求发送给真实的服务器。 四层负载均衡和七层负载均衡的最大差别是：四层负载均衡只能针对IP地址和端口上的数据做统一的分发，而七层负载均衡能根据消息的内容做更加详细的有针对性的负载均衡。我们通常使用LVS等技术实现基于Socket的四层负载均衡，使用Nginx等技术实现基于内容分发的七层负载均衡，比如将以“/user/***”开头的URL请求负载到单点登录服务器，而将以“/business/\***”开头的URL请求负载到具体的业务服务器。

### 5.负载均衡算法

常用的负载均衡算法有：轮询均衡（Round Robin）、权重轮询均衡（Weighted Round Robin）、随机均衡（Random）、权重随机均衡（Weighted Random）、响应速度均衡（Response Time）、最少连接数均衡（Least Connection）、处理能力均衡、DNS响应均衡（Flash DNS）、散列算法均衡、IP地址散列、URL散列。不同的负载均衡算法适用于不同的应用场景。

1.轮询均衡（Round Robin）

轮询均衡指将客户端请求轮流分配到 1至 N台服务器上，每台服务器均被均等地分配一定数量的客户端请求。轮询均衡算法适用于集群中所有服务器都有相同的软硬件配置和服务能力的情况下。

2.权重轮询均衡（Weighted Round Robin）

权重轮询均衡指根据每台服务器的不同配置及服务能力，为每台服务器都设置不同的权重值，然后按照设置的权重值轮询地将请求分配到不同的服务器上。例如，服务器A的权重值被设计成 3，服务器B的权重值被设计成 3，服务器C的权重值被设计成 4，则服务器A、B、C将分别承担 30%、30%、40%的客户端请求。权重轮询均衡算法主要用于服务器配置不均等的集群中。

3.随机均衡（Random）

随机均衡指将来自网络的请求随机分配给内部的多台服务器，不考虑服务器的配置和负载情况。

4.权重随机均衡（Weighted Random）

权重随机均衡算法类似于权重轮询算法，只是在分配请求时不再轮询发送，而是随机选择某个权重的服务器发送。

5.响应速度均衡（Response Time）

响应速度均衡指根据服务器设备响应速度的不同将客户端请求发送到响应速度最快的服务器上。对响应速度的获取是通过负载均衡设备定时为每台服务都发出一个探测请求（例如Ping）实现的。响应速度均衡能够为当前的每台服务器根据其不同的负载情况分配不同的客户端请求，这有效避免了某台服务器单点负载过高的情况。但需要注意的是，这里探测到的响应速度是负载均衡设备到各个服务器之间的响应速度，并不完全代表客户端到服务器的响应速度，因此存在一定偏差。

6.最少连接数均衡（Least Connection）

最少连接数均衡指在负载均衡器内部记录当前每台服务器正在处理的连接数量，在有新的请求时，将该请求分配给连接数最少的服务器。这种均衡算法适用于网络连接和带宽有限、CPU处理任务简单的请求服务，例如FTP。

7.处理能力均衡

处理能力均衡算法将服务请求分配给内部负荷最轻的服务器，负荷是根据服务器的CPU型号、CPU数量、内存大小及当前连接数等换算而成的。处理能力均衡算法由于考虑到了内部服务器的处理能力及当前网络的运行状况，所以相对来说更加精确，尤其适用于七层负载均衡的场景。

8.DNS响应均衡（Flash DNS）

DNS响应均衡算法指在分布在不同中心机房的负载均衡设备都收到同一个客户端的域名解析请求时，所有负载均衡设备均解析此域名并将解析后的服务器IP地址返回给客户端，客户端向收到第一个域名解析后的IP地址发起请求服务，而忽略其他负载均衡设备的响应。这种均衡算法适用于全局负载均衡的场景。

9.散列算法均衡

散列算法均衡指通过一致性散列算法和虚拟节点技术将相同参数的请求总是发送到同一台服务器，该服务器将长期、稳定地为某些客户端提供服务。在某个服务器被移除或异常宕机后，该服务器的请求基于虚拟节点技术平摊到其他服务器，而不会影响集群整体的稳定性。

10.IP地址散列

IP地址散列指在负载均衡器内部维护了不同链接上客户端和服务器的IP对应关系表，将来自同一客户端的请求统一转发给相同的服务器。该算法能够以会话为单位，保证同一客户端的请求能够一直在同一台服务器上处理，主要适用于客户端和服务器需要保持长连接的场景，比如基于TCP长连接的应用。

11.URL散列

URL散列指通过管理客户端请求URL信息的散列表，将相同URL的请求转发给同一台服务器。该算法主要适用于在七层负载中根据用户请求类型的不同将其转发给不同类型的应用服务器。

### 6.LVS

LVS（Linux Virtual Server）是一个虚拟的服务器集群系统，采用IP负载均衡技术将请求均衡地转移到不同的服务器上执行，且通过调度器自动屏蔽故障服务器，从而将一组服务器构成一个高性能、高可用的虚拟服务器。整个服务器集群的结构对用户是透明的，无须修改客户端和服务器端的程序，便可实现客户端到服务器的负载均衡。

### 7.LVS的原理

LVS由前端的负载均衡器（Load Balancer，LB）和后端的真实服务器（Real Server，RS）群组成，在真实服务器间可通过局域网或广域网连接。LVS的这种结构对用户是透明的，用户只需要关注作为LB的虚拟服务器（Virtual Server），而不需要关注提供服务的真实服务器群。在用户的请求被发送给虚拟服务器后，LB根据设定的包转发策略和负载均衡调度算法将用户的请求转发给真实服务器，真实服务器再将用户请求的结果返回给用户。 实现LVS的核心组件有负载均衡调度器、服务器池和共享存储。

- 负载均衡调度器（Load Balancer/Director）：是整个集群对外提供服务的入口，通过对外提供一个虚拟IP 来接收客户端请求。在客户端将请求发送到该虚拟IP 后，负载均衡调度器会负责将请求按照负载均衡策略发送到一组具体的服务器上。
- 服务器池（Server Pool）：服务器池是一组真正处理客户端请求的真实服务器，具体执行的服务有WEB、MAIL、FTP和DNS等。
- 共享存储（Shared Storage）：为服务器池提供一个共享的存储区，使得服务器池拥有相同的内容，提供相同的服务。

LVS技术中常用的名词：

- CIP（客户端IP）：用户记录发送给集群的源IP地址
- VIP（虚拟IP）：用于Director 对外提供服务的IP地址
- DIP（Director IP）：Director 用于连接内外网络的IP地址，即负载均衡器上的IP地址
- RIP（真实IP）：集群中真实服务器的物理IP地址
- LIP（LVS内部IP）：LVS集群的内部通信IP

LVS的IP负载均衡技术是通过IPVS模块实现的。IPVS是LVS集群系统的核心软件， 被安装在Director Server 上， 同时在Director Server上虚拟出一个IP地址。用户通过这个虚拟的IP地址访问服务器。这个虚拟的IP地址一般被称为LVS的VIP，即Virtual IP。访问的请求首先经过VIP到达负载调度器，然后由负载调度器从真实服务器列表中选取一个服务节点响应用户的请求。

### 8.LVS数据转发

LVS的数据转发流程是LVS设计的核心部分。 （1）PREROUTING链接收用户请求：客户端向PREROUTING链发送请求。 （2）INPUT链转发：在PREROUTING链通过RouteTable列表发现请求数据包的目的地址是本机时，将数据包发送给INPUT链。 （3）IPVS检查：IPVS检查INPUT链上的数据包，如果数据包中的目的地址和端口不在规则列表中，则将该数据包发送到用户空间的ipvsadm。ipvsadm主要用于用户定义和管理集群。 （4）POSTROUTING链转发：如果数据包里面的目的地址和端口都在规则里面，那么将该数据包中的目的地址修改为事先定义好的真实服务器地址，通过FORWARD将数据发送到POSTROUTING链。 （5）真实服务器转发：POSTROUTING链根据数据包中的目的地址将数据包转发到真实服务器。

### 9.LVS NAT模式

LVS NAT （ Network Address Translation ） 即网络地址转换模式。 NAT模式通过对请求报文和响应报文的地址进行改写完成对数据的转发，具体流程如下。 （ 1 ） 客户端将请求报文发送到LVS ， 请求报文的源地址是CIP（Client IP Address，客户端IP），目标地址是VIP（Virtual IP Address，虚拟IP）。 （2）LVS在收到报文后，发现请求的IP地址在LVS的规则列表中存在，则将客户端请求报文的目标地址VIP修改为RIP（Real-server IP Address，后端服务器的真实IP），并将报文发送到具体的真实服务器上。 （3）真实服务器在收到报文后，由于报文的目标地址是自己的IP，所以会响应该请求，并将响应报文返回给LVS。 （4）LVS在收到数据后将此报文的源地址修改为本机IP地址，即VIP，并将报文发送给客户端。

NAT模式的特点

- 请求的报文和响应的报文都需要通过LVS进行地址改写，因此在并发访问量较大的时候LVS存在瓶颈问题，一般适用于节点不是很多的情况下。
- 只需要在LVS上配置一个公网IP即可。
- 每台内部的真实服务器的网关地址都必须是LVS的内网地址。
- NAT 模式支持对IP 地址和端口进行转换，即用户请求的端口和真实服务器的端口可以不同。

### 10.LVS DR模式

LVS DR（Direct Routing）模式用直接路由技术实现，通过改写请求报文的MAC地址将请求发送给真实服务器。 LVD DR模式是局域网中经常被用到的一种模式，其报文转发流程如下。 （1）客户端将请求发送给LVS，请求报文的源地址是CIP，目标地址是VIP。 （2）LVS在收到报文后，发现请求在规则中存在，则将客户端请求报文的源MAC地址改为自己的DIP（Direct IP Address，内部转发IP）的MAC地址，将目标MAC改为RIP的MAC地址，并将此包发送给真实服务器。 （3）真实服务器在收到请求后发现请求报文中的目标MAC是自己，就会将此报文接收下来，在处理完请求报文后，将响应报文通过lo（回环路由）接口发送给eth0网卡，并最终发送给客户端。

NAT模式的特点

- 通过LVS修改数据包的目的MAC地址实现转发。注意，源IP地址仍然是CIP，目标IP地址仍然是VIP地址。
- 请求的报文均经过LVS，而真实服务器响应报文时无须经过LVS，因此在并发访问量大时比NAT模式的效率高很多。
- 因为DR 模式是通过MAC 地址改写机制实现转发的，因此所有真实服务器节点和LVS只能被部署在同一个局域网内。
- 真实服务器主机需要绑定VIP 地址在lo接口（掩码 32 位）上，并且需要配置ARP抑制。
- 真实服务器节点的默认网关无须被配置为LVS网关，只需要被配置为上级路由的网关，能让真实服务器直接出网即可。
- DR 模式仅做MAC 地址的改写，不能改写目标端口，即真实服务器端口和VIP端口必须相同。

### 11.LVS TUN模式

TUN（IP Tunneling）通过IP隧道技术实现。 LVS TUN模式常用于跨网段或跨机房的负载均衡，具体的报文转发流程如下。 （1）客户端将请求发送给前端的LVS，请求报文的源地址是CIP，目标地址是VIP。 （2）LVS在收到报文后，发现请求在规则里中存在，则将在客户端请求报文的首部再封装一层IP报文，将源地址改为DIP，将目标地址改为RIP，并将此包发送给真实服务器。 （3）真实服务器在收到请求报文后会先拆开第1层封装，因为发现里面还有一层IP首部的目标地址是自己lo接口上的VIP，所以会处理该请求报文，并将响应报文通过lo接口发送给eth0网卡，并最终发送给客户端。

TUN模式的特点

- UNNEL模式需要设置lo接口的VIP不能在公网上出现。
- TUNNEL模式必须在所有的真实服务器上绑定VIP的IP地址。
- TUNNEL 模式中VIP→真实服务器的包通信通过TUNNEL 隧道技术实现，不管是内网还是外网都能通信，所以不需要LVS和真实服务器在同一个网段内。
- 在TUNNEL 模式中，真实服务器会把响应报文直接发送给客户端而不经过LVS，负载能力较强。
- TUNNEL 模式采用的是隧道模式，使用方法相对复杂，一般用于跨机房LVS 实现，并且需要所有服务器都支持IP Tunneling或IPEncapsulation协议。

### 12.LVS FULLNAT模式

无论是DR模式还是NAT模式，都要求LVS和真实服务器在同一个VLAN下，否则LVS无法作为真实服务器的网关，因此跨VLAN的真实服务器无法接入。同时，在流量增大、真实服务器水平扩容时，单点LVS会成为瓶颈。 FULLNAT能够很好地解决LVS和真实服务器跨VLAN的问题，在跨VLAN问题解决后，LVS和真实服务器不再存在VLAN上的从属关系，可以做到多个LVS对应多个真实服务器，解决水平扩容的问题。FULLNAT的原理是在NAT的基础上引入Local Address IP（内网IP地址），将CIP→VIP转换为LIP→RIP，而LIP和RIP均为IDC内网IP，可以通过交换机实现跨VLAN通信。 LVS FULLNAT具体的报文转发流程如下。 （1）客户端将请求发送给LVS的DNAT，请求报文的源地址是CIP，目标地址是VIP。 （ 2 ） LVS 在收到数据后将源地址CIP 修改成LIP （ Local IP Address，LVS的内网IP），将目标地址VIP修改为RIP，并将数据发送到真实服务器。多个LIP在同一个IDC数据中心，可以通过交换机跨VLAN通信。 （3）真实服务器在收到数据包并处理完成后，将目标地址修改为LIP，将源地址修改为RIP，最终将这个数据包返回给LVS。 （4）LVS在收到数据包后，将数据包中的目标地址修改为CIP，将源地址修改为VIP，并将数据发送给客户端。

### 13.Nginx反向代理与负载均衡

一般的负载均衡软件如LVS实现的功能只是对请求数据包的转发和传递，从负载均衡下的节点服务器来看，接收到的请求还是来自访问负载均衡器的客户端的真实用户；而反向代理服务器在接收到用户的访问请求后，会代理用户重新向节点服务器（We b服务器、文件服务器、视频服务器）发起请求，反向代理服务器和节点服务器做具体的数据交互，最后把数据返回给客户端用户。在节点服务器看来，访问的节点服务器的客户端就是反向代理服务器，而非真实的网站访问用户。

upstream_module

ngx_http_upstream_module是Nginx的负载均衡模块，可以实现网站的负载均衡功能即节点的健康检查。upstream模块允许Nginx定义一组或多组节点服务器，在使用时可通过proxy_pass代理方式把网站的请求发送到事先定义好的对应Upstream组的名字上。

```html
upstream restLVSServer{
    server 191.168.1.10:9000 weight=5;
    server 191.168.1.11:9000;
    server example.com:9000 max_fails=2 fail_timeout=10s bakup;
}
```

如上代码定义了名为restLVSServer的upstream，并在其中定义了 3个服务地址，在用户请求restLVSServer服务时，Nginx会根据权重将请求转发到具体的服务器。常用的upstream配置如下。

- weight：服务器权重。
- max_fails：Nginx尝试连接后端服务器的最大失败次数，如果失败时大于max_fails，则认为该服务器不可用。
- fail_timeout：max_fails和fail_timeout一般会关联使用，如果某台服务器在fail_timeout时间内出现了max_fails次连接失败，那么Nginx会认为其已经挂掉，从而在fail_timeout时间内不再去请求它，fail_timeout默认是10s，max_fails默认是1，即在默认情况下只要发生错误就认为服务器挂了，如果将max_fails设置为0，则表示取消这项检查。
- backup：表示当前服务器是备用服务器，只有其他非backup后端服务器都挂掉或很忙时，才会分配请求给它。
- down：标志服务器永远不可用。

proxy_pass

proxy_pass指令属于ngx_http_proxy_module模块，此模块可以将请求转发到另一台服务器，在实际的反向代理工作中，会通过location功能匹配指定的URI，然后把接收到的服务匹配URI的请求通过proxy_pass抛给定义好的upstream节点池。

```html
location /download/{
    proxy_pass http://192.168.1.13:9000/download/vedio/;
}
```

如上代码定义了一个download的反向代理，在客户端请求/download时，Nginx会将具体的请求转发给proxy_pass配置的地址处理请求，这里配置的地址是http://192.168.1.13:9000/download/vedio/。

常用proxy_pass配置:

- proxy_next_upstream：在什么情况下将请求传递到下一个upstream
- proxy_limite_rate：限制从后端服务器读取响应的速率
- proxy_set_header：设置HTTP请求header，后续请求会将header传给后端服务器节点
- client_body_buffer_size：客户端请求主体缓冲区的大小
- proxy_connect_timeout：代理与后端节点服务器连接的超时时间
- proxy_send_timeout：后端节点数据回传的超时时间
- proxy_read_timeout：设置Nginx从代理的后端服务器获取信息的时间，表示在连接成功建立后，Nginx等待后端服务器的响应时间
- proxy_buffer_size：设置缓冲区的大小
- proxy_buffers：设置缓冲区的数量和大小
- proxy_busy_buffers_size：由于设置系统很忙时可以使用的proxy_buffers大小
- proxy_temp_file_write_size：指定缓存临时文件的大小