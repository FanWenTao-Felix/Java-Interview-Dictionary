## 网络

### 1.说一下TCP/IP的四层网络模型？那么七层网络模型呢？

OSI七层模型，就是搞一个标准的网络模型出来，大家都按照这个来走，那么大家都有统一的规范。OSI七层模型，是应用层、表示层、会话层、传输层、网络层、数据链路层、物理层。TCP/IP四层模型，数据链路层、网络层、传输层、应用层。

从底向上的网络分层

1）物理层

物理层就指的这个，就是怎么把各个电脑给联结起来，形成一个网络，这就是物理层的含义，物理层负责传输0和1的电路信号。计算机的最最底层，就是0/1，电信号。

2）数据链路层

数据链路层，物理层给各个电脑连接起来了，还传输最底层的0和1电路信号，关键不行啊，你得定义清楚哪些0和1分为一组，这些信号啥意思？这才能进行通信。所以数据链路层就干这事儿，定义一下电路信号咋分组。

很多年前，每个公司都定义自己的电路信号分组方式，但是后来出来了以太网协议，以太网。一组电信号是一个数据包，叫一个帧（frame），每个帧分成两个部分，标头（head）和数据（data），标头包含一些说明性的东西，比如说发送者、接收者和数据类型之类的。

每台电脑要往另外一台电脑发送数据，一堆0/1电路信号，封装成数据包，包含头和数据，头里包含了从哪儿来到哪儿去，必须从一台电脑的一个网卡，发送到另外一个电脑的一个网卡，所以以太网发送的数据包必须得指定，目标电脑的网卡的mac地址。

以太网规定了，每个网卡必须得包含一个mac地址，mac地址就是这个网卡的唯一标识，

以太网协议规定了，接入网络里的所有设备，都得有个网卡，以太网协议里的那个数据包，在数据链路层传输的数据包，必须从一个电脑的网卡传输到另外一个电脑的网卡，而这个网卡地址就叫做所谓的mac地址。每块网卡出厂的时候，就有一个唯一的mac地址，48位的二进制，但是一般用12个16进制数字表示，前6个16进制是厂商编号，后6个16进制是网卡流水号。

windows上，ipconfig /all，看看物理地址，就是mac地址，7C-67-A2-20-AB-5C

所以在以太网里传输数据包的时候，必须指定接收者的mac地址才能传输数据。

但是以太网的数据包怎么从一个mac地址发送到另一个mac地址？这个不是精准推送的，以太网里面，如果一个电脑发个数据包出去，会广播给局域网内的所有电脑设备的网卡，然后每台电脑都从数据包里获取接收者的mac地址，跟自己的mac地址对比一下，如果一样，就说明这是发给自己的数据包。

但是上面这种广播的方式，仅仅针对一个子网（局域网）内的电脑，会广播，否则一个电脑不能广播数据包给全世界所有的其他电脑吧，是仅仅广播给一个子网里面的电脑的。

3）网络层

子网内的电脑，通过以太网发个数据包，对局域网内的电脑，是广播出去的。那么怎么知道哪些电脑在一个子网内呢？这就得靠网络层了，这里就有一套IP地址，IP地址就可以让我们区分哪些电脑是一个子网的。

网络层里有IP协议，IP协议定义的地址就叫做IP地址。IP地址有IPv4和IPv6两个版本，目前广泛使用的是IPv4，是32个二进制数字组成的，但是一般用4个十进制数字表示，范围从0.0.0.0到255.255.255.255之间。

每台计算机，都会分配一个ip地址，ip地址的前24位（就是前面3个十进制数字），代表了网络，后8位（就是最后1个十进制数字），代表了主机。如果几台电脑是一个子网的，那么前面的3个十进制数字一定是一样的。举个例子，大家平时做实验，玩儿虚拟机吧，自己win上开几个linux虚拟机，你会发现，win上的ip地址可能是192.168.0.103，然后几个虚拟机的ip地址是192.168.0.182，192.168.0.125，192.168.0.106，类似这样的。这个win机器和几个虚拟机，前面3个十进制数字都是192.168.0，就代表大家是一个子网内的，最后那个数字是这个子网的不同主机的编号。

但是实际上上面就是举个例子，其实单单从ip地址是看不出来哪些机器是一个子网的，因为从10进制是判断不出来的。需要通过ip地址的二进制来判断，结合一个概念来判断，叫做子网掩码。比如说ip地址是192.168.56.1，子网掩码是255.255.255.0。知道了子网掩码之后，如果要判断两个ip地址是不是一个子网的，就分别把两个ip地址和自己的子网掩码进行二进制的与运算，与运算之后，比较一下代表网络的那部分。

192.168.56.1和192.168.32.7，判断是不是一个子网的，拿子网掩码255.255.255.0，跟两个ip地址的二进制做与运算，通过二进制来比较网络部分的地址是不是一模一样的。

有了网络层的ip地址之后，两台在子网内的电脑终于可以通过广播+mac地址判断来传输数据包进行通信了。

但是如果发现要接受数据包的计算机不在子网内，那么就不能通过广播来发送数据包，需要通过路由来发送数据包。

路由器负责将多个子网进行连接，比如你在自己家里，其实你就只是你自己的一个子网，你要是访问网站啥的，是跟那个网站机器所在的子网进行通信。

每个电脑都可以搞多个网卡的，不是只有一个网卡，一般笔记本电脑都有以太网网卡和wifi网卡，发送数据包的时候要决定走哪个网卡。路由器，其实就是配置了多个网卡的一个专用设备，可以通过不同的网卡接入不同的网络。

网关其实是就是路由器的一种，运作在网络层，这个概念不多解释了，大家可以就把路由器上的ip地址认为是网关，路由器上每个网卡都有mac地址和对应的ip地址。路由器虽然有mac地址，但是不能通过mac地址寻址的，必须通过ip地址寻址，所以路由器其实是工作在网络层的设备。

网络交换机，也是一种设备，是工作在数据链路层的，路由器是工作在网路层的。网络交换机是通过mac地址来寻址和传输数据包的；但是路由器是通过ip地址寻址和传输数据包的。网络交换机主要用在局域网的通信，一般你架设一个局域网，里面的电脑通信是通过数据链路层发送数据包，通过mac地址来广播的，广播的时候就是通过网络交换机这个设备来把数据广播到局域网内的其他机器上去的；路由器一般用来让你连入英特网。

LAN，就是local area network，就是局域网；WAN，就是wide area network，就是广域网。WLAN是wireless local area network，就是无线局域网，也就是wifi，在局域网内，直接通过wifi无线联网。

家里的路由器是包含了交换机和路由的两个功能的，如果是连接到局域网内的设备就把线插LAN那儿；如果是连接到英特网，就把线插在WAN那儿。

两个局域网之间，如果要是通过一个路由器进行通信的话，是怎么弄的。大概过程就是，路由器配置了两块网卡，每个网卡可以连到一个局域网内。

局域网1内的电脑，要发送数据包到局域网2内的电脑，在数据包里写上自己的ip地址和对方的ip地址。但是他们俩不在一个局域网内，于是局域网1内的电脑，先通过交换机将数据包发送给路由器，这个过程需要将路由器的一块网卡的ip地址对应的mac地址写到数据包的头部，然后才能通过交换机广播出去，路由器接收到之后比较自己一块网卡的mac地址，就知道是来找自己的。

接着路由器接收到数据包之后，就会在局域网2内，将目标机器的ip地址对应的mac地址写入头部，接着再次通过交换机发送广播通知，发送给局域网2内的电脑。

一个局域网内的每台机器都有自己的ARP cache，这个ARP就是用来在一个局域网内让各个设备都知道每个设备的ip地址和mac地址的对应关系的，一般就是某个机器发送广播通知自己的ip地址和mac地址的对应关系，然后每个机器给他一个回应。以此类推，大家都互相这样广播一把，ip地址和mac地址的对应关系，大家不就都知道了。

一个ip地址对应着一个mac地址

所以大家在上面可以看到，一个子网内的机器之间通信，就是在数据包里写上对方的mac地址，然后交换机广播出去ok了；但是如果是跨子网的通信，就是写上对方的ip地址，然后先通过mac地址广播到路由器，让路由器再根据另外一个子网的ip地址转换为mac地址，通过另外一个子网的交换机广播过去。就这个意思。

4）传输层

上面我们大概明白了通过网络层的ip地址怎么划分出来一个一个的子网，然后在子网内部怎么通过mac地址广播通信；跨子网的时候，怎么通过ip地址 -> mac地址 -> 交换机 -> 路由器 -> ip地址 -> mac地址 -> 交换机的方式来通过路由器进行通信。

但是这里还有一个问题，就是一台机器上，是很多个程序用一个网卡进行网络通信的，比如说浏览器、QQ、视频直播，这些软件都用了一个网卡往外面发送数据，然后从网卡接收数据，对吧。

所以还需要一个端口号的概念，就是你得发送数据包到某个机器的一个网卡的某个端口上去，然后那个机器上监听那个端口的程序，就可以提取发送到这个端口的数据，知道是自己的数据。端口号是0-65536的范围内，0~1023被系统占用了，别的应用程序就用1024以上的端口就ok了。

电脑1，是在端口48362监听的，通过网卡发送了一条数据 -> 电脑2的ip地址的20386这个端口 -> 电脑2的上面的某个QQ，监听着20386的端口 -> 电脑2的网卡接收到一条数据之后，发现人家找的是20386这个端口，就去找谁哪个哥儿们在监听20386端口，QQ在监听，我就把这个网卡过来的数据，传递给QQ，通过端口知道，哪条数据是给你的

所以其实大家会发现一点，网络层，是基于ip协议，进行主机和主机间的寻址和通信的，然后传输层，其实是建立某个主机的某个端口，到另外一个主机的某个端口的连接和通信的。这个通信，就是通过socket来实现的，通过socket就可以基于tcp/ip协议完成刚才上面说的一系列的比如基于ip地址和mac地址转换和寻址啊，通过路由器通信啊之类的，而且会建立一个端口到另外一个端口的连接。

udp和tcp都是传输层的协议，作用就是在数据包里加入端口号，可以通过端口号进行点对点的通信了。udp协议是不可靠的，发出去人家收到没有就不知道了；tcp协议是可靠的，要求三次握手，而且要求人家接收到数据必须回复你。

传输层的tcp协议，仅仅只是规定了一套基于端口的点对点的通信协议，包括如何建立连接，如何发送和读取消息，但是实际上如果你要基于tcp协议来开发，你一般是用socket，java socket网络编程

第一个点：端口号，允许了两个电脑上程序对程序的通信

第二个点：TCP就是一个我们平时主要用于网络编程通信的协议了，上层的协议，平时经常用到的一个协议，三次握手建立连接，流式拆包发送数据，四次握手断开连接

两个程序之间互相交换几次数据，程序1先发送一个数据给程序2，程序2返回一个结果，以此类推，反复进行3次，大家互相交换一些数据，交换成功了以后，就认为两个程序之间建立了TCP连接

三次握手，交换了3次数据，底层的网络模型里面，具体在干什么？

电脑上的程序，要先发送一个数据给服务器上的程序，这个数据实际上来说是按照tcp协议的规范封装的一个tcp包，tcp包头和具体的数据

互相发送TCP包，包头里面就包含了TCP三次握手互相之间要设置和交换的一些数据，具体交换哪些数据，可以看后面的一讲，专门讲解TCP三次握手的视频

Socket编程，连接，以IO流的形式，发送数据流，以流的方式从对方服务器再接收一段数据回来，这个过程也是按照TCP协议在进行通信，对应到底层的网络模型，到底是个什么意思呢？

你发送的数据，按照固定的大小，封装成一个一个TCP包，每个TCP包封装在IP包里，封装在以太网包，最后通过网卡出去，走底层的以太网协议 + IP协议，子网内 + 跨子网，把你的一个一个连续的TCP包通过这种方式给传输到对方的服务器上去

对方的服务器接收到N多个TCP包，最后组装起来就是你以IO流的方式发送 过来的一段数据，人家就会反过来，通过IO流的方式返回一个一个TCP包的数据给你，一样的通过底层的IP协议 + 以太网协议，来传输

如果TCP通信结束之后，他实际上来说就会断开TCP连接，四次挥手，互相交换四次数据，就是互相传输4个TCP包，把socket相关的数据给删除掉，连接其实就是断开了

传输TCP包的时候，对应到底层，如果一个TCP包比较大的话，此时是不能直接用一个以太网包来传输，底层的以太网包也是有一个固定的大小的，会在底层把你的TCP包再次拆分为多个以太网包

建立TCP连接，到底是什么意思呢？

就是以TCP的协议的规范，定义的是说一台电脑的一个端口上的程序，有一个socket；跟另外一个服务器上的某个端口上的程序，另外一个socket，之间，通过交换几次TCP包，大家交换了一下数据，最后就在各自的电脑 / 服务器上，建立了对应的socket，就代表说，建立了一个TCP连接

没有TCP三次握手建立连接的话，两个程序之间不知道对方的一些基本情况，没法有效的进行通信，所以通过三次握手建立连接，交换一些数据，就知道对方是什么情况了，此时就可以进行通信了

5）应用层

通过传输层的tcp协议可以传输数据，但是人家收到数据之后，怎么来解释？比如说收到个邮件你怎么处理？收到个网页你怎么处理？类似这个意思，所以针对各种不同的应用，邮件、网页之类的，都是定义不同的应用层协议的。这个应用层，我们就假设综合了会话层、表示层和应用层了，3层合成1层。

比如最常见的，应用层的协议就是http协议，进行网络通信。

4层：数据链路层（以太网协议），网络层（ip协议），传输层（tcp协议），应用层（http协议）

7层：物理层（网线，海底光缆，传递0/1电路信号），会话层、表示层、应用层 -> 应用层

ip地址和子网掩码用来划分子网的，判断哪些ip地址在一个子网内。同时你的ip地址和mac地址关联起来的，唯一定位了你的网卡。网关地址，你就认为是路由器上的那个网卡的ip地址吧，路由器的网卡也有mac地址，mac地址对应了一个ip地址。

DNS地址是啥呢？Domain Name System。因为我们一般定位是通过ip地址+mac地址+端口号来定位一个通信目标的，但是如果在浏览器上输入一个[www.baidu.com](www.baidu.com)，咋整？这个时候是先把[www.baidu.com](www.baidu.com)发给DNS服务器，然后DNS服务器告诉你[www.baidu.com](www.baidu.com)对应的ip地址的。

### 2.用浏览器请求一个链接的时候，经历了哪些过程（DNS解析过程）？

我们先假设，我们给电脑设置了几个东西：

ip地址：192.168.31.37

子网掩码：255.255.255.0

网关地址：192.168.31.1

DNS地址：8.8.8.8

我们打开一个浏览器，请求[www.baidu.com](www.baidu.com)地址，这个时候找DNS服务器，DNS服务器解析域名之后，返回一个ip地址，比如172.194.26.108。接着会判断两个ip地址是不是一个子网的，用子网掩码255.255.255.0，对两个ip地址做与运算，拿到192.168.31.0和172.194.26.0，明显不是一个子网的。

那就得发送一个数据包给网关，其实你就认为是我们的路由器吧，就是192.168.31.1，而且我们是可以拿到网关ip地址的mac地址的，现在我们从应用层出发，通过浏览器访问一个网站，是走应用层的http协议的。

既然要把浏览器发出的请求打包成数据包，要把哪些东西给放到数据包中去呢？应该是把http请求给打包到数据包中去。

http协议分为几个部分：

请求方法 + URL地址 + http版本：比如GET http://172.194.26.108/test HTTP/1.1，类似这种

请求头，类似下面这种：

Host: upload.jiangsu.io

Proxy-Connection: keep-alive

User-Agent: Mozilla/5.0

空行

请求体，比如常见的可以放一个json

这就构成了一个http请求报文

浏览器请求一个地址，先按照应用层的http协议，封装一个应用层数据包，数据包里就放了http请求报文

这个时候会将这个http请求报文打包成一个数据包，仅仅只是数据包的数据部分，此时是数据包是没有头的。上面根据http协议搞一个http请求报文，然后搞一个数据包出来，就是网络模型中到的应用层干的事儿了。

接着就是跑传输层来了，这个层是tcp协议，这个tcp协议会让你设置端口，发送方的端口随机选一个，接收方的端口一般是默认的80端口。这个时候，会把应用层数据包给封装到tcp数据包中去，而且会加一个tcp头，这个tcp数据包是对应一个tcp头的，这个tcp头里就放了端口号信息。

接着跑到网络层来了，走ip协议，这个时候会把tcp头和tcp数据包，放到ip数据包里去，然后再搞一个ip头，ip头里本机和目标机器的ip地址。这里本机ip地址是192.168.31.37，目标机器是172.194.26.108。

因为，通过ip协议，可以判断说，两个ip地址不是在一个子网内的，所以此时只能将数据包先通过以太网协议广播到网关上去，通过网关再给他发送出去

接着是数据链路层，这块走以太网协议，这里是把ip头和ip数据包封到以太网数据包里去，然后再加一个以太网数据包的头，头里放了本机网卡mac地址，和网关的mac地址。但是以太网数据包的限制是1500个字节，但是假设这个时候ip数据包都5000个字节了，那么需要将ip数据包切割一下。

这个时候一个以太网数据包要切割为4个数据包，每个数据包包含了以太网头、ip头和切割后的ip数据包，4个数据包的大小分别是1500，1500,1500，560。ip头里包含了每个数据包的序号。

这4个以太网数据包都会通过交换机发到你的网关上，然后你的路由器是可以联通别的子网的，这个是时候你的路由器就会转发到别的子网的可能也是某个路由器里去，然后以此类推吧，N多个路由器或者你叫网关也行，N多个网关转发之后，就会跑到百度的某台服务器，接收到4个以太网数据包。

百度服务器接收到4个以太网数据包以后，根据ip头的序号，把4个以太网数据包里的ip数据包给拼起来，就还原成一个完整的ip数据包了。接着就从ip数据包里面拿出来tcp数据包，再从tcp数据包里取出来http数据包，读取出来http数据包里的各种协议内容，接着就是做一些处理，然后再把响应结果封装成htp响应报文，封装在http数据包里，再一样的过程，封装tcp数据包，封装ip数据包，封装以太网数据包，接着通过网关给发回去。

### 3.TCP三次握手和四次握手的工作流程是什么（画一下流程图）？为什么不是五次握手或者两次握手？

（1）tcp三次握手过程

通过传输层的tcp协议建立网络连接的时候，其实走的是三次握手的过程

建立三次握手的时候，TCP报头用到了下面几个东西，ACK、SYN、FIN。

第一次握手，客户端发送连接请求报文，此时SYN=1、ACK=0，这就是说这是个连接请求，seq = x，接着客户端处于SYN_SENT状态，等待服务器响应。

第二次握手，服务端收到SYN=1的请求报文，需要返回一个确认报文，ack = x + 1，SYN=1，ACK = 1，seq = y，发送给客户端，自己处于SYN_RECV状态。

第三次握手，客户端收到了报文，将ack = y + 1，ACK = 1，seq = x + 1

其实三次握手说白了，就是来回来去三次请求，每次请求带上一堆TCP报文头，根据报文头是否正确，就是越好的协议来建立连接。简单说就是这样。

（2）为啥不是2次或者4次握手呢？

假设两次握手就ok了，要是客户端第一次握手过去，结果卡在某个地方了，没到服务端；完了客户端再次重试发送了第一次握手过去，服务端收到了，ok了，大家来回来去，三次握手建立了连接。

结果，尴尬的是，后来那个卡在哪儿的老的第一次握手发到了服务器，服务器直接就返回一个第二次握手，这个时候服务器开辟了资源准备客户端发送数据啥的，结果呢？客户端根本就不会理睬这个发回去的二次握手，因为之前都通信过了。

但是如果是三次握手，那个二次握手发回去，客户端发现根本不对，就会发送个复位的报文过去，让服务器撤销开辟的资源，别等着了。

因为3次握手就够了，不需要4次或者5次浪费资源了。

（3）tcp断开连接的4次挥手

第一次挥手，客户端发送报文，FIN=1，seq=u，此时进入FIN-WAIT-1状态

第二次挥手，服务端收到报文，这时候进入CLOSE_WATI状态，返回一个报文，ACK=1，ack=u+1，seq=v。客户端收到这个报文之后，直接进入FIN-WAIT-2状态，此时客户端到服务端的连接就释放了。

第三次挥手，服务端发送连接释放报文，FIN=1，ack=u+1，seq=w，服务端进入LAST-ACK状态

第四次挥手，客户端收到连接释放报文之后，发应答报文，ACK=1，ack=w+1，seq=u+1，进入TIME_WAIT状态，等待一会儿客户端进入CLOSED状态，服务端收到报文之后就进入CLOSED状态。

### 4.说说socket通信的原理？

socket就是在传输层里把tcp/ip协议给封装了一下，我们程序员一般都是面向socket来编程的，比如java原生就支持socket网络编程的。

大体来说这个步骤，就是我们搞一个ServerSocket无限等待别人来连接你，然后某个机器要跟你连接，就在本地创建一个socket去连接你，然后建立连接之后，在服务器上，ServerSocket也会创建出来一个socket的。通过客户端的socket跟服务端的socket进行通信，我给你写数据，你读数据，你给我写数据，我读数据，就这个过程。

当然这个底层，比如建立连接和释放连接，都是基于tcp三次握手和四次挥手的规范来搞的，包括基于tcp协议传输数据，其实就跟我们之前说的一样，都是封装个tcp数据包，里面有tcp报头，整了端口号啥的，然后封装在ip数据包里，最后封在以太网数据包里传递。

### 5.说一下http的工作流程？http 1.0、http 1.1、http 2.0具体有哪些区别？

http发起请求的底层原理，大家其实都知道了，理解了那个原理，就一通百通了。那么来聊下http请求和响应的规范吧。其实请求的报文，就是请求头、请求方法、请求正文，GET/POST啥的，应该都知道；请求头，自己百度一下吧，作为一个工程师必须知道。响应，状态行，响应头，响应正文，状态行，200,400,500

http请求封装到应用层数据包，封装在tcp数据包，封装在ip数据包，封装在以太网数据包，如果过大，可能会拆成几个包，走以太网协议+交换机 -> 广播 -> 网关 -> 多个网关 -> 目标的机器 -> 一层一层拆包 -> http请求报文 -> 传递给tomcat -> spring mvc -> http响应 -> 一样的路径会去

最最底层，这个数据如何传输？走的是物理层，网线、光缆，所有数据都是0/1电路信号

http协议，其实是每个搞java必须会的基础。

互联网初期，一般一个网页几乎都没什么图片，当时就是挂一些文字，一个网页里就是一大坨的文字。http 1.0版本。

浏览器 -> 网站，互相之间是先要通过tcp三次握手，建立一个连接，浏览器和网站互相都给对方留出一份资源，浏览器发起http请求 -> tcp -> ip -> 以太网，网站上面去，网站返回一个响应，连接关闭，tcp四次挥手。释放掉浏览器和网站各自给对方保持的一份资源。

http 1.0要指定keep-alive来开启持久连接，默认是短连接，就是浏览器每次请求都要重新建立一次tcp连接，完事儿了就释放tcp连接。早期的网页都很low，没啥东西，就一点文字，就用这个没问题。但是现在，一个网页打开之后，还要加载大量的图片、css、js，这就坑爹了，发送多次请求。

早期，2000年之前，那个时候网页，都很low，当时你打开一个网页，就是说现场底层tcp三次握手，跟网站建立一个tcp连接，然后通过这个tcp连接，发送一次http请求，网站返回一个http响应（网页的html，里面有一大段文字），浏览器收到html渲染成网页，浏览器就走tcp四次挥手，跟网站断开连接了

到了后面，发现说2000之后，2010之后更不用说了，网页发展很迅猛，一个网页包含着大量的css、js、图片等资源。比如你请求一个网页，这个网页的html先过来，过来之后，浏览器再次发起大量的请求去加载css、js、图片，打开一个网页可能浏览器要对网站服务器发送几十次请求。

http 1.0，疯了，刚开始请求网页的html，tcp三次握手建立连接 -> 请求/响应 -> tcp四次挥手断开连接，接着再次要加载css、js、图片，要发送30个请求，上面的过程来30次，30次频繁的建立tcp连接以及释放tcp连接。很慢很慢。

其实最慢的不是说发送请求和获取响应，打开和释放连接，这都是很重的过程

http 1.1默认支持长连接，就是说，浏览器打开一个网页之后，底层的tcp连接就保持着，不会立马断开，之后加载css、js之类的请求，都会基于这个tcp连接来走。http 1.1还支持host头，也就可以支持虚拟主机；而且对断点续传有支持。

浏览器，第一次请求去一个网站的一个页面的时候，就会打开一个tcp连接，接着就在一段时间内都不关闭了，然后接下来这个网页加载css、js、图片大量的请求全部走同一个tcp连接，频繁的发送请求获取响应，最后过了一段时间，这些事儿都完了，然后才会去释放那一个tcp连接。大幅度的提升复杂网页的打开的速度，性能。

http 2.0，支持多路复用，基于一个tcp连接并行发送多个请求以及接收响应，解决了http 1.1对同一时间同一个域名的请求有限制的问题。二进制分帧，将传输数据拆分为更小的帧（数据包），frame（数据包，帧），提高了性能，实现低延迟高吞吐。

### 6.http和https的区别是什么？https的原理是什么？

http协议都是明文的，是没有加密的，所以其实现在一般大部分应用都是用https协议的。之前是基于SSL协议对http进行加密，后来又升级到了TSL协议来加密，现在称之为SSL / TSL吧。

https的工作原理大概是这样的：

（1）浏览器把自己支持的加密规则发送给网站

（2）网站从这套加密规则里选出来一套加密算法和hash算法，然后把自己的身份信息用证书的方式发回给浏览器，证书里有网站地址、加密公钥、证书颁发机构

（3）浏览器验证证书的合法性，然后浏览器地址栏上会出现一把小锁；浏览器接着生成一串随机数密码，然后用证书里的公钥进行加密，这块走的非对称加密；用约定好的hash算法生成握手消息的hash值，然后用密码对消息进行加密，然后把所有东西都发给网站，这块走的是对称加密

（4）网站，从消息里面可以取出来公钥加密后的随机密码，用本地的私钥对消息解密取出来密码，然后用密码解密浏览器发来的握手消息，计算消息的hash值，并验证与浏览器发送过来的hash值是否一致，最后用密码加密一段握手消息，发给浏览器

（5）浏览器解密握手消息，然后计算消息的hash值，如果跟网站发来的hash一样，握手就结束，之后所有的数据都会由之前浏览器生成的随机密码，然后用对称加密来进行进行加密。 常用的非对车呢加密是RSA算法，对称加密是AES、RC4等，hash算法就是MD5

就好比，有个人说我加密的时候是用了一个公钥去加密，然后你解密的时候是用私钥去解密；我加密的时候用的算法，跟解密的时候用的算法，是一样的，对称加密

### 7.什么是长连接？http长连接是什么？

http本身没什么所谓的长连接短连接之说，其实说白了都是http下层的tcp连接是长连接还是短连接，tcp连接保持长连接，那么多个http请求和响应都可以通过一个链接来走。其实http 1.1之后，默认都是走长连接了，就是底层都是一个网页一个tcp连接，一个网页的所有图片、css、js的资源加载，都走底层一个tcp连接，来多次http请求即可。

http 1.0的时候，底层的tcp是短连接，一个网页发起的请求，每个请求都是先tcp三次握手，然后发送请求，获取响应，然后tcp四次挥手断开连接；每个请求，都会先连接再断开。短连接，建立连接之后，发送个请求，直接连接就给断开了

http 1.1，tcp长连接，tcp三次握手，建立了连接，无论有多少次请求都是走一个tcp连接的，走了n多次请求之后，然后tcp连接被释放掉了

### 8.HTTP、TCP、以太网的关系

（1）浏览器发出了一个请求

他一定会通过底层的操作系统，跟对方的服务器进行TCP三次握手，建立TCP连接

接下来，浏览器就会把自己封装好的http请求报文，你可以认为就是一段http协议规范的请求数据，通过底层的tcp流的方式，如果请求报文比较大的话，此时就会拆包，把一段大的数据拆分放到多个TCP包里去

服务器端其实返回http响应，也是通过底层的TCP的连接，以IO流的形式在发送数据，一段很大的HTML页面，这个就肯定会拆分为多个TCP包，每个包里包含一段数据，不可能通过一个大的包来发送

电脑收到多个TCP包，组装起来，成为一个完整的HTML数据，接着就可以在浏览器里渲染显示这个html页面了

如果此时浏览器被关闭，就会断开TCP连接，也就是走四次挥手的过程，断开这个连接

（2）我们自己手工基于Java的Socket进行网络编程，基于TCP协议进行数据传输

连接连接：TCP三次握手

你通过IO流的形式发送数据过去，底层拆分为多个TCP包过去，人家通过IO流的形式给你返回数据回来，底层拆分为多个TCP回来

断开连接：TCP四次挥手

### 9.DNS解析器查询IP

查ip地址，是通过你的电脑上的什么东西去查呢？

就是操作系统的层面提供了Socket库，就可以进行网络相关的一些常见的操作，比如说发送请求到DNS服务器去查询ip地址

DNS服务器是在哪里知道的呢？你的电脑又是怎么知道DNS服务器自己本身的IP地址呢？每台电脑可以自己手动设置一个DNS服务器的地址，当然也可以让电脑自动获取，比如电脑自己预先设置好的DNS服务器地址，这个都没什么问题

全世界有13台根域DNS服务器

（1）任何一台DNS服务器上都有根域DNS服务器的地址

（2）从根域DNS服务器开始多层级顺藤摸瓜往下级DNS服务器去找

（3）每台DNS服务器都有缓存的功能

### 10.无线局域网和以太网之间关系？

现在我们家里用的路由器其实都是集成了集线器、交换机和路由器的功能的，他是一个综合的东西，之前我们说过，所有电脑发出去的网络请求，其实都是按照几层网络模型来封装数据包

比如说按照tcp协议封装一个包，再封装到ip包里去，最后封装到以太网包里去，这个以太网层面都是有mac地址的，会写在包头里，表明了目标设备的mac地址，接着这个以太网包就会通过电脑的网卡发送出去

这个网卡就会负责把我们的数据包转换为电路信号，就是0101之类的电信号，通过正负电极来做的，这个电路信号也是按照以太网的协议来进行分割，这样电路信号就可以表示出完整的以太网数据包的内容了

然后电信号会通过无线网传输到路由器，路由器里面有一个集线器的功能，这个集线器就是负责把这个数据包广播给子网内的所有设备，这里就是指路由器本身包含的交换机功能，交换机收到这个数据包之后

他会根据mac地址表做一个转发，就是根据你的目标mac地址转发到对应的端口上去，你大概就认为是转发给路由器吧，路由器会根据目标地址和自己本身的mac地址判断一下，发现是自己的包，就会接收这个包

这里大家要注意的一点是，路由器里的交换机的这个功能，实际上是基于mac地址实现的，不知道大家发现了没有，也就是基于以太网协议工作的，属于子网内的通信方式，他是通过集线器功能广播出去数据包

各个设备（比如交换机，路由器）都是根据目标mac地址判断是不是应该自己接收的，所以一定要注意这一点

而且这里要注意的一点，比如你是通过以太网网卡和网线连接路由器的，那么此时就是封装以太网包然后通过以太网网卡发包出去到集线器，然后广播给路由器，路由器网卡接收电路信号，转换为数字信号，根据mac地质判断是自己的包

如果你的笔记本电脑走的是无线网呢？其实是类似的，只不过tcp包封在ip包里，然后ip包就不是封在以太网包里了，是封在无线局域网协议规定格式的包里，然后这个包通过无线网卡发出去，发到路由器上的同样是无线网卡上

所以无论底层是什么样的联网方式，其实本质都是类似的

假设如果我们家里的电脑是通过网线跟路由器连接的，那么可以做以太网协议，按照以太网协议封装好以太网的包，在包头里写上mac地址，发送到交换机上去，转发到路由器上，之间是通过网线连接的

如果是家里走的是无线局域网呢？笔记本电脑跟路由器之间是不走网线的

无线局域网跟以太网是一个层次的协议，都是数据链路层的协议，走的是不同的底层网络数据传输的方式，你的电脑就会具备一个无线网网卡，可以支持不同的上网方式的。家用电脑，支持的就是两种，以太网网卡，无线局域网网卡，走两种不同的协议发网络数据包出去，到路由器上

### 11.ARP广播获取路由器mac地址以及ARP缓存机制

比如说我们一般是知道，在自己的笔记本电脑上都会配置一个网关的ip地址，实际上来说就是路由器的网卡的ip地址，同时还有一个mac地址，所以说，我们现在假设仅仅知道他的ip地址，那如何知道路由器网卡的mac地址呢？

ARP机制，就是在电脑上，ARP功能，会在子网内广播一下，找各个设备，问他们呢，你们的ip地址和mac地址的对应的关系能否告知我一下？路由器就会反过来告诉ARP机制，说我的ip地址和mac地址对应关系

ARP机制会自动缓存ip和mac的对应关系

电脑就知道路由网关的网卡ip地址和mac地址之间的关系了

### 12.全双工和半双工

全双工和半双工，主要发生在路由器的交换机的这块功能里，如果是全双工，就是说发送数据和接收数据可以同时进行；如果是半双工，那么要么这一时刻只能发送数据，要么这一时刻只能接收数据

如果是工作在半双工的情况下，那么需要先判断是否有数据接入进来，避免发生信号碰撞的问题，要等一个方向的数据线过去了，自己才能把数据发出去；如果是全双工的话，不需要判断信号碰撞的问题，直接把数据数据发送出去好了，因为可以同时接收数据和发送数据，在全双工模式下

以太网网络层面处于半双工的工作模式

全双工的意思：同时在网络硬件设备的层面，有人可以发包过去，还有人可以传包回来

这就是他们的区别

### 13.粘包和拆包

就是说是这样子的，本来两个包应该是属于独立的两块的数据，但是此时服务器一下子收到了两个包，把里面的数据认为是一块数据，处理的时候，合并起来处理，两个包粘在一起了，数据出现错误

拆包，服务器先收到了一个包的一半的数据，然后又收到了这个包的另外一半的数据，如果说刚收到前一半的数据就开始处理，肯定是不对的，拆包，这也是一个常见的网络问题，netty的时候

### 14.为什么说交换机工作在以太网层而路由器工作在IP层？

路由器通过一个端口接收到了以太网包之后，会根据mac地址判断是否是转发给自己的包，如果是的话，他就会拆开以太网包，看里面的IP包的ip地址，根据ip地址来转发给自己连接的其他子网的路由器

所以这里非常关键的一点，就是路由器是工作在IP协议层的，他是基于IP协议来的，跟交换机不一样，交换机是工作在以太网协议层的，是基于以太网协议工作的

然后根据下一个路由器的ip地址查找对应的mac地址

路由器之间传输数据，其实也是很简单的，假设也是通过以太网方式来转发数据，那么就是给数据包加上下一个目标路由器的mac地址，接着发送到下一个路由器即可，这个时候会把数据包再次转换为电路信号发送出去

下一个路由器你可以想想肯定也是交换机先接收到数据包的，因为通过以太网协议和mac地址，让下一个路由器的交换机部分收到数据包，根据mac地址转发给下一个路由器，下一个路由器比对一下mac地址发现是给自己的

接着各个路由器之间都按照一样的思路不停的转发，最后一直转发到目标ip地址所在的子网的路由器上去，那个子网路由器再转发给目标的web服务器

这里的话要注意几个要点，一个是这里路由器再发送网络包的时候，其实是会自动拆包的，就是可能会把大的数据包再次拆分为小的包去发送，这是一个，大家需要注意一下

然后这里还有一个问题，假如说你的家用路由器跟下一个路由器之间是通过无线网连接的，或者是ADSL线路连接的，不是以太网连接的，那怎么办呢？其实很简单，你的路由器接收到数据之后，肯定会从里面拿出来ip地址，因为路由器的工作都是依托ip地址来的

接着假如说你是走以太网发送数据到下一个路由器，那就根据以太网协议，查询下一个路由器的ip地址对应的mac地址，然后通过以太网协议发送数据出去，这里会走一个广播的方式，广播到下一个路由器去

下一个路由器的交换机接收到了再转发给路由器，根据mac地址判断是自己的包，这都是走以太网协议的，对吧

那么如果是无线局域网或者是ADSL线路呢？那路由器就根据ip地址找到下一个路由器的ip地址，然后通过无线局域网的规范，或者是网络线路的规范，把数据转换为指定的格式，按照协议封装数据，接着转换为电路信号发送出去就可以了

### 15.家里的调制解调器（Modem）是怎么接入运营商网络的？

一般我们家里上网，都是找某个运营商，比如联通，移动，电信之类的，然后上门装个Modem也就是调制解调器，这个大家应该都有印象吧，一般国内我们管那个东西叫做“猫”，这个就是我们家里的路由器可以联网的关键

之前说到路由器收到数据包以后会再次转化为电路信号发送出去，那么发送给谁呢？其实就是这个Modem，只要在数据包上写Modem设备的mac地址，就可以通过以太网协议给发过去

这个Modem收到数据包之后，其实会干一个事儿，就是把数据包拆成一个一个很小的单位，叫做信元，接着就是把这个信元再次转换为电路信号，然后就会通过Modem直接连的网线，比如有的地方不知道大家见过没有，网线是在电线杆上的

当然现在很多地方这个网线都埋到地下去了，接着会通过网线发送到运营商的电话局里去，然后就是进入互联网了，也就是转发到下一个路由器，这个一般是运营商的路由器，然后路由器之间都是类似的转发操作在里面

## NIO

### 1.NIO

Buffer缓冲区

如果你要通过NIO写数据到文件或者网络，或者是从文件和网络读取数据出来，此时就需要通过Buffer缓冲区来进行

有4个概念：capacity、limit、position、mark

capacity

缓冲区的容量大小，就是里面包含的数据的大小

```html
byte[] data = new byte[]{1, 2, 3};
ByteBuffer buffer = ByteBuffer.wrap(data);
System.out.println(buffer.capacity());
```

这里可以看到这个ByteBuffer的capacity是3，因为里面的字节数组的大小是3

limit

limit这个概念，就是对Buffer缓冲区使用的一个限制，就是说从这个index开始就不能读写数据了，默认情况下limit是跟capacity一样，限制你最多读取capacity容量内的数据，比如上面有3个数据，此时用下面的代码可以进行限制

```html
buffer.limit(1);
System.out.println(buffer.limit());
```

这就是说从index = 1的位置开始就不能读取和写入了，可以通过CharArray来演示一下，使用put方法即可

position

位置，就是代表了数组中可以开始读写的index，不能大于limit，可以通过CharArray来演示一下，使用put方法即可，他会随着读写一直自动推进，直到跟limit一样，就不让你读了，如果手动设置的position大于了limit，那么自动把limit设置为position

remaining，代表的是position到limit之间的距离

mark

类似路标的东西，在某个position的时候，设置一下mark，此时就可以设置一个标记，后续调用reset()方法可以把position复位到当时设置的那个mark上去，把position或limit调整为小于mark的值时，就丢弃这个mark

### 2.如何分配一个Buffer缓冲区以及读写其中数据？

ByteBuffer.allocateDirect(100)：这可以分配一个Direct缓冲区，效率更高

ByteBuffer.wrap(byte[] array)：这就是把你已经有的一个byte数组，作为核心数据放到缓冲区里去

position = 0

capacity = 数组大小

limit = capacity

put(byte b)和get()：这两个就是说对当前position位置放入一个数据，或者读取一个数据

put(byte[] src, int offset, int length)和get(byte[] dst, int offset, int length)：类似上面的，把指定src数组里的一段数据写入缓冲区，或者是从缓冲区里读取数据到数组中

put(byte[] src)和get(byte[] dst)：类似上面那样，就是把数组全部写入缓冲区，以及从缓冲区读取全部数据到数组里去

### 3.如何调用Buffer API操作缓冲区的？

clear()，还原缓冲区里的状态，position设置为0，limit设置为capacity，丢弃mark，但是本质不是删除数据，就是还原那些标记位罢了，因为还原之后就可以复用缓冲区里的空间，覆盖老的数据了

flip()，准备读取刚写入的数据，就是将limit设置为当前position，将position设置为0，丢弃mark。一般就是先写入数据，接着准备从0开始读这段数据，就可以用flip

rewind()，将position设置为0，并且丢弃mark。一般先读取了一遍数据，接着想要再次重新读取一遍数据，这个时候可以用rewind，此时limit是不变的

所以其实一般其实比较少遇到说直接操作Buffer的position、limit和mark之类的，很少。通常都是上述几个方法，直接往里面写入数据，然后打算复用的时候，就clear()，重新可以写数据；如果写了一段数据打算要读取了，此时可以flip()；如果希望重新读取一遍数据，可以rewind()

### 4.FileChannel

顺序写磁盘文件，不停的基于FileChannel写数据，就是在文件末尾不停的追加数据。

多线程同步并发安全的

他一定是一个线程先执行完了写文件，hello world；下一个线程才能有机会去写；不可能多个线程同时基于一个FileChannel来写的

基于synchronized做线程同步的，他就可以保证多线程调用同一个流的getChannel()方法的时候，他是可以保证多线程并发安全的

文件锁

比如说在一个jvm内，是可以通过多个线程就使用一个FileChannel来写，是线程安全的，那如果是多个jvm呢？此时就没办法保证多线程按照顺序来写文件了，并发写文件，可能会有问题的

所以可能会导致文件里的数据出错，混乱

FileChannel给我们提供了一个功能，就是所谓的文件锁，你可以对文件上锁，共享锁，独占锁，如果对文件是上共享锁的话，此时你可以读文件，别人也可以读文件，别人也可以上共享锁

但是没人可以写文件，包括你在内

别人无法加独占锁，别人只能上共享锁，大家都持有对文件的共享锁

不能写数据到文件里去，只能读

现在因为有人加了锁，所以此时你读不到数据的，你必须也加一个文件共享锁，此时才能从里面去读取出来数据，但是写数据是肯定不行的，所有人都可以读文件里的数据

他加锁是可以支持针对文件的position开始的size字节数，分段加锁，就对文件的某个段（region），进行加锁。这个东西是跟底层的操作系统是有关系的，如果操作系统不支持共享锁，就会自动转换为独占锁

如果使用FileChannel对文件上独占锁有什么作用

如果有人上了独占锁，别人就不可以上独占锁了，也不能上共享锁，这个时候只能是上独占锁的人自己可以读和写，其他人应该就不可以读和写了

用FileChannel真可以立即写入数据到磁盘吗？

你通过FileChannel写数据到磁盘文件的时候，是立即数据可以写到磁盘上吗？不是的，刚写完以后，数据其实是停留在os cache上的，操作系统自己管理的一个内存区域，是一个读写的内存缓冲区

往磁盘文件写数据的时候，他实现落到os cache上的

如果说此时机器宕机，那么os cache里的数据可能就会丢失了，内存里面

如果写磁盘的时候，不是立马落地到磁盘上去，是先落地到os cache上去，此时最大的好处，就是性能高，让磁盘写的性能比较高

kafka、elasticsearch，写数据到磁盘的时候，都是先写入os cache的，后面的操作系统自己不定时的会决定把os cache里的数据写入到磁盘上去，希望数据立马可以写入磁盘上，就不能光是用FileChannel.write()

FileChannel.write方法

FileChannel.write方法在干什么事情

FileChannelImpl是JDK内核的一个类，那个源码直接看是看不到的，也没必要去细看，并发底层，synchronized实现，volatile实现，IO流的实现，Socket的实现，其实底层很多都是基于c来写的，而且都是跟操作系统，硬件去打交道的

FileChannel是有一个position的概念，指针，是指向了当前文件的某个位置，所以说你写数据的时候是从当前position开始写数据的，你写入文件之后，文件会不断的变大，容纳你写入进去的一些数据

你写了多少bytes的数据，文件的position就会往前推移多少位

他一定是从buffer里读取数据（你需要调整好buffer里面的数据的标志位，position，limit），写入底层的文件，position，从position开始写，写了多少数据之后，就会顺便递增FileChannel的position

如果写文件的时候，RandomAccessFile设置的是append追加的模式，FileChannel的position刚开始就是在文件的末尾，大家应该知道，完全可以去百度一下看看

FileChannel从磁盘读取数据到内存

对FileChannel底层有一个非常关键以及核心的概念：position

读数据，是从File当前的position开始读的，每次你刚开始比如说你要是初始化了一个FileChannel之后，position是从0开始的，所以你自然就可以读到从0开始的文件里的一些数据

如果你要随机读取文件里的某个位置，直接设置和定位FileChannel的position，就可以限定是从什么位置开始读数据，就可以随机读取文件里的某一段数据。你读取出来了多少字节的数据，FileChannel的position就会往前推移多少位

如果你用FileChannel写数据的话，刚开始position也是0，如果你直接写数据，很可能是会覆盖掉原来的老数据的

### 5.多线程读写磁盘文件如何同步

多个线程并发的写磁盘的时候，通过FIleChannel并发写的时候，底层是如何实现同步的？FileChannelImpl这个类，是源码不太方便看，猜测一下大概都知道，在调用和执行FileChannel.write()方法的时候，这个里面一定是有多线程并发同步的代码的，他可以保证同时间只有一个线程在执行底层的文件写逻辑

NIO核心原理剖析

看的主要是一些接口源码和注释，去给分析一下他底层工作的一些原理，FileChannel的position，还有一个就是Buffer的position和limit，这些东西是如何配合起来使用的，你要自己好好去体会一下

底层一定是做了多线程同步的，只有一个线程可以写磁盘文件

### 6.NIO是如何基于多路复用技术支持海量客户端的？

NIO里就三大核心组件：Buffer、Channel、Selector

其中Buffer就是封装数据的，主要是把数据写入Buffer，或者从Buffer里读数据

Channel就是一个数据管道，他是负责数据传输的，把Buffer给Channel，他可以负责传输数据，比如把数据写入文件，或者从文件读取数据；还可以把数据写入网络，或者从网络读取数据

最后就是一个Selector，他是多路复用组件，专门用在网络编程里的

不需要给每个Socket连接都创建一个线程，不需要每个Channel就创建一个线程，完全可以用一个Selector来多路复用监听N多个Channel是否有请求，这里是基于操作系统底层的select通知机制的，不是轮询各个channel

这样可以避免创建大量的线程

如果说是通过传统的socket编程来解决这个问题，可能比如说1000个客户端需要1000个线程，但是此时通过NIO网络编程模型来是实现的，线程池里就10个线程，就可以完美的处理1000个客户端的请求了

### 7.Selector如何注册Channel

1、第一次注册：会走底层的类库，把channel和感兴趣的key注册到selector里去

2、keys数组：他会自动初始化，每个channel感兴趣的key，都会放到keys数组里面去

3、一个channel反复注册：本质就是改变keys数组里的那个感兴趣的操作而已

4、keys数组的扩容：如果keys数组越来越多的话，此时就会自动每次乘以2倍来进行扩容

### 8.反向通知机制

linux select机制，他可以让你一个线程可以监听多个socket是否有请求发送进来

每个channel都对应一个SelectionKey，大致可以表明的是说，我们对某一个channel感兴趣的操作，还有的话呢，通过这个key可以唯一反向获取到对应的channel

selector.select()机制，猜测一下都知道了

底层一定是基于操作系统的类库来实现对多个socket的一个监听，如果某个socket有对应的请求进来了，此时他对应的channel就可以执行某个操作了，每个channel是对应着一个key的

select()方法，他会感知到哪些channel底层的socket有请求进来了，可以执行IO操作来读取数据或者发送数据出去了，他就会把那些channel对应的key的集合，给你返回回来了，他会干这么一件事情

这个方法他是阻塞的，如果没感知到哪个channel对应的socket可以执行读写操作的话，此时他就会卡着，阻塞着，一直等待某个channel可以写数据，或者是可以读数据了

## 分布式文件系统

### 1.Master-Slave架构

（1）Master负责管控集群，Slave负责管控某台机器上的数据

（2）Slave必须不停的发送心跳给Master

（3）Master如果发现某个Slave一段时间内没上报心跳，此时认为他宕机

最最核心的一点就是心跳机制，heartbeat机制，euerka那块的时候已经看到了，每个服务实例都是一个eureka client，他会负责不停的上报心跳给euerka server来证明自己还存活着

如果eureka server一段时间过后发现某个euerka client一直没上报心跳，就会认为那个服务实例已经死掉了，此时就会从服务注册表里摘除这个服务实例，其他的服务会不停的来拉取最新的服务注册表，此时感知到某个服务实例宕机之后，其他服务就不会再去访问那个宕机的服务实例了

### 2.分布式文件系统

目录的管理，文件的管理

目录：创建目录、删除目录、重命名目录，目录是不是有层级结构的，是一个树形的概念

文件：上传文件到某个目录里去，删除文件，对文件进行重命名，下载文件（读取文件）

分布式文件系统，是不是需要一套元数据，专门维护说你的文件系统里有哪些目录层级的结构？每个目录下面有没有挂载哪些文件？文件目录树

双缓冲机制

edits log，他只是一条日志，修改日志，他就是说明了他本次对文件目录树做了什么修改

如果此时namenode宕机了，会怎么样？不要紧的，磁盘文件里存有一份edtislog的数据，如果你重启namenode，就可以读取全部的editslog来回访日志，重新把日志对应的操作在内存文件目录树上执行一遍，此时就可以恢复出来一份完整的数据

因为edits log会先在内存缓冲里等待一会儿，所以说此时，如果 有些edits log还没刷入磁盘，此时就宕机了，会导致内存缓冲里的部分数据会丢失，如果namenode宕机，是可能会导致部分数据丢失的

分段存储机制

假设你频繁的更新文件目录树，此时有几千万条editslog都放在一个文件里，如果一个文件过大的话，可能还会导致读写性能的下降

一般来说磁盘文件，editslog会不断的增长的话，一般都是会采取分段存储的机制，先写入一个文件，如果说这个文件的大小达到了一定的数量之后，此时就会拆分出来一个新的文件，一般来说建议单个日志文件的大小不要超过1GB

editslog机制的弊端分析：耗时过长的Master重启

比如说现在你的editslog里都有几千万条日志了，此时你的NameNode一旦重启，你需要从磁盘上读出来几千万条日志，一条一条在内存里执行回放一遍，比如说一开始先是创建某个目录，创建文件，删除文件

可能会导致你的NameNode重启的时候需要耗时几个小时都有可能

基于fsimage和checkpoint机制优化Master重启性能

重启过慢，每次重启都要回放所有的edits log机制

假设在晚上8:00的时候，突然执行了一次checkpoint操作，NameNode把一份完整的文件目录树写入到了磁盘上的fsimage里去，接着8:10，8:00~8:10之间，一共做出了几十条editslog的变更日志

此时NameNode需要重启，他会直接读取fsimage文件加载到内存里变成文件目录树，接着把edits log文件里的几十条editslog读出来，在内存的文件目录树里回放一遍

比如说你的有一个目录，/usr目录

在fsimage里只有一条数据，但是在editslog里就不只是一条了，创建操作，更新操作，重命名操作，在editslog里有多条操作日志

优化Master机器的CPU负载：Backup节点的引入

NameNode所在的机器做的磁盘IO的操作太多了

NameNode进程，他需要额外分配出来一个线程，后台线程定时的去进行磁盘IO的操作，其实这个是很影响本地CPU负载的，如果你一边大量的线程需要来更新内存的文件目录树，肯定是要加锁的

此时如果你还要每隔一段时间，耗费比如说几秒钟甚至几分钟的时间也对文件目录树来加锁读取数据写入本地磁盘，会导致更新文件目录树，和读取文件目录树写入磁盘，他们之间会产生巨大的锁的冲突

冷备份

引入BackupNode可以作为冷备份的解决方案

冷备份：每隔一段时间可以去备份一下数据，每次恢复数据就是一部分，有些最新的数据一定是会丢失的

热备份：几乎是实时的在同步数据到其他的机器上去，如果说这台机器宕机，其他机器可以立马切换过来接管所有的操作

基于NIO FileChannel将内存缓冲数据写入磁盘文件中

editslog日志在磁盘文件上进行分段存储的机制设计

editslog如果都在一个文件里，那么如果后续做了checkpoint操作之后，你需要把checkpoint时间点之前的editslog都删了，此时怎么删呢？所有的数据都在一个文件里，你这样子是非常的不好删的

按照细粒度的方式把editslog可以拆分为很多个日志文件

每一次你刷磁盘的时候都是刷一个新的editslog日志文件，日志文件的名字就是txid~txid.log，格式，是最好的。如果你checkpoint之后要删除一些editslog日志文件，完全可以就把之前的一些文件给物理删除即可

每次在落地磁盘的时候，都是把上一次落地磁盘的最大的一个txid+1

0~500.log

501~1000.log

1001~1500.log

每次落地磁盘都记录好本次落地的时候，最大的txid是多少，下一次落地磁盘就可以取出来进行命名就可以了，每次落地磁盘都是一个新的日志文件

25kb，50字节，500条数据就会刷一次盘，500条数据就在一个日志文件里面，后面删除的时候也就方便很多了

### 3.editslog同步机制设计

（1）pull模型

pull模型，不会对NameNode造成太大的影响，被动去接收请求，每次最多就是在内存里缓存一小块的数据，供BackupNode来拉取；如果BackupNode有问题，那么他是不会影响到NameNode

NameNode主动push给BackupNode，很可能会被BackupNode一些异常的情况给影响，导致NameNode可能会有不稳定的问题；pull模型，BackupNode一旦异常，大不了就是不发送请求过来拉取日志，但是对NameNode是没影响的

（2）批量拉取editslog

批量拉取，这个你可以结合具体的情况，比如说我们这里设定的是每次批量拉取10条数据，但是你也可以搞的大一些，每次批量拉取20条，30条，可配置化的，就可以提升edits log同步的性能

（3）缓存机制

每次NameNode端都会在内存里缓存一块数据，要么是内存缓冲里的数据，要么是某个磁盘文件的数据，每个磁盘文件也就25kb，所以最多就是缓存25kb的数据。大部分的拉取，都是直接从缓存里走

不用频繁的读取磁盘文件，也不用频繁的申请锁去读取内存缓冲的数据

（4）低成本解决并发冲突问题

大部分的请求都是走内存缓存，避免去竞争锁拉取内存缓冲的数据；对于ArrayList写，读，不要去加锁，CopyOnWriteArrayList，读是读快照，写的时候也是基于多个快照版本来进行更新的

（5）效果

基本上来说，90%的请求都是走内存缓存，不需要读磁盘，不需要竞争锁；少量的请求会读磁盘文件，或者竞争锁从内存缓冲加载数据出来；BackupNode几乎是可以实时的跟上NameNode editslog的变化

### 4.集群

副本

比如说hadoop hdfs，默认就是3个副本，是有一个规律的，假设你的集群的所有的机器是假设到多个机架上的，机房和机架的关系，其中2个副本是在一个机架上，另外一个副本是在别的机架上

默认情况下，如果是一个机架里的某台机器宕机了，此时可以使用这个机架上的另外一台服务器上的副本就可以了；万一说这个机架都故障了，此时别的机架上还有一个副本冗余是可以用的

提高可用性的级别，万一某个机架都故障了，其他机架上有副本可以用

3个副本的优点，就是可以实现更高的可用性，缺点，对存储空间的占用太多了

双副本，一个图片就存储两份，在两台机器上就可以了，对于可用性而言也可以保证，一般来说比较多的故障就是某台机器故障，但是其他机器上还有图片的副本可以使用，保证了系统的可用性

资源均匀负载

尽可能得让集群里的各个机器上存放的数据是比较均匀的负载的

30TB的数据，4台机器

一台机器上放了20TB的数据，另外三台机器，每台机器放3TB多一点的数据。要实现集群里的存储资源的均匀使用，每台机器的存储的数据量大概在7TB~8TB之间

构思一下这个里面的思路，首先呢，必须是要知道，每台机器上放了多少数据量的文件，我现在需要知道的是机器01上存放了5TB的数据，机器02上存放了5.3TB的数据，机器03上存放了6TB的数据，机器04上存放了6.1TB的数据

比如说来了一个图片上传的请求，我应该把图片的2个副本上传到哪两台机器上去呢？把机器上面的数据量的大小正序来排序，选择数据量最小的两台机器就可以了，各个机器的存储的数据量基本是均匀的

## Netty

### 1.优点

NIO框架：Netty，封装了底层很多复杂的网络通信细节，让你开发程序非常的简单，它提供了很多的高阶的功能，可以让你基于他开发出来非常复杂的网络通信程序

NIO API，有点复杂，Selector、Channel、SelectionKey、Buffer

Netty简化了网络编程的API

数据传输，直接基于Buffer封装成二进制字节流的数据格式，网络通信的时候，需要支持不同的协议，而且可以对自定义的数据结构进行编码和解码，Netty都支持了

Netty还提供了很灵活的扩展的功能

Netty：高性能、高并发/高吞吐、高可靠

Netty：大量的商业项目都使用了Netty，所以经过了复杂生产环境的验证，基本上来说作为一个开源项目非常的成熟

### 2.EventLoopGroup

EventLoopGroup，本质在底层就是一个线程池的这么一个东西，可以让你从里面获取新的线程，以及他会负责管理这些线程的生命周期

他的线程池里的默认的线程数量，实际上就是你的机器可用的cpu核的数量 * 2，比如说你是4核8G的机器，那么默认线程池的线程数量就是8个，最小最小也得是1，起码线程池里得有1个线程

ThreadFactory是null，肯定是会用默认的机制去创建新的线程出来

ThreadPerTaskExecutor + 默认的ThreadFactory

你有多少个线程，就会对应一个EventExecutor数组，每个线程就对应一个EventExecutor

EventLoopGroup线程池是如何进行初始化的？

每个线程就对应了一个NioEventLoop

很多的线程，每个线程叫做NioEventLoop，每个线程都会负责一部分的客户端连接的SocketChannel，对这些SocketChannel都会注册在线程自己的Selector中，每个线程通过自己的Selector去轮询（Loop）他负责的这一批客户端连接的网络请求事件

NioEventLoop，负责轮询Nio事件的线程，轮询多个客户端连接的Nio事件

线程池的初始化，NioEventLoopGroup，cpu核 * 2 = 线程数量，每个线程就对应一个NioEventLoop，有一个自己的Selector，每个线程就通过Selector负责一批SocketChannel（客户端连接）的Nio网络事件的轮询

### 3.ServerSocketChannel

event loop，轮询网络事件，线程

这里面的东西肯定是负责通过一个Selector去轮询多个网络连接的事件

ServerSocketChannel -> 端口号，然后通过一个独立的线程（Acceptor）去使用Selector去轮询这个ServerSocketChannel是否有连接的事件接入，如果有的话，跟客户端建立连接，然后将客户端的连接分发给Processor线程

每个Processor线程应该是负责处理一部分客户端的连接，使用自己的Selector不断的轮询各个客户端连接的网络事件，收到了请求解析出来

请求应该是交给Handler线程去进行处理，处理请求，设置响应

Processor把响应发送给对应的客户端就可以了

### 4.架构

高并发架构设计：两层线程模型、NIO多路复用非阻塞、无锁串行化、并发优化

高性能架构设计：Protobuf序列化协议、direct buffer、bytebuf内存池、网络参数优化

高可靠架构设计：网络连接断开、网络链路探查、NioEventLoop线程容错、JDK epoll bug处理、内存块自动释放

可扩展架构设计：handler链条你可以自己扩展、序列化协议、定制网络通信协议

## IM系统

### 1.架构

应用层：IM系统可以支持很多业务的，客服系统，销售系统，类似钉钉的企业内部的IM应用

API层：客服系统（电商APP，客服系统客户端模块，客服系统服务端模块）

客服系统 -> android客户端模块，嵌入在电商APP里的，在电商APP里你打开客服功能模块，相当于就是运行客服系统的android客户端模块，android客户端模块就需要跟IM系统进行连接的建立，接下来才能准备去发起一个会话，发送消息到IM系统去

客服系统 -> 服务器端模块，带着网页的，平时你看到的一些客服都是坐在电脑前面的，打开客服系统的网页，就应该要去跟IM系统建立一个连接，等待有人发送消息到IM系统，IM系统再推送给客服系统的网页上去

接入层：IM系统而言，必须得跟人家进行连接的建立，这个连接建立的过程，接收请求，返回响应，网络通信的东西，都封装在这一层

功能层：IM系统是提供很多的功能，接收消息，推送消息，群聊，红包，离线消息，安全认证，类似于这样的一些功能，很多的

存储层：两种消息存储，第一种比如说是即时性的消息，当前正在聊天的时候，大家比较关注的都是最新的一些100条消息，这些消息可以存放在Redis中；离线消息，昨天、或者几天以前、几个月以前、几年以前的消息，平时正常来说都不怎么需要看的，可以存放在MySQL数据库里，HBase大数据存储中

### 2.客户端关闭、重复登录的时候应该如何处理？

已经建立好连接的客户端关闭，网页关闭

一般来说玩儿这种客服系统的APP，点击联系客服的按钮，打开客服模块，跟IM系统建立连接，发送一些消息过去，从客服模块里退出来，或者是点击客服模块里有一个“咨询完毕”的按钮，直接从APP里退出，或者是长时间没有使用客服模块

代表你要跟IM系统断开连接了

主动，被动，客服模块长时间发现你没有发送消息，直接自动在底层断开连接，释放资源，直接从APP里退出，此时也会导致建立好的连接断开

用户登出的场景，跟IM系统建立好连接了，IM系统断开连接

一个用户在一个APP上已经登录了，跟IM系统建立了连接，此时他在另外一个手机上登录了一个APP，或者网页上登录了，重复登录的，IM系统要识别出来重复登录的场景，把之前登录的那个设备（APP、网页）的连接断开

重新跟最新的登录的设备建立连接，保证不要对一个用户建立多个重复的连接

### 3.单聊功能

单聊功能，你一个请求发送过来，必然是会带上是要发送个谁的，是业务系统自己决定的，客服系统，销售系统，类似钉钉的IM工具

IM系统收到消息之后会进行存储，单聊功能就实现完毕了

消息如何进行推送，是由另外的一个功能模块，推送服务，从kafka里消费出来这个消息，决定是否当前要把消息推送给对方去，找到对应的连接，从这个连接中发送消息过去，就可以了

### 4.群聊功能

群聊功能是有点复杂的，很多人在一个群里，你发送了一条消息之后，别人都可以看到，别人发送了一条消息之后，你也可以看到

写扩散机制

你发送一条消息之后，是会在数据存储中写多份的，对群里的每个其他的人都会写一条数据，别人一旦登录之类的，可以查看属于自己的未读的消息，他就可以把属于自己的消息，都楼出来，自己就可以看到了

IM系统也得维护一下，创建一个群聊，一旦创建了群聊之后，就维护一条群聊的数据，里面包含了哪些人，包括群聊可以提供很多的功能，包括从群里踢人，艾特某个人，很多的，功能太多了

现在任何一个人在群里发送一条消息，写入到IM系统里，IM系统的群聊功能就得走一个写扩散的机制，把这个消息给群里所有人都写一份，群里所有人都可以在APP客户端里瞬间看到别人发送的一条消息

APP里的群聊对话框，里面很多的消息不停的弹出来，一条一条的

### 5.基于Netty进行双向通信

如果是支持社交的功能，多个使用APP的C端用户，他们可能会建立一个群聊，在群聊里，他们可以进行IM即时通讯

Netty服务端可以接收客户端发送过来的消息，也可以反向推送消息回客户端去

就是我们的Netty服务端每次都是在接收到客户端的请求之后应答一个响应回去，他没有办法主动推送一个消息给客户端去

网络通信的双向通信的架构给搞出来

底层的网络连接通过Netty建立好了之后，其实应该是客户端发送一个token过来，进行认证，服务端对token认证过后，才能认为连接建立完毕的，否则token认证失败的话，此时就应该关闭这个连接

一旦token认证成功了之后，是不是就可以在服务端把这个客户端的连接给缓存起来

## 自研分布式微服务注册中心

### 1.Eureka、ZooKeeper、Consul等服务注册中心有什么问题

第一个问题，默认的参数配置下，服务发现的速度是很慢的，一般来说要几十秒或者几分钟才能发现一个新的服务，或者感知到一个服务的下线。可以通过配置他的各种参数，让他的服务发现和故障感知的时效性提高到1s以内

比如eureka有3台机器，你90个服务实例，30个服务实例对eureka01发起请求，30个服务实例对eureka02发起请求，30个服务实例对eureka03发起请求，eureka01要同步给eureka02和eureka03，90个服务他们每秒比如发起大量的请求，eureka每台机器都要承受所有服务的请求，服务实例越来越多，每秒会有心跳，还会有拉取注册表，eureka单机就会出现性能瓶颈，超过他单机能承载的一个最大的量了

服务发现和故障感知 -> 其他所有的服务都要监听zk里一个znode的子节点的变化，如果有子节点变化，那么zk就会反向通知所有的其他服务说，有服务变化了，可能是上线、下线、崩溃

zk最多就是给几百个或者上千个服务实例反向推送变化的服务注册表的数据，量也不是很大，100KB，瞬间反向推送给几百个上千个服务实例，瞬间会通过网卡输出最多上百MB的数据出去

频繁的服务上线和下线，会导致zk频繁的打爆自己的网卡，不可能在1秒内就全部推送出去，慢慢推送，网卡被打爆掉，甚至会影响zk集群间的通信，zk可能会不稳定，甚至挂掉；或者是服务注册的时候就会遇到zk的报错，zk会极为的不稳定

### 2.Raft协议：什么是分布式一致性协议

（1）集群里多台机器，只有一个人可以接收写入请求，他就是leader，集群需要选举出来一个人当做leader

（2）leader收到写入请求之后，需要采取一定的方案同步给集群里其他的机器

（3）如果leader崩溃掉了，其他的机器就会重新选举出来一个leader

划分出来一个主从的角色，leader、follower

### 3.Raft协议：如何实现Leader选举？

启动了之后，一般来说，3台机器，每个人都会投票给自己，选举自己当选为leader，他对自己的投票会发给其他的机器，选不出来leader，3台机器，最起码需要2条机器，大多数人都认可你当leader，你才可以当选为leader

Raft协议，如果一轮投票，发现大家没有选举出来一个leader，此时如何呢？大家都走一个随机时间的等待，timeout时间过后，再次发起第二轮选举。机器01选择休眠等待3秒钟，机器02选择休眠等待1.5秒钟，机器03选择休眠等待4秒钟

第二轮选举的时候，机器02先苏醒过来，发现进入了第二轮投票，他发现此时没有人发送选票给他，他就还是选举自己当做leader，发送给了机器01和机器03

机器02：投票给自己，机器02，机器02

机器01：机器02，投票给机器02，机器02

机器03：机器02，机器02，投票给机器02

大家发现选票都投完了，发现超过半数的人（全票）都投给了机器02，此时机器02当选为leader，Raft协议本质就是通过随机休眠时间保证说一定会在某一轮中投票出来一个人当选为leader

### 4.Raft协议：2PC与过半写机制

心跳：每个服务定期发送心跳给leader，如果发现某个服务超过一定时间没有发送心跳，自动认为他宕机了

刚开始leader受到一个注册请求，uncommitted，他把这个uncommitted请求发送给各个follower，作为第一个阶段，各个follower收到uncommitted请求之后，返回ack给leader，如果leader收到了超过半数的follower的ack

此时leader就把这个请求标记为committed，同时发送committed请求给所有的follower，让他们也对消息进行committed

跟zk的ZAB协议是一致的

### 5.Raft协议：Leader的崩溃恢复机制

有服务，注册的请求还没发送过去，leader就崩溃了，此时进入了在剩下的两台follower中重新选举leader过程中，还没有诞生一个新的leader，服务注册的请求是失败的，无法发送，你需要不停的重试

如果说你的注册请求发送到了一个leader上去，此时uncommitted状态，没有发送uncommitted请求到其他follower上去，leader崩溃了，此时这个注册请求是失败的，需要服务不停的重试，选举出来新的Leader

如果说你的注册请求发送到了leader上去，也发送了uncommitted请求到其他follower上去，部分follower收到了请求，但是还没达到半数follower返回ack给Leader，leader就挂了，会导致服务也认为服务注册强求失败了

如果说已经超过了半数的uncommitted请求的ack给leader了，服务注册请求已经成功了，此时leader崩溃了，选举一个新的leader，会去接收其他follower的ack，如果超过半数follower有ack，直接commit操作

跟zookeeper几乎是类似的

### 6.客户端是如何进行服务发现的

参考eureka的服务发现的多级缓存的架构，主要是用于避免掉对同一个内存数据结构频繁的读写出现大量的锁互斥，多线程频繁读写，避免涉及到大量的加锁和等待的过程

刚开始的时候，服务发现，会先找ReadOnlyMap，如果没有就找ReadWriteMap，如果没有就从核心注册表加载出来放入ReadWriteMap中以及ReadOnlyMap中，后续服务会每隔一段时间去加载注册表

默认情况，就是从ReadOnlyMap里去加载

如果注册表出现了变更，此时会直接invalid删除ReadWriteMap中所有的数据，一个后台线程会每隔一段时间检查ReadOnlyMap和ReadWriteMap两者数据是否一致，如果不一致，就是发现ReadWriteMap里空了，此时会清空ReadOnlyMap

下次别人服务过来加载注册表，看到ReadOnlyMap是空的，直接就会从核心注册表里加载数据，填充两个map就可以了

### 7.基于Raft协议的注册中心的本质：容量受限于单机

所有的写请求都得基于leader去完成，如果你有大量的服务实例，上万服务实例，心跳间隔调的很低，100ms，1s一次，拉取服务注册表的间隔调节的很低的话，此时你的leader一定压力是会很大的

单机都要上万，甚至是几万并发的请求都是有可能的

服务注册表的数据量特别大，因为包含了大量的服务实例，几万，几十万

单台机器的内存容量是有限的，我升级leader的机器配置，24核48G，让他去一台机器抗超高并发，抗超大数据量

leader承载所有的写，leader和follower每台机器保留的都是完整的数据，所有注册表数据都在一台机器上，一台leader机器抗所有的写，从架构的角度而言，单机瓶颈，这样也是有问题的

### 8.Peers以及Raft协议下的服务注册中心的缺陷

eureka：纯peers，任何一个节点都可以接收读写请求，每台机器都要承载所有的写入的请求，把心跳上报的频率调节的很小，把拉取注册表的频率调节的很小，保证你的服务发现的时效性，注册表可能会很大，每个人都频繁的来拉取

zookeeper以及类似的基于raft协议的注册中心：类似的问题

单机抗所有并发，无法伸缩

单机抗所有数据，内存可能不够，没有办法进行伸缩

单机网卡流量有限，服务太多会打满网卡

机器，都是用千兆网卡，理论上每秒就是传输100+MB，一般还到不了，每秒也就传输几十MB这样子

### 9.心跳机制

基于数据分片机制正常上报

shard概念是非常，机器崩溃的时候，集群扩容，用一个shard去聚合多个服务的数据，服务就是跟一个shard严密的绑定在一起的，让我们的每个服务跟master之间建立一个长连接其实就可以了

心跳，应该频率高一些，服务就通过一个跟master机器的一个长连接，每秒钟都上报一个心跳过去

采用什么样的频率依据心跳进行故障感知？

定时去检测各个shard里面的服务，最近一段时间是否上报了心跳，如果心跳正常，那么就不用做什么了，但是如果超过了一定的时间，没有心跳过来，此时你就应该认为这个服务就故障了

立马就反向通知订阅这个服务的其他服务就可以了

如果master机器发现某个服务默认超过5秒钟都没有心跳，立即就认为他是宕机了

服务发现的长连接能否基于Slave机器进行？

服务A的shard对应的应该是一个机器组的概念，模仿RocketMQ里面的broker group形成的一个概念，进行主从同步的几台机器，应该是可以形成一个组的，此时我们可以从这个组里的master+slaves里面，随机挑选出来一台机器

对于slave，他可以仅仅是复制心跳，对于slave角色而言，是不会启动检查心跳的线程

如果Slave机器挂了如何进行长连接转移？

一旦slave挂了，之前跟这个slave建立上连接的服务，立马随机从组里重新挑选一台机器出来，可能是master，也可能是其他的slave

如果Master机器挂了，如何让Slave热切换为Master？

对于一个组内的master而言，他应该是说要定时的给slave发送心跳的，告诉slave自己当前其实还活着，每秒钟发送一次心跳，各个slave一旦发现比如说超过5秒没收到这个master发送过来的心跳，此时大家就判断说，这个master必死

必须得有一个新的master出现，多个slave是否需要进行一下选举呢？

也可以基于raft协议去进行一个选举，如果只有一个slave必然是这个slave去进行接管；在这里，不要基于raft协议随便去选一个master出来，各个slave之间还是进行投票，不是随机休眠挑选一个slave

每个人去比较，谁之前从master接收到的数据是最多的，就让谁当新的master，完全是仿照zookeeper来做的；如果大家接收到的数据是一样多的，此时可以投票让slaveId最大的那个机器成为新的master

对于其他的服务而言，他们应该都转变为每隔5秒钟，去Controller节点尝试拉取这个分组里最新的master是谁，Controller主要就是管集群里有哪些机器，shard在各个分组的分配是如何定的

新的master选举出来之后，就去找controller进行一个注册

对宕机的Master机器，如何采用Slave角色进行恢复？》

必须得以slave的方式去进行一个启动，让他去连接到当前最新的master上去，跟新的master进行数据恢复，另外一个新的master感知到有slave挂载上来了，此时必然就会让一部分的机器转移长连接到新的slave上去，进行rebalance

### 10.log4j的几种日志级别以及我们在项目里如何使用？》

log4j的日志是分成几种级别的，也就是说我们可以按照不同的级别去打印日志

all：所有的级别

trace：就是对系统运行中产生的各种细小的事件，进行追踪

debug：为了调试系统的运行，打印的一些日志

info：就是对系统正常运行过程中打印的一些日志，帮助我们了解系统运行的情况

warn：系统运行过程中，发现了一些异常的情况，但是不至于让系统崩溃，进行警告

error：系统已经产生了一些异常，导致一些功能没法正常的运行了，主动退出系统

fatal：发生了绝对严重的异常，导致系统立马要崩溃

off：关闭日志输出

## 秒杀系统

### 1、秒杀促销活动服务

（1）秒杀促销活动服务的业务流程

（2）秒杀促销活动的Redis数据结构设计

电商运营人员会在你的这个服务里选择对应的一些热门的商品，给他一个超低折扣，锁定他的一些库存，专门是用于进行秒杀促销活动的售卖，这个服务会把你选择好的商品信息、折扣信息、促销活动信息、库存数据，都放到一个redis里去

采取一个数据库+缓存双写的一个模式，在你配置好了秒杀活动以及通过了审核之后，就把这个秒杀活动的数据直接灌入到Redis缓存里去，接着呢，你对外提供的秒杀活动的查询接口，其实可以直接就从Redis里把数据搂出来

在Redis里肯定是不可能通过字符串的key-value对来存放的

每天有几个秒杀场次，你可以搞一个key，seckill::#{当日的日期}::rounds，在里面可以搞一个list，我们需要的是一个有序的数据集合，在里面可以按照一定的顺序放进去多个秒杀的场次，list里存放的可以是秒杀场次的id主键值

可以直接就读seckill::#{当日的日期}::rounds这个key，可以拿到当日的秒杀场次的主键id的值，遍历这里的主键id的值，可以再接着去拿每一个秒杀场次里的数据，我们需要知道一个秒杀场次他里面有哪些秒杀商品，还有就是他自己对应的时间点是几点

seckill::round::#{秒杀场次id}::info，可以跟上一个hash数据结构，可以放一些秒杀场次的基本信息，比如最典型的就是秒杀场次开始的时间点，比如说12:00，10:00，当然还可以跟上其他的一些东西

对于每个秒杀场次都必须可以拿到他的秒杀商品的id集合

seckill::round::#{秒杀场次id}::products，跟上一个list，有序的数据结构，在里面可以放入你这个秒杀场次要跟上哪些商品，我拿到这些商品id之后，我如果想要获取商品的更多的数据，可以通过商品id走一个商品系统去查询，商品标题和简要的描述

seckill::#{秒杀场次id}::#{商品id}::info，里面跟上一个hash数据结构，在hash数据结构里可以去包含所有的秒杀商品的数据，包括了秒杀价格和秒杀数量

综合的运用list和hash两种数据结构

但是的话呢，还要再考虑到一点，就是说针对APP里展示出来的秒杀活动的场次和商品列表的数据，量肯定是不大的，其次查询的频率可能很高，所以甚至可以做一份完整的缓存，就是说某一次查询你的秒杀活动场次列表和商品列表的时候，把你完整的一份数据都拼装好，拼装成一个超大的字符串

放在redis里，也可以让客户端做一个缓存，尽可能先用这份缓存好的完整数据去展示就可以了，比如APP端每隔5分钟做一个过期，在服务端让这份完整拼装好的大缓存数据，包含了当天所有的场次和商品，缓存过期时间可以设置为10分钟，10分钟以后过期，就自动重新基于一大堆的key组装一份数据出来

保证说我们的用户就可以看到我们每天的秒杀活动了

### 2、秒杀促销活动的前端页面

（1）秒杀活动页面静态化方案

秒杀活动管理系统，配置一些秒杀场次、商品、价格折扣、秒杀库存，前端就可以给他展示出来了，仅仅只是一个列表而已，对于这个列表而言，你可以把里面的数据放在缓存里一份，对于前端来说可以做一个缓存，每隔一段时间去加载和刷新一次就可以了

点击某个秒杀的商品可以进入到一个秒杀商品的活动页面里去

亿级流量电商详情页系统的架构设计，伪静态化，实际上并没有静态化，动态渲染，每次一个页面请求过来就直接在Nginx层基于lua从多级缓存里加载页面数据，基于模板技术动态渲染成一个静态页面，再返回回去

纯静态化，每天都需要对全量几亿甚至几十亿个商品的详情页进行一次静态渲染，把每个详情页渲染成html静态页面，可以去死了，性能损耗，时间开销，存储空间，都是成本上无法接受的

秒杀商品活动页面，是不太适合这种动态渲染的，每天就那么几个商品，其实商品数量是很少的，页面数量是很少的，而且这种页面的访问频率实际高的，因为很多人都会集中去访问这几个秒杀商品活动页面

实际上任何一个页面，都不可能完全是静态的，因为肯定会涉及一些别的东西，比如说什么用户自己的个人信息了，还有给用户的一些推荐商品了，用户的位置信息了，类似这样的一些东西，都是动态的，所以说对页面而言，那一定是动态分离，静态的部分做静态化，动态的部分就是动态到后台加载

秒杀活动商品详情页，那是数量很少的，所以可以直接用纯静态化方案，这个静态化其实也非常的简单，最经典的，用freemarker或者velocity这种模板技术都是可以搞定的

有了静态化的页面之后，就可以做一些静态页面的缓存方案了

所谓的动静分离，意思就是说在秒杀活动页面里，大部分都是静态，之前都已经通过html页面渲染都已经把内容填充好了，商品标题、价格、秒杀数量、乱七八糟的一些东西、商品描述

动的一块呢，在页面里肯定会有一些比如说你的用户个人信息、登录状态、位置信息、动态个性化推荐内容，这些是属于动态化的

（2）页面静态化以及CDN缓存方案

找DNS解析域名，然后DNS智能解析让你去请求距离最近的CDN加载，其实现请求CDN的负载均衡服务器，然后分发请求给CDN缓存服务器，把一个缓存服务器的地址给你，你再去请求缓存服务器

CDN厂商，他们的CDN服务器遍布全国各地，对于你自己而言，你不可能说在全国各地搞太多的服务器，你完全可以把你的秒杀活动静态页面以及他依赖的一些js、css和图片，都给推送到CDN厂商的服务器上去，距离用户近一些

（3）静态页面的缓存以及文件服务器存储

其实秒杀活动静态页面一般分为两个部分，一个部分是把数据都嵌入html以后的静态htm页面，一个部分是html页面引用的js、css和图片，所以这些静态资源都可以直接推送到CDN里去，所谓CDN可以理解为距离用户所在地最近的一台机器，用户的APP和网页加载的时候就直接走CDN了

假设我们自己秒杀活动页面的Nginx服务器可能就3台，此时如果说你有100万用户同时要访问你的秒杀活动页面，100万请求都会发送到你的台Nginx服务器上来了，这个是必然的

但是我们可以选择一些分散在全国各地的CDN服务器，购买他们的服务，把我们的页面上推到CDN厂商的在全国各地的服务器上去，假设有100台服务器，100万用户每个人的请求都会找距离自己比较近的CDN服务器

每台CDN服务器也不过就在一定时间范围内接受了1万次请求而已

第一个好处，利用散步在全国各地的CDN服务器去分散我们自己的服务器的压力，利用大量的散步各地的CDN服务器就可以轻松抗下高并发的秒杀活动静态页面的读取的请求，都是没问题的

第二个好处，假设我们公司的机房在上海，此时云南、贵州、还有很多偏远的地方的用户的请求如果说都要走到我们上海的机房来，那么速度就会可能比较慢，但是如果说秒杀活动页面都分散在各个省份，云南、贵州或者其他的偏远省份都有一些CDN服务器，我们都推送了页面之后

各个地方的用户就距离自己最近的CDN服务器去加载，加载的速度也会块很多

如果请求回源到服务端，那么html页面因为是静态的，就可以直接放在nginx服务器上，直接本地读取静态页面返回了，至于说js、css和图片，也可以放在nginx上，如果回源过拉就直接本地读取返回了

尽可能挑选距离用户最近的CDN

假设不小心修改了页面，就需要让CDN快速失效缓存，然后重新推送页面过去；

至于命中问题，就是要选择推送到哪些CDN节点，如果太分散了，那么成本很高，而且失效的时候成本很高，还可能导致命中率很低，所以最好是推送到距离自己用户量最大的地区，而且保证CDN和公司服务器的网络要好

1000个CDN服务器上都有我们的页面缓存，此时可能有很大一部分CDN服务器并没有太多的人去访问，但是有少部分的CDN服务器因为距离你大部分用户比较近，可能承载的压力就会比较大一些

而且是缓存在CDN的二级缓存服务器上，那个缓存服务器容量大，集中，缓存命中率会比较高，而且数量不多，缓存失效速度也快

CDN服务器数量不要太多，尽量都是选择在距离你大部分用户比较近的地方；万一你要失效缓存，此时CDN服务器数量不多，失效的时候速度就会比较快一些，成本也比较低；但是都是距离用户比较集中，缓存命中率整体也高

（4）秒杀后台接口url隐藏方案

技术高手，自己写一个程序，直接咔嚓一下去访问你的秒杀接口URL地址，他不就可以提前发起秒杀抢购了吗，就避免到了时间之后跟很多人一起去抢购了

不能直接在前端界面里写死一个url地址去访问后台的秒杀抢购接口，那样别人会提现发现了胡乱访问的，合理的应该是把秒杀抢购接口做成动态URL，一直到秒杀开始前1分钟，才让秒杀前端发送一个请求到后台一个接口，去获取动态的秒杀抢购接口URL地址

这个秒杀抢购接口URL地址自己本身其实也可以暴露，但是这个接口要求必须带上一个随机字符串的md5加密值，否则一律不允许访问

（5）后端与前端时钟同步的秒杀倒计时方案

用户拿到静态页面之后，接着就要等待秒杀活动开始，但是这个是要基于时间来判断的，而且需要进行时钟倒计时，可能页面/客户端和服务端的时间是不同步的，这个完全是有可能的，就比如说有的人把自己的电脑和手机的时钟调整过，所以一般需要前端定时访问后端的一个授时服务接口，进行时钟同步和倒计时

（6）秒杀场景下的前端验证码方案

为了避免说秒杀一开始，所有人都瞬间发起请求，几秒钟之内发起了几百万，上千万次请求过来，那是相当的这个恐怖的，一方面为了避免机器刷单，一方面是为了进行前端限流和错流，必须在用户点击秒杀抢购按钮的时候，弹出一个验证码

弹出一幅拼图，让你拉动拼图拼好，这个都有很多商用验证码解决方案

一旦每个人都要进行一个拼图验证码的过程，假设100万人平均用30秒去拼好一幅拼图，瞬间就会让你的流量拆分到30秒里去了，每秒就3万多请求，此时对我们后台的Nginx服务器的压力一下子就减小了

（7）秒杀活动页面的限流方案

其实很简单，控制页面上的抢购按钮，秒杀开始前都是灰的，秒杀开始后就让点击一次，立马按钮变灰，不允许反复点击，在30秒内不允许重复抢购，避免有人疯狂的点击按钮，不停的发送请求过来

### 3、秒杀场景下的高并发负载均衡架构

（1）防黑客DDoS攻击的高防IP方案

防止黑客的DDoS攻击，黄牛刷单、黑客其他攻击、非法作弊请求

比如说你购买了CDN产品的10TB资源流量包，然后正常情况下，支撑上百万次请求都没问题，结果有黑客对你的seckill-detail.zhss.com域名进行DDoS攻击，利用很多台服务器，疯狂的请求你的这个域名

他疯狂的请求，短时间内，半个小时内就请求了上百万次，请求你的CDN上百万次，就把你的10TB的资源流量包全部刷光

如果说CDN的流量被刷爆了之后，再次请求你的域名，CDN就不能提供服务了，直接会让所有请求回源到Nginx服务器上去，假设他是100mb带宽的机器，此时被疯狂攻击，直接会挂掉，无法再提供任何正常请求了

你的Nginx服务器可以设置一个防火墙，防火墙可以自动过滤掉大量的请求

如果说，你的seckill.zhss.com这个域名被黑客DDoS攻击之后，可能导致大量的黑客构造出来的请求直接到你的秒杀抢购的后台服务器上去了，从LVS到Nginx，到Tomcat服务器上去

某一个秒杀活动刚刚开始，结果黑客疯狂的攻击你，黑客的请求把你的LVS、Nginx、Tomcat服务器的资源全部打满，甚至打挂，此时导致正常用户的秒杀请求根本没有办法来执行了，全部失效了

DDoS攻击，一定要用云厂商的DDoS高防商业产品

独立二级域名解析到DDoS高防产品去，DDoS高防产品的源站地址解析到SLB上去，所以请求先经过DDoS高防，如果被攻击，流量直接被清晰过滤，合法流量才会到SLB去，SLB此时再进行转发

一般来说是一年几十万的费用，整个就可以把你的读链路和写链路都加入DDoS高防产品保护起来

基于云厂商验证码机制拦截黄牛和黑客请求？

黄牛，或者是刷单，黑客非法请求，典型的特征，他们都不是人去点击秒杀抢购的请求，他们可能都是在秒杀开始之后想办法截取秒杀抢购后台真是的url地址，他们可能没有发起DDoS攻击，就是普通的一些请求，但是这些请求都是他们写的程序构造出来的，直接发送到DDoS高防产品

比如说，正常来说一般用户可能就一个账号去抢购一个秒杀的产品，但是黄牛党，直接搞了一个程序，利用5台电脑，或者是10台电脑，20台电脑，他有多个账号同时发起请求过来，普通人都是在页面上或者APP上来进行点击的，所以手速一般比较慢

但是黄牛党搞多个电脑多个账号，他直接是程序发送，就是可以在程序里写一个for循环，不停的发送请求，万一他的请求速度比较快，可能会导致一些黄牛党的程序运行的速度远远高于普通用户的手速

黄牛抢了一堆秒杀低价产品，然后再转手倒卖出去，一般会来一些QQ群，微信群

黑客自己吃饱了撑的，也是自己写程序发送请求到后台去

验证码机制，前端滑动提交一大堆的行为：

o 浏览器名称、版本

o 操作系统

o 屏幕长宽

o 鼠标点击、移动

o 键盘敲击

o 屏幕滑动轨迹

o URL

o 是否安装Flash

验证码后端基于大数据和AI验证是不是合法的行为，如果是，就判定验证码滑动通过，然后请求发到后端，后端调用验证码后端接口检查本次验证码滑动是否通过，如果通过才能方形，否则如果是黄牛，刷单，黑客，接口绝对不放行

直接在nginx+lua层就可以把这个事儿给做了

如何基于限流算法对秒杀系统进行整体限流？》

DDoS、刷单/非法请求、人肉刷单作弊，放行的流量其实一般都是正常用户自己来参与的秒杀请求，之前整体对秒杀系统的后台已经做过完善的压测了，每秒的TPS在5万，就已经很高了，如果超出5万，那么可能明显发现后台很多机器的负载压力就很大了

正常的抢购请求一下子发送过来每秒有5.5万请求了

秒杀商品太火爆了

一秒内5.5万个请求如果说一旦放行到了后台服务器去，可能你的秒杀系统的压力会极大，可能会扛不住

一定要在Nginx环节，基于Lua脚本做一个秒杀系统整体性的限流，一共有2台Nginx服务器，秒杀系统整体后台Tomcat服务器最多可以抗5万TPS，每台Nginx服务器每秒最多可以方形2.5万请求16

限流算法介绍：令牌桶算法和漏洞算法

令牌桶：假设一秒就限速100，那么专门搞一个后台线程按照10ms一个令牌的速率往一个桶里放令牌，1s刚好放100个令牌，对每一秒都做一个令牌桶，请求过来从当前这一秒的令牌桶里拿令牌，拿到就放行，否则就拒绝

通过这种方式，可以确保，每秒钟可以拿到令牌进行处理的请求，最多就能是100个请求

漏桶：做一个漏桶，请求就是水滴，水滴流入漏桶的速度任意，无论有多少请求都直接流入漏桶，用漏桶装起来，然后漏桶按固定速度出水滴，比如一秒限速100，那么就10ms出一个水滴，如果桶满了，有新的请求要作为水滴入桶，此时就拒绝

用一些队列这种数据结构做令牌桶或者是漏桶，可以实现上述的思路

如何基于Nginx+Lua实现一套业务限流机制

DDoS、非法请求、作弊刷单、整体限流、业务限流

是跟业务有关系的，比如说，秒杀场次，几个商品，商品A的限购数量是1000，商品B限购数量是2万件，商品C限购数量是1000件，在这种情况下，你觉得你放行5万个请求到秒杀抢购后台服务器的意义在哪儿？

分段限流，Nginx+Lua这一层，整体限流做完了，确保每一秒放过去的流量都是在后台最大压力承载范围之内，接着用Lua脚本做业务限流，你必须基于Redis记录下来，一个秒杀场次里的每个商品的限购数量是多少，你必须得知道，其实在秒杀开始之前，就可以提前Lua脚本加载进内存里了

每个秒杀场次的每个商品的抢购请求的数量，可以基于Redis做一个原子incrby累加计数，然后，如果说商品A发现放行到Tomat服务器的抢购请求的数量已经超过1000了，此时就可以直接对商品A后续抢购请求直接返回一个响应，说抢购完毕

商品B，如果发现放行到后台Tomcat服务器的抢购请求数量超过2w了，也直接可以拒绝后续的抢购请求了

假设有10万用户同时参加秒杀抢购，瞬时过来的流量很高，有DDoS（几十万请求，直接被过滤掉），非法请求（几千个非法请求，直接过滤掉），人肉作弊请求（几百个请求，也直接过滤掉），正常的10万（整体限流，过滤掉5万请求，保留5万请求），业务限流（2.2万件限购数量，2.8万请求被过滤，仅仅放行2.2万请求）

最终放行的2.2万请求全部会抢购到自己心仪的商品，7.8万人被整体限流和业务限流都给干掉了，如果有5万人是被整体限流pass掉了（系统繁忙，秒杀失败了），2.8万人是被业务限流（抱歉，商品库存被秒杀一空拉！）

很公平，FIFO，手速越快，请求先到，就给你先放过去，请求后到，就会发现你被业务限流了

对于你的基于Tomcat部署的秒杀系统而言，最后他看到的也就是最多一秒过来2.2万个请求这样子，假设10万人一起抢，到LVS+Nginx那一层的每秒并发也就上万而已，Tomcat部署的那一堆服务器最多每秒也就几千个请求而已了

（2）秒杀场景下的SLB负载均衡架构方案

用户在自己的笔记本电脑上的浏览器里，或者是自己的手机上的APP里，各种点击发送请求到后台系统上去，此时发送请求的时候必定会指定一个域名，或者起码是ip地址，否则的话根本无法连接到后天系统

域名，此时可以用这个域名到DNS服务器上做一个解析，解析之后指向一个IP地址，可以是LVS服务器的IP地址

LVS服务器，作为负载均衡调度器，请求到来了以后，直接基于linux内核内部的一些底层机制进行请求转发，转发给后端的Web服务器池子里的一台服务器，本质上就是在进行负载均衡，而且因为LVS主要是基于linxu内核级的一些底层机制做请求转发，所以说效率极高，单机抗每秒几十万甚至上百万吞吐量绝对不是问题

但是Web服务器都是Tomcat之类的，一般4核8G的服务器每秒1000以内的请求就差不多了，所以说假设发现后端服务器池子承载的请求容量到极限了，此时就可以进行Web服务器的集群扩容

为什么叫做LVS呢？Linux Virtual Server，就是linux虚拟服务器，也就是说把你一组Web服务器统一成一台虚拟机服务器对外提供服务，外面的人访问你，都是访问你的LVS，看起来就跟只有一台服务器一样

（3）基于SLB的秒杀场景和普通场景的分流隔离

（4）秒杀场景的Nginx请求分发方案

（5）Nginx环节的请求限流方案

（6）高并发场景下的Nginx内核参数调优

### 4、 秒杀场景的超高并发架构设计

（1）秒杀抢购请求的黄金链路流程



（2）高并发场景下的Tomcat内核参数性能调优

（3）秒杀场景下的接口限流方案

MQ的削峰场景

（4）重复秒杀请求去重解决方案

（5）秒杀接口的防刷防作弊风控解决方案

（6）秒杀场景的Redis分布式缓存架构方案

（7）基于Redis Lua脚本实现的复杂秒杀业务逻辑

（8）秒杀场景下的库存超卖问题解决方案

（9）秒杀场景下的多线程并发优化实战

（10）高并发场景下的线程池参数调优

（11）秒杀场景下的多线程同步加锁优化实战

（12）秒杀场景下的分布式锁优化实战

（13）秒杀场景下的Disruptor以及内存队列实战

### 5、秒杀场景的异步下单技术方案

（1）秒杀场景下的RocketMQ集群架构方案

（2）秒杀场景下的消息队列技术方案

（3）秒杀场景下的Redis+RocketMQ一致性回滚方案

（4）秒杀场景下的数据库架构方案

（5）秒杀场景的分库分表技术方案

（6）秒杀超高并发场景下的数据库压测

（7）高并发场景下的数据库连接池参数调优

（8）高并发场景下的数据库内核参数调优

（9）秒杀下单服务的核心业务逻辑实现

（10）高并发场景下的数据库锁实战

### 6、秒杀成功后的业务逻辑实现

（1）秒杀成功后的异步通知用户解决方案

（2）秒杀成功后的订单查询方案

（3）秒杀成功后的订单支付以及后续逻辑实现

（4）秒杀成功后长期不支付解决方案

### 7、高可用的秒杀系统架构设计

（1）秒杀系统的全链路中间件高可用架构

（2）秒杀系统的全链路高可用降级方案

LVS高可用：LVS双机器部署 + keepalived

Nginx高可用：多机器冗余部署，几台服务器，LVS会做负载均衡

秒杀抢购服务：多机器冗余部署，Nginx会做负载均衡

Redis Cluster：master-slave架构，主从架构，自动故障切换

RocketMQ：集群部署+多副本冗余

秒杀下单服务：多机器冗余部署

秒杀库存服务：多机器冗余部署

（3）Redis缓存崩溃后的秒杀系统自动恢复方案

一旦Redis崩溃，就没法进行秒杀抢购了，此时如果说把所有的请求全部打回去就说是抢购失败，那也不太好，可能会导致这次秒杀活动就彻底失败了，其实此时比较好的方案是把秒杀抢购流水日志顺序写入本地磁盘，进入os cache，返回的状态告诉用户说，正在抢购中，让他耐心等待

其实此时，他要不然就是停留在这个界面等待，要不然就是进入到之前抢购过的一个秒杀商品详情页里去，此时页面里查询他的抢购状态就是发现在redis里可以查到他对这个商品发起过抢购，状态是正在执行中

以此类推，包括所有的用户对每个商品的抢购状态都最好存一下，包括抢购失败，抢购进行中，抢购成功，完成创建订单，完成支付订单，等等，这样子其实在秒杀商品详情页里是可以获取到每个用户对每个商品的抢购状态的

以此可以类推他是否可以再次下单抢购，比如之前说过的MQ积压方案，快速释放掉了他的抢购，此时他再次进入详情页，是可以重新进行抢购的

所以这里也是一样的，此时是完全可以把抢购流水日志顺序写入磁盘文件，进入os cache，其实性能也还可以

此时秒杀就直接结束了，因为大部分流量被拦截了，少部分流量放进来都进磁盘了作为流水日志了，接着Redis集群可以紧急进行修复，比如说重启之类的，然后让秒杀系统后台线程自动探查Redis是否恢复，如果恢复了，则顺序读取本地磁盘的秒杀流水日志，进行流量重放去执行抢购，后续流程一切正常

两个方案：redis主从同步取消，只有master，把redis cluster，就用最普通的redis部署几台机器，然后可以用twemproxy中间件或者是codis对几天机器上的redis做分布式数据存储和路由，取消slave复制这个概念

一点任何一台机器宕机，此时对那台机器的抢购操作转化为流水日志写入服务器本地磁盘文件，等到那台redis机器恢复了，再重放流水去执行就可以了，库存超卖问题，还能实现redis崩溃的高可用机制

第二个方案，依靠订单系统去检查的方案，不是太好

（4）RocketMQ集群崩溃后的临时本地存储降级方案

MQ崩溃，只不过是无法下订单罢了，但是抢购是可以正常执行的，所以抢购成功与否，结果直接返回就行了，然后此时可以把秒杀抢购下单通知写入内存，内存中进入本地磁盘文件，接着后台开个线程，逐步的慢慢读取这些数据然后直接调用下单服务就行了，他的缺点就在于说，可能会丢失一点数据罢了

对我们而言，在这里，完全没必要去等待MQ恢复，你可以把秒杀抢购成功的通知写入内存缓冲，然后刷入磁盘，后台开一个线程直接做服务直连，直接绕过MQ，以一个很慢，速度很低的节奏，把抢购成功通知慢慢的发送给秒杀下单服务的接口

（5）数据库集群崩溃的临时本地存储降级方案

（6）秒杀服务崩溃的防服务雪崩降级方案

（7）秒杀系统的全链路漏斗式流量限制方案

（8）秒杀系统的双机房多活部署方案

（9）秒杀系统部分机房故障时的降级方案

### 8、秒杀系统的压测、故障演练以及实时大盘

（1）秒杀系统的全链路压测以及针对性优化

先基于虚拟机环境各种部署和开发代码，演练，做一个模拟的本地全链路压测，每秒1000请求，每秒500请求，做 一些高可用演练，真实平台去做一个集成，会做一些代码改造，跟真实电商平台集成在一起

（2）秒杀系统的全链路故障演练以及高可用架构验证

（3）秒杀系统的基于大数据技术的实时数据大盘

### 9、秒杀业务中台的架构升级与改造

### 10.redis实例

基于Redis实现的缓存机制

redis如果说简单了，里面存放的就是一大堆的key-value对，set key value，往里面放一堆数据，然后通过get key，从里面获取一堆数据，往简单了用，基本上来说redis就是这么用的，第一种最经典的场景

你可以用redis来应对高并发和高性能

可以把复杂查询以后的结果放入redis里作为缓存，下次再查询的时候就直接从redis缓存里出，不需要再次从数据库里执行上百行的SQL语句去查询了，只要10毫秒就可以做到了

同样的机器配置下，数据库每秒也就抗几千次请求，redis每秒可以抗几万次请求到十万次的请求都可以做到16270984

实现一个最简单的分布式锁

set key value nx，必须是这个key此时是不存在的，才能设置成功，如果说key要是存在了，此时设置是失败的

比如说有很多台机器，要竞争一把锁，此时你可以让他们对同一个锁的key，比如lock_key，设置一个value，而且都是要加上nx选项的，此时redis可以通过nx选项，保证说只有一台机器可以设置成功，可以加锁成功，其他机器都是会失败的

博客网站的文章发布与查看

mset一下子设置多个key-value对

mget就是一下子获取多个key的value

msetnx就是在多个key都不存在的情况下，一次性设置多个key的value

mset和mget，相当于是batch批量设置和查询，比如说假设你一次性要往redis里塞入20条数据，假设你是通过for循环加上set，执行20次的set，每一次set操作都要一次完整的网络通信过程，每一次set就算他是10ms，200ms

mset，一次性把20个key-value对通过一次网络通信，交给redis去执行，此时就是10ms就可以了，mget也是一个意思，批量查询，msetnx，必须所有key都不存在，然后才可以完成本次的设置

用户操作日志审计功能

平时我们对系统上的一些用户的一些核心操作，比如更新一些数据的操作，都是会有一个审计日志的功能，其实就是把你用户在系统里的一些操作记录下来，每一次操作都记录成一条日志，审计日志

后续可以通过一个列表来进行一个查询，分页查询

我们如果说要基于redis来存储这种操作审计日志，应该如何来做呢？也可以在redis里，搞一个key，每天都有一个key，每天的这个key里就把当天所有的操作日志都串联在一起，查询的时候，都是按天来查询你的操作审计日志就可以了

key -> value，value取出来，做一下字符串拼接

redis的append这个api，就是说可以不停的把你的日志追加到指定的key里去

简单的唯一ID生成器

ID，都是通过数据库的自增主键来实现的，有一些场景下，分库分表的时候，你同一个表里的数据都会分散在多个库的多个表里，这个时候就不能光是靠数据库来生成自增长的主键了，此时就需要生成唯一ID

社交网站的网址点击追踪机制

社交网站（微博）一般会把你发表的一些微博里的长连接转换为短连接，这样可以利用短连接进行点击数量追踪，然后再让你进入短连接对应的长连接地址里去，所以可以利用hash数据结构去实现网址点击追踪机制

利用redis的incr自增长，然后10进制转36进制，接着hset存放在hash数据结构里，再提供一个映射转换的hget获取方法

利用redis的incr自增长，然后10进制转36进制，接着hset存放在hash数据结构里，再提供一个映射转换的hget获取方法

实现一个博客网站文章计数器》

博客网站，发布一篇文章，修改一篇文章，查看一篇文章，有人查看了一下这篇文章，就可以维护一下这篇文章他的一个浏览次数，对于这个浏览次数就可以统一都放在一个hash数据结构里，每个key就是一篇文章，value就是文章的浏览次数

hincrby hash view_count 1

hget hash view_count

基于hash数据结构重构博客网站案例

redis的hash数据结构，特别适合存放什么呢，就是类似于我们自己Java代码里搞的一些对象，很适合用hash数据结构来存储的，如果说你的一些对象不用hash结构来存储的话，比如你直接用json串把java对象序列化成json，然后用key-value对的字符串形势放在redis里，但是操作起来不是太方便

hexists判断博客是否存在，不存在可以发表新博客，用hmset一次性设置多个key-value对在hash数据结构里

查看博客的时候，直接用hgetall hash，一次性把一个hash里全部key-value对拿出来，然后返回就可以了

更新博客，也是用hmset就可以了162709

基于令牌的用户登录会话机制

用户平时会访问我们的系统，在处理任何一个请求之前，必须检查一下，这个请求是否带上了一个令牌，如果带了一个令牌，那么此时就必须在redis里检查一下，这个令牌是否有在redis里合法的、有效的一个session会话

如果有这个session会话，此时就可以允许这个请求被处理，因为说明这个人之前已经登录过我们的系统了，登录过后才会在redis里放一个有效的session会话；如果说没有这个session的话，此时就会导致用户必须强制被迫登录

如果用户登录通过之后，就会返回给浏览器或者客户端一块令牌，同时在redis里初始化好一个session会话，后续客户端就会在指定时间范围内发送请求的时候带上一块令牌，每次令牌和服务器端的session校验通过就可以执行请求

过一段时间过后，服务端的redis里的session会话就会过期，过期了之后，又会导致你必须要重新登录，虽然你可能带上了令牌，但是一检查发现这块令牌对应的redis里的session已经过期了

hset把用户id和令牌存储一下，hset把用户id和过期令牌过期时间存储一下

每次访问系统都让用户带上令牌，如果令牌不存在就是没登录，hget获取存储的令牌和过期时间，如果令牌过期了也要强制登录，如果令牌校验通过，这次请求就可以通过

如果令牌要是过期了，就用hdel把存储的令牌和过期时间都删了

秒杀活动下的公平队列抢购机制

秒杀系统有很多实现方案，其中有一种技术方案，就是对所有涌入系统的秒杀抢购请求，都放入redis的一个list数据结构里去，进行公平队列排队，然后入队之后就等待秒杀结果，专门搞一个消费者从list里按顺序获取抢购请求，按顺序进行库存扣减，扣减成功了就让你抢购成功

公平队列，基于redis里的list数据结构，搞一个队列，抢购请求都进队列，先入先出，先出来的人先抢购，此时就是公平的

list数据结构，你可以把他理解为是Java里的ArrayList，LinkedList，就是一种有序的数据结构，也可以把他作为队列来使用也是可以的

对于抢购请求入队列，就用lpush list request就可以了，然后对于出队列进行抢购，就用rpop list就可以了，lpush就是左边推入，rpush就是右边推入，lpop就是左边弹出，rpop就是右边弹出

所以你lpush+rpop，就是做了一个左边推入和右边弹出的先入先出的公平队列

实现博客网站的分页浏览

博客的发表和修改，查看一个博客的详细内容，浏览次数和点赞次数的统计

发表博客的时候就把博客数据lpush到一个list里去，分页的时候，就传入page_no和page_size两个参数，然后可以算出来start_index是(page_no - 1) * page_size，end_index就是page_number * page_size – 1

接着就是用list的lrange list start_index end_index，就可以把那一页的数据取出来了

除了获取一页数据之外，还要返回list里所有的数据量，就是用llen list就可以

网站用户注册时的邮件验证机制

填写完注册信息，然后提交注册，此时后台完成注册校验和用户数据入库，返回一个消息告诉你说注册成功，但是稍后发送了一封验证邮件到你的邮箱，希望你去邮箱里点击一个链接确认你的邮箱

一般来说在注册的后台里，是否在注册的逻辑里直接就发送一封邮件呢？发送邮件是比较耗费时间的，所以通常来说，你后台注册成功之后，都会把一个发送邮件的任务给放到一个队列里去，然后直接返回给你了

接着lpush将发送邮件任务放入list，然后发送邮件的系统就用brpop阻塞式的等待从队列里获取任务，这就可以把list做成阻塞队列的效果了，加一个timeout超时时间即可

网站每日UV数据指标去重统计

set数据结构，跟Java里的set是一样的，就是说放无序的、不重复的数据集合，list一般来说做一个操作，时间复杂度都是O(n)，set一般的操作，时间复杂度是O(1)，无序的，不重复的数据集合，数据结构上的优化，可以做到

如果说你把重复的数据放到一个set里，他会自动给你进行去重

网站的uv，有多少用户访问了你的网站，但是一个用户可能会访问多次，此时要对多次访问进行去重，保留完整的不重复的访问过你网站的用户集合，然后算出集合的元素数量，就会知道你当日的uv，sadd把uid放入集合，scard可以拿到uv值，当然这个仅仅是演示，实际实现是不可能这么做的

朋友圈点赞功能的实现

假设说你发了一条朋友圈，此时可能你的好友会对你的朋友圈进行点赞，还可以取消点赞，你的好友在刷朋友圈的时候可以查看到自己是否对你点赞过，你自己还可以查看到你的朋友圈有哪些人点赞了，有多少人给你点赞了

sadd给某一条朋友圈添加点赞的一个好友，用户取消点赞的话，那就是srem删除某个好友的点赞，查看你是否对某条朋友圈进行过点赞，sismember，你发出的朋友圈被哪些人点赞了，smembers，你的朋友圈的点赞次数，scard

实现音乐网站的排行榜程序

sorted set，不能有重复的数据，加入进去的每个数据都可以带一个分数，他里面的数据都会按照分数进行排序，有序的set，他自动按照分数来排序，相当于你可以定制他里面的排序规则了

zadd，把音乐加入排行榜中，刚开始分数可能就是0；zscore可以获取音乐的分数；zrem可以删除某个音乐；zincrby可以给某个音乐增加分数，这个增加分数可能就是说有人下载了，或者是有人播放了，或者有人分享了， 有人点赞了，此时可以按照规则去加分，那么排序就会移动了；当然也可以减去分数；zrevrank获取音乐在排行榜里的排名；zrevrange set 0 100 withscores，可以获取排名前100的热门歌曲

购买此商品的顾客也同时购买

zremrangebyscore，zunionstore，zinterstore

买了一个商品，他会给你推荐一个列表，购买过此商品的顾客也同时购买了其他XX商品，这个也是可以用这个sorted set来实现的

对每个顾客，每次购买了之后，都会遍历他之前购买过的所有的商品，对每个商品都维护一个同时购买的其他商品的数量，可以用zincrby set 1 其他商品，然后后续如果要看到某个商品购买的人还购买了其他哪些商品，就可以用zrevrange set start_index end_index withscores，

网站重复垃圾数据的快速去重和过滤

对于你的一些网站，垃圾数据，多的是一些不良广告，在一些论坛或者别的，有的时候你会看到一些在帖子下面的评论里，是一些广告，都有，可能会遇到有人频繁的提交相同的垃圾信息到你的站点里

pfadd key content，如果返回的是1，那么说明之前没见过这条数据，如果返回的是0，说明之前见过这条数据了

基于位图的网站用户行为记录程序

如果说你要记录一下，在系统 里执行一些特殊的操作，每天执行过某个操作的用户有多少个人，操作日志，审计日志，记录下来每个用户每天做了哪些操作，每个用户每天搞一个set，里面放他做的一些操作日志

也可以对每种操作都搞一个set，里面放执行过这些操作的用户

bitmap，位图，二进制里的一位一位的，字符串，int，long，double，二进制，都是对应多少多少位的，一个字节是8位的二进制数，int就是4个字节就是32位，你直接可以在redis里操作二进制的位数据

可以把网站里每一种操作每天执行过的用户都放在一个位图里，一个用户仅仅对应了一位而已

setbit key user_id 1

getbit key user_id

bitcount key

一个位图统计100万用户的行为，也不过一百多kb的内存1627098499

陌生人社交APP里的查找附近的人功能》

geoadd key longitude latitude user，记录每个用户的地理位置

georadiusbymember key user radius unit=’km’，radius设置为1，就是附近1公里的用户都找出来，再从返回的set里删除user自己，就可以了162

### 11.LVS

真正在公司里，负载均衡这块的架构部署和运维，都是运维工程师去干的，LVS+KeepAlived+Nginx这样的一套架构，Java工程师是不碰这套架构的

各个互联网公司的主流负载均衡的架构，其实基本上来说都是这样的一套架构

SLB -> Server Load Balancer -> 负载均衡

就是假设我们有一个系统，是一个单块系统，部署很多台机器，此时你的请求每秒有100个请求，一共部署了2台机器，此时你必须让每秒100个请求先到你的负载均衡的设备上去，然后让负载均衡的设备100个请求均匀分发给2台机器，每台机器50个请求

LVS，就是一种负载均衡的技术，部署在linux服务器上，LVS服务器获取到100个请求，均匀分发给2台部署在Linux服务器上的Tomcat，Web服务器，每台Web服务器拿到2个请求就可以了

用户在自己的笔记本电脑上的浏览器里，或者是自己的手机上的APP里，各种点击发送请求到后台系统上去，此时发送请求的时候必定会指定一个域名，或者起码是ip地址，否则的话根本无法连接到后天系统

域名，此时可以用这个域名到DNS服务器上做一个解析，解析之后指向一个IP地址，可以是LVS服务器的IP地址

LVS服务器，作为负载均衡调度器，请求到来了以后，直接基于linux内核内部的一些底层机制进行请求转发，转发给后端的Web服务器池子里的一台服务器，本质上就是在进行负载均衡，而且因为LVS主要是基于linxu内核级的一些底层机制做请求转发，所以说效率极高，单机抗每秒几十万甚至上百万吞吐量绝对不是问题

但是Web服务器都是Tomcat之类的，一般4核8G的服务器每秒1000以内的请求就差不多了，所以说假设发现后端服务器池子承载的请求容量到极限了，此时就可以进行Web服务器的集群扩容

为什么叫做LVS呢？Linux Virtual Server，就是linux虚拟服务器，也就是说把你一组Web服务器统一成一台虚拟机服务器对外提供服务，外面的人访问你，都是访问你的LVS，看起来就跟只有一台服务器一样

### 12.基于NAT技术实现的LVS请求转发原理

一般LVS服务器对外提供的是一个virtual ip address，就是虚拟服务器的ip地址，所有客户端/前端都访问这一个虚拟ip地址，其实就是LVS服务器的地址，接着LVS服务器收到请求了之后，会基于NAT技术进行地址改写

如果运行在用户本地笔记本电脑上的浏览器想要发送请求给我们的后端系统，此时要把请求发送给LVS服务器，最最起码也得基于TCP/IP协议，去跟LVS服务器在TCP/IP这个层面去进行一个TCP三次握手，建立好TCP连接

接着就是在TCP连接基础之上，去发送HTTP请求报文，把HTTP请求报文发送到LVS上去，LVS再把这个HTTP请求报文转发给我们的Web服务器，也就是Tomcat服务器，Tomcat获取到一个完整的HTTP请求报文，接着就可以进行请求处理

其实，假设你认为LVS是收到HTTP请求报文然后转发给Web服务器这样的一个原理，那你就完全大错特错了！对LVS的原理的理解就彻底错误了！LVS是工作在四层网络协议上的负载均衡的技术，Nginx他们是工作在七层网络协议上的负载均衡的技术

第四层的网络协议就是TCP/IP协议，第七层的网络协议就是HTTP协议

NAT就是Network Address Translation，也就是网络地址转换

假设此时运行在笔记本电脑上的一个浏览器，此时要发送请求给LVS服务器，先要跟LVS服务器建立一个TCP连接，建立TCP连接大家应该还记得吧？TCP三次握手，互相之间要来回发送几个报文，SYN报文，ACK报文

LVS负载均衡系统核心代码是挂载在linux内核层面的，所以linux服务器拿到一个建立TCP连接过程中的初始SYN报文之后，这个SYN报文就会由linux内核转交给LVS的核心代码模块，此时LVS核心代码模块会根据负载均衡算法从后端Web服务器池子里挑选出来一台机器，就会把SYN报文之类的其他报文，直接报文转发给Web服务器

然后就会用NAT技术改写报文里面的目标地址和端口为Web服务器的地址和端口，把报文转发过去

而且此时客户端（笔记本上的浏览器或者是手机上的APP）一定是想要跟LVS服务器建立一个TCP Socket网络连接的，此时LVS会把跟你这个客户端的Socket连接记录到一个hash表里去，以及这个连接的请求转发到哪个Web服务器了，下次同一个Socket连接再发送后续的报文来的时候，LVS就会把这个连接的报文同样再次转发给上次转发的那台Web服务器去

LVS看到的以及处理的，包括针对的，都没有一个所谓的HTTP概念，他仅仅是有一个TCP/IP的概念，他是运行在四层网络协议上的一个负载均衡的技术，他根本就不去care你的HTTP协议或者请求

HTTP请求实际上在底层也是很多的网络包/报文组成的

假设Web服务器上运行的是一个Tomcat，Tomcat会通过linux内核跟LVS服务器也是建立好TCP连接，然后通过TCP连接，Tomcat会读取到一个一个的完整的HTTP请求，Tomcat理解的是一个完整的HTTP请求

Tomcat本身是针对七层网络协议里的应用层的HTTP协议，他自己是不跟linux内核打交道，都是Tomcat基于一些API跟Linux内核层面有一个交互，Linux内核层面跟LVS服务器建立好TCP连接之后，然后收取你指定的一份数据，这份数据拿到以后交给Tomcat，Tomcat针对一个完整的HTTP请求对应的数据进行处理

LVS会对每个连接进行监听，在不同的TCP状态下有不同的超时时间，如果超时没拿到请求，就把这个连接从hash表了删除就可以了1627098499

### 13.基于IP隧道技术的LVS请求与响应分离原理

Tomcat不断的通过从底层的linux内核层面读取接收到的网络报文里面的数据，直到这些数据可以组成一个HTTP请求，Tomcat会把HTTP请求转交给我们的Servlet，如果说我们用的是Web层的框架，框架的Servlet就会把请求转交给我们自己写的代码

接下来我们自己写的代码就会处理这个请求，做一系列的事情，比如说更新数据库，查询数据库，更新缓存、es、nosql，都有可能，搞了一通之后，接下来会返回一个响应回去给浏览器/手机APP

这个所谓的响应返回回去的时候，也是Tomcat通过JDK提供的API，JDK API是通过底层linux提供的一些API，去进行网络上的IO操作，其实linux内核会把你的响应数据的一个一个的报文，返回给LVS服务器

对于LVS服务器会把你的响应报文返回给你对应的那个客户端去

对于浏览器或者是手机APP而言，也是不停的通过底层的OS层面（Windows、Android）不停的收取网络数据包，响应报文，假设大家都是基于HTTP协议进行通信和交互的，假设收取数据到一定的程度，感觉收到了一个完整的HTTP响应报文

接下来可以按照HTTP协议解析HTTP响应，可能是把HTTP响应里封装的一个HTML页面的数据在浏览器里渲染展示出来，也可能仅仅是获取到一个JSON字符串，然后给用户进行一些提示

LVS最早在实现的时候经过压测，如果说所有的响应报文都依然从LVS来走，如果Web服务器达到20台以上的时候，往往整体的每秒QPS都达到了几万了，此时LVS调度服务器的吞吐量会达到极限，成为一个瓶颈，主要是LVS服务器得处理请求，还得获取响应返回，最起码是他的网络带宽可能就吃不消了

但是事实上一般来说，大部分的请求都是请求里的数据很少，但是响应的数据很多，所以说可以采取一种技术让LVS服务器处理请求，但是让Web服务器自己就直接把响应返回给用户笔记本上的前端或者手机上的APP

IP隧道技术，是IP tunneling，也叫做IP封装技术，IP encapsulation

大家只要理解一下就好了，因为涉及到比较专业的网络知识，一般都是运维工程师玩儿的，还涉及到一些网络硬件设备的知识，所以我们只要大致理解这么个思路就ok了，大致来说，就是每一台Web服务器都把自己的vip配置在ip隧道设备上

然后LVS拿到请求之后，把目标地址为Web服务器的vip的请求报文封装到另外一个IP报文里，接着转发IP报文给一台Web服务器，Web服务器拿到IP报文以后解析一下，拿到里面的请求报文，发现目标地址就是一个vip，结果这个vip就配置在自己的IP隧道设备上，此时就可以处理这个请求

Web服务器想要去发送响应，响应发送给谁呢？已经不是LVS了，他此时会根据你的报文里的一些信息，然后Web服务器直接根据自己的路由表，找到需要返回响应的客户端，把响应报文返回给指定的客户端就可以了

他这个里面涉及到的大量的概念根本不在Java工程师的知识体系里，除非说大家有一个非常完整的网络相关的整套知识体系，大白话讲网络的课程，远远不够，大学是计算机科班出身的程序员，计算机网络

还有一种直接路由技术，也跟这个IP隧道技术是类似的，大家肯定有很多疑问，但是不要管他了，只要知道有这么一两种方法，LVS服务器可以把请求转发给Web服务器，然后Web服务器的响应直接返回给用户就可以了

这样LVS的吞吐量会大幅度提升，一台调度服务器支撑后端Web服务器池子几十台都没问题的

### 14.LVS的多种负载均衡算法

最简单的就是round robin了，就是每个请求不停的转发给下一个服务器，如果服务器挂了就摘除，就这么简单，但是如果不同的服务器处理速度和吞吐量不一样，必然会导致性能较差的服务器最终就扛不住了，请求一直阻塞

如果做了weighted加权处理之后，就可以给不同性能的服务器设置不同的权重，权重较大的可以获得更多的请求，权重较低的可以获取较少的请求，这样可以保证各个服务器相对较为均衡一些

但是这样也有一点问题，就是你设置的权重如果不太准确的话，也未必合理

本质上LVS服务器转发请求给Web服务器，互相之间也是建立底层的Socket TCP连接，所以说LVS可以记录下来每一台Web服务器目前建立了多少个连接了，每次有新的请求来就把新的连接给连接数量最少的服务器就可以了

但是这么做其实也有一样的问题，如果不同服务器的处理速度不一样，那每台服务器都处理一样数量的连接，绝对是有问题的

所以可以做加权处理，设置不同服务器的权重，这样在建立连接的时候会让服务器的连接数量的比例和各个服务器的权重比例都是成正比的

假设把Web服务器改成缓存服务器，每次请求目标ip都是针对某台缓存服务器的，尽量让针对同一个目标ip的请求都到一台缓存服务器上去，这样的话呢，就可以让你的缓存命中率比较高一些

这个是比较适合缓存集群的，也就是说假设请求是直接转发给缓存集群的话，一般尽量是让一个目标IP的请求路由到上次发送过去的那个缓存服务器上去，这样可以提高缓存命中率，但是前提是那台服务器的连接数量不能太高

而且他有一个优化，就是一个目标IP可以映射到一组服务器，假设一台服务器超载了，那就路由到其他服务器，此时连接映射到这一组服务器上去，如果一段时间没请求了，就可以把连接里映射的部分服务器摘除

这个就是之前讲过的，对于连接里的源地址或者是目标地址，可以把他路由到的服务器记录到hash表里去，下次还是继续路由到那台服务器上去

动态反馈负载均衡算法

这个也很好理解，就是收集和监控各个服务器的请求处理时间和负载情况，综合下来判定一下每台服务器大致每秒可以处理多少请求的吞吐量，当前负载情况如何，来决定把请求抓饭给谁

round robin + 加权权重，随机 + 加权权重，hash负载均衡（根据请求参数里的某个值，把这个固定的值算一个hash，就固定路由到那台服务器上去），动态反馈负载均衡算法

### 15.LVS的Linux内核级实现原理

LVS实际上是在linux内核里修改了TCP/IP协议栈，这样可以对收到的请求直接在linux内核层面进行地址改写和转发，所以因为他运行在内核层面，这样才能让他的性能和吞吐量都极为的好

LVS有一个IPVS模块挂载在了内核的LOCAL_IN链和IP_FORWARD链两个地方，一个IP报文到达的时候，如果目标地址是virtual ip address，就会转交给LOCAL_IN链，会被挂载在LOCAL_IN链上的IPVS模块处理

IPVS模块正常情况下会根据负载均衡算法选择一个后端服务器，把报文进行改写和转发，接着会在hash表了记录这个连接和转发的后端服务器地址，下次如果这个连接的报文再到达的时候，就直接根据hash表里的连接对应的服务器地址，直接转发

然后NAT方式改写和转发过去的报文响应回来的时候，会被挂载在IP_FORWARD链上的IPVS模块捕获，接着进行改写响应报文的地址，返回给用户

hash表里的一个连接数据只要128字节，所以一般服务器可以调度几百万个连接都没问题

如果说用linux内核提供的定时器来做

Hash表里的连接会设置一个定时器，连接超时的时候就会回收这个连接，但是如果有几百万个连接，那么可能会导致一个很严重的问题，就是有几百万个超时器，这么多超时器一起运行会导致很大的负载

LVS比较早期的版本就是用linux内核的定时器去做的，如果说你的连接数量较大了以后，此时linux服务器的cpu负载就会非常的高

实际的实现思路，是用了kafka里的时间轮机制，大家可以具体去看看kafka里的时间轮机制，在大数据的kafka的课程里已经讲解过如果在内存里要进行数万甚至是数十万的任务的超时监控，最好别每个任务都设置一个定时器，那样其实对cpu负载和内存的消耗，都是极大的，是不靠谱的

kafka就是设计了几个时间轮，不同的时间轮的时间周期是不同的，然后把不停的超时时间的连接放在不停的时间轮的格子里，让一个或者多个指针不停的旋转，每隔一秒让指针转一下，就可以让不同的时间格里的连接超时失效

把大量的超时任务放在时间轮里，你就几个指针不停的旋转，首先不是每个任务都有定时器，减少了内存消耗，其次没有那么多的定时器一起转，那么cpu负载就不会太高了，那么就可以接受了

LVS而言，他的Hash表里的大量的连接的超时监控，也是通过多个时间轮来实现的，原理说实话跟Kafka可以说是几乎一模一样

Hash表的分段锁，把Hash表拆成了很多个小分段，不同的分段一把锁，这样可以降低锁的粒度，减少高并发过程中的锁的频繁冲突，跟ConcurrentHashMap是一个原理，对不对，不同的技术搞到最后，都是想通的1627098499

### 16.为什么通常把四层协议的LVS和七层协议的Nginx一起使用

LVS绝对是运作在四层网络协议上的负载均衡的技术，对他来说，根本就没有HTTP这样的一个概念，他仅仅只是关注最最底层的一些网络报文而已

假设，如果我们要是想做七层网络协议的负载均衡的技术，也就是说基于HTTP请求去进行负载均衡和请求转发

最大的问题在于，需要先多次报文过后建立好一个TCP连接，接着拿到通过TCP连接发送过来的完整HTTP协议的请求，然后把这个请求从内核空间切换到用户空间，交给用户空间运行的一个负载均衡技术去进行处理，根据请求里的一些内容进行转发给后端服务器，再次切换到内核空间，跟后端服务器建立TCP连接，把请求发送过去

拿到的响应先是从内核空间转交给用户空间的负载均衡技术，接着再把响应通过内核发送回去

这会导致大量的内核空间和用户空间的切换

所以一般一旦涉及到了用户空间的系统运行，单机也就是抗每秒最多1000或者几千个请求，或者高配置服务器下是每秒几万请求，但是并发和吞吐远远低于LVS，LVS一般抗个每秒几万到几十万的请求都不是问题，甚至是百万并发都有可能实现

但是好处在于可以根据HTTP请求进行路由转发

四层协议的LVS和七层协议的Nginx（本身就是专门处理HTTP请求），为什么通常在负载均衡这一层会一起来使用呢？走七层协议进行负载均衡性能远远不如LVS，如果没有LVS，仅仅就是用多台Nginx服务器组成的集群去接收所有的请求，去转发请求给后端的Web服务器

在负载均衡这一层，在最外侧，通常都是部署一个LVS作为核心的负载均衡的设备，通过大连的优化，可以很轻松的做到单机百万级的并发量，缺点，没有办法根据HTTP请求的内容去进行一些高阶的功能和转发

Nginx可以拿到完整的HTTP请求，可以做很多高阶的负载均衡的功能，在功能上，Nginx可以做很多很多的事情，甚至可以在Nginx里嵌入lua脚本，在Nginx本地处理请求，读取缓存

### 17.使用独立二级域名让秒杀系统与电商系统隔离部署

LVS、Nginx，这些都是一些负载均衡的技术，在秒杀系统里，在负载均衡这一层大概都做一些什么事情，一般来说，后台系统，他跟域名之间的关系是什么，[www.zhss.com](http://www.zhss.com)，假设你是一个C端公司，都是直接是你的电商网站，或者是你的APP的官网；假设你是一个B端公司，公司门户官网

对外提供一些系统，可能会提供不同的系统，还有一些系统是对内部工作人员提供的一些系统，platform.zhss.com，seller.zhss.com，supplier.zhss.com，假设我们是一个电商公司，mall.zhss.com，指向了我们的电商网站

用户正常的如果来浏览商品，下订单，或者支付，或者是别的请求，都走这个电商网站，mall.zhss.com，秒杀系统如果说也是走这个域名访问后台系统，甚至把秒杀系统和电商系统部署在一起，都在一批机器上

瞬时流量是超高的，导致电商网站正常的一些请求，就被堵死了

mall.zhss.com/order，mall.zhss.com/seckill，mall.zhss.com域名解析到了LVS服务器上去，后面都对应着同样一批nginx，搞秒杀活动，瞬时每秒数万请求都解析mall.zhss.com域名，都涌入了LVS+Nginx

可能一下子万一你的LVS和Nginx的配置不是太高，可能会导致一下子让你的负载均衡层的设备的资源被打满，此时你商城正常的一些用户浏览商品，下订单之类的请求，可能就不行了，他们正常的请求，也是mall.zhss.com，也是走到一批LVS+NGINX去

速度突然变得很慢

商城域名：mall.zhss.com

秒杀系统：seckill.zhss.com

对二级域名进行解析的时候，不要解析到mall.zhss.com域名对应的LVS上去，最好是seckill.zhss.com单独解析到一个独立的LVS+Nginx服务器上去，nginx之前给大家讲解了直接处理请求从本地磁盘读取静态html文件

秒杀抢购的URL地址必须是独立域名下的地址：mall.zhss.com/seckill，seckill.zhss.com/order?xx=xx&xx=xx

浏览秒杀活动的商品详情页，秒杀商品都是极为热门的商品，详情页浏览量会非常的大，如果说你把商品详情页放在你的Nginx服务器上，所有人都直接从你的Nginx服务器上去读取秒杀商品详情页

网络带宽撑不住，一个普通的商品详情页，无论是网站上，还是手机APP，你以为他最大的内容是什么？就是高清图片，商品详情页里 一般有大量的图片，甚至是嵌入大量的视频，所以说网站仅仅浏览一些html，几kb大小，js和css都没多大，最大的就是那些高清图片，可能一个详情页的所有图片+视频的静态资源，5mb

你的Nginx服务器的带宽可以给多少？每秒钟可以支撑多少流量经过？300mb，同时也就只能让60个人去加载你的详情页，每个人都要加载5mb，差不多就打满了，所以说如果你的详情页都放在Nginx去加载，最大的问题在于他的带宽

大带宽的Nginx服务器，搞很多台，要不然的话，带宽撑不住

大带宽服务器，很贵的，网络带宽如果是在服务器上弄大带宽，价格很高的，如果仅仅是一个1mb的带宽的普通服务器，一年可能小几千，300mb的大带宽服务器，一年可能要上十万，几十万

CDN的计费是走流量的，比如说加载一次商品详情页需要5mb，你在CDN上购买的都是流量资源包，CDN购买一年的1TB的流量资源包，可能就几百块钱，非常便宜，100w mb，加载一次详情页是5mb流量，支撑你每年20w次的详情页，每年加载2000w次详情页，这个成本就很低很低了

你需要把你的秒杀商品详情页指定一个域名，seckill-product.zhss.com/xxx，这个域名必须是解析到CDN产品上去的，直接就会找距离自己最近的CDN服务器去加载图片、视频之类的资源就可以了，css、js也可以的

在这个之前，你需要配置CDN产品的源站站点的IP地址，就是你的秒杀活动商品详情页的Nginx服务器的地址，你可以在CDN的界面上选择一个预热，就是CDN的各个节点直接从你的Nginx服务器上拉取各种静态资源，按照你指定的URL地址去拉取，缓存在CDN的各个节点上

### 18.秒杀商品的库存数据是如何提前加载到缓存的？》

你的这一场秒杀活动，所有商品加起来一共有多少可售卖的库存，就会有多少请求放过来，每个秒杀场次的每个商品，最多就放可售库存一样数量的抢购请求过来，就直接利用数据库的行锁来做抢购不就可以了么

update xx set 库存=库存-1，数据库里是有行锁的，可以保证你多线程并发更新一行数据，都是串行起来的，假设你某个商品可以秒杀的数量有1万件，然后瞬间涌入1万请求，一下子就把你的数据库给击垮了

8核16G的机器以及16核32G的机器，部署的MySQL数据库，1万请求，瞬间cpu、内存、磁盘IO、网络IO瞬间会飙升到最高值，服务器接近于崩溃的边缘

秒杀架构，通常来说，都会用Redis或者是其他的NoSQL来做秒杀抢购库存存放的地方，你的每个商品不是要参与秒杀吗，其实一般会把这些参与秒杀的商品的库存，提前加载到Redis缓存里来

无非就是扣减Redis里的库存，一旦库存扣减完毕，直接就宣告这个秒杀商品售罄

可销售库存，锁定库存，已销售库存，还是三个库存，在秒杀管理平台，可以看到这三个指标的实时监控数据

### 19.秒杀抢购过程中的库存超卖问题分析

第一个是检查库存是否足够，足够就执行锁库存

```html
seckill::product::153 = {
    sale_stock_amount: 3000,
    locked_stock_amount: 0,
    saled_stock_amount: 0
} 
```

很简单，加分布式锁啊，秒杀抢购的时候加锁，避免超卖，支付的加锁，避免数据错乱，一直不支付自动释放库存，也加锁，缺点就是，分布式锁的性能并不是特别好，因为他是依托停顿+轮询去检查锁是否释放的，不管怎么说都会产生大量的网络通信，这就会导致并发能力下降了

解决方案

方案一，可以用我们之前讲解过的分布式锁，先获取一个锁，seckill::product::153::lock，Redisson去做，绝对不会在你获得锁的期间有别人去查询和更新库存数据，此时你可以放心的查询，如果可以抢，就扣减库存，释放锁，别人获取锁，再重复

对于高并发来说是不太合适的，Redisson分布式锁的实现源码，Lua脚本+watch dog，锁等待，每个人都得轮询不停的去重新尝试加锁，中间都有一个等待的过程，会产生很多的网络通信的开销

获取锁的人释放了锁，其他的人还都处于锁等待的过程中，此时过了几十ms才有下一个人获取了锁，分布式锁的整体并发的能力不是不太好

方案二，FIFO内存队列，秒杀抢购系统里，对所有进来的请求全部进入一个内存队列排队，按照先后顺序出队再去Redis里执行秒杀抢购逻辑，把针对某个商品的所有抢购请求都hash路由到一台服务器上去，进入一个内存队列，保证对这个商品的抢购都是有序的

缓存和数据库的一致性的方案，就讲了这个内存队列的方案，严格保证顺序，就一定是一致的，内存队列万一你的系统重启或者宕机，可能会导致崩溃，内存队列里的数据就会丢失，万一请求特别多，可能会导致你的内存爆掉，频繁gc

方案三，乐观锁

抢购前先检查是否有可售库存

乐观锁方案，每个库存数据都绑定一个版本号，每次更新的时候用乐观锁判断，是否没变过，如果没变，才可以更新，redis可以做到的，有一个watch机制，而且watch机制可以和pipeline结合起来用

watch一些数据是否有变化，然后通过pipeline一次性提交多个操作，如果有变化提交就失败，否则就成功，提交完之后最后要获取到库存的值，如果发现是负数，那么秒杀就失败了

乐观锁方案会很耗费CPU，他可能会频繁的去更新结果是失败的，因为版本已经别别人变更了，此时他要重新再查询最新的版本额，再次更新，可能很多服务器的很多请求都会处于轮询的状态

电商大厂，做秒杀抢购的库存超卖的解决，都是直接写lua脚本，一下子提交到redis去执行就可以了，redis可以保证lua脚本按照顺序来执行，每个lua脚本的执行都是原子的，就是没人会来影响你

会把查询库存数量是否可以抢购 + 更新一堆库存字段 + 是否抢购成功的返回值，这些逻辑封装在一个lua脚本里，然后提交lua脚本可以Redis去执行，一秒钟上万个请求过来了，其实就是上万个lua脚本提交到Redis内存里去执行

毕竟redis是单线程的，还是可以用分段锁策略优化并发能力的，比如你redis集群部署三个master，那每个商品库存可以拆三个分段，压力均匀在三台机器上，然后可以做转移扣减，就ok了

对于支付或者释放来说，也是乐观锁watch，然后pipeline提交，就可以了

提前把商品的库存，有1万个库存，就把1万个库存数据压入redis里的一个队列里去，抢购的时候，就是不停的从队列里出队，如果出完了，就说明抢购结束

### 20.前端与客户端如何确定秒杀下单成功了？

用户大致分为两种情况，就是在ngxin+lua这一层就直接请求被干掉了，看到的就直接是，不好意思，抢购失败，商品已经没有库存了；在抢购系统的时候，抢购失败了，此时也会看到上述提醒；抢购成功了，看到的文本，可以是类似于，抢购进行中，或者抢购请求处理中，请耐心等待

阿里云，企业用的，购买很多的服务器，也是一种电商，也要支付和下订单，即使你支付成功了，他显示给你的是一段文本，正在支付处理中，请稍等，几秒钟过后，才会有一个页面的跳转，此时已经处理完毕

如果此时他要是退出了这个界面，那就看不到具体的处理情况了，正常情况下，你应该提醒他，请不要离开这个界面，前端/客户端就可以不停的轮询发送请求到后台，检查这个秒杀抢购的订单是否创建成功了

可以页面离开，跳转到支付界面，让你进行订单的支付，后续的全流程，都是电商的核心系统在处理了，跟你秒杀系统就没关系了

### 21.下单成功之后的订单支付逻辑与未支付逻辑》

在一个界面里等待，如果说发现订单创建好了，就可以正常的支付；不停的刷新订单列表，可以查到这个秒杀的订单，此时点击支付也是可以的；会跑定时调度任务，或者是直接用MQ延迟消息，做订单的自动取消

创建成功了一个普通的订单，可以在MQ的延迟队列里发送一个30分钟的延迟消息，30分钟后拿到这个延迟消息，检查订单的支付状态，还没支付就直接关闭掉；创建的是一个秒杀订单，可以在MQ的延迟队列里发送一个10分钟的延迟消息，秒杀订单如果10分钟没支付，直接就取消订单

### 22.MQ消息积压解决方案与秒杀订单延迟问题

MQ里的消息0丢失，消息不会重复，消息积压问题，高可用架构，等等

如何保证，你的秒杀抢购成功的消息绝对不会丢失，消息绝对不能重复

秒杀场次id + 商品id + 用户id + 订单类型（秒杀类型），组合成一个唯一索引，此时才能保证用户在一个秒杀场次里，对一个商品最多只能下一个秒杀类型的订单

就是可以写一个key，秒杀场次id+商品id+用户id，如果发现redis里已经有了，此时就不能重复进行下单了

可能会导致大量的用户，已经无法抢购了，很多人已经抢购成功了，但是也没人可以快速的查到订单去进行支付，大家 会很疑惑，一直等待，可能要几十分钟之后才可以查询到订单去进行支付

此时可以先不用把订单写入订单系统去，直接把订单写入到redis里去，然后让用户直接基于redis来查询订单，再进行支付

拿出来一个通知的时候可以做一个检查，发现这个通知拿到的时间跟这个通知写入到MQ的时间相比，已经超过了2分钟了，20s左右就可以从写入MQ到下订单成功了，此时可以认为MQ那边出现了严重的几十万甚至上百万消息的积压问题

立马启动一个针对消息积压的临时解决方案

对于前端而言，他可以稍微给一个buffer，他定好一个时间，如果超过3分钟还没拉取到订单下成功的通知，此时就直接跳转一个界面，告诉用户说，不好意思，秒杀抢购失败，请重新进行秒杀下单

比如通过快速的释放秒杀库存，一秒钟去调用秒杀库存服务1000次，两台服务器每秒可以调用秒杀库存服务2000次，部署2台服务器，底层基于redis，所以速率可以是很快的，60s * 2000 = 120000万次，积压了50万条消息，4分钟就可以把库存都释放完毕了

不要完全去释放库存，可以把一部分通知继续正常去下订单，同时还在不停的释放库存

## Nginx

### 1.Nginx

Nginx本身虽然是处理HTTP请求的，也就是跑在七层网络协议上的，但是他也是可以做到高并发的，他用的网络通信架构师异步非阻塞，并发架构师多进程机制，他在启动之后是一个主进程和多个子进程，子进程负责处理客户端请求，用的是异步非阻塞模式

主进程负责建立、绑定和关闭socket网络连接

一个worker进程收到请求之后，客户端可以直接去干别的，本身这可以是异步模式的，接着worker进程判断如果IO（比如读取本地磁盘的html，或者是请求后端的Tomcat服务器）不能立马处理，那么就可以去处理别的请求，等IO执行完毕之后，linux内核通知worker进程，worker进程再通知客户端

异步非阻塞，保证了他一个worker进程就可以实现高并发的网络通信架构，处理高并发请求，同时多个worker的多进程机制，也可以让他实现针对高并发的并发模型，只要你的物理机配置足够高，可以多加一些worker进程

nginx把自己内部的大量的功能做成了很多的模块，别人要对nginx内核做一个扩展，很容易的，直接按照他的规范开发一个模块，嵌入到nginx里去执行就可了，nginx处理请求的时候，会先调用很多的模块对请求做一个内存里的处理

要做IO的时候，就提交给内核去执行，非阻塞的IO

多进程架构 + 模块化架构 + 异步非阻塞架构，就是nginx最核心的几大架构

### 2.Nginx使用什么样的IO事件驱动模型

如果在4核8G的服务器上部署一个Tomcat，里面有一些线程并发运行处理请求，Tomat服务器上部署的系统一般每秒就处理几百请求到1000请求就撑死了，但是为什么Redis、Nginx、LVS每秒也能轻松上万请求

你每个线程拿到一个请求，全部得后续执行阻塞式IO，访问数据库也属于通过网络IO跟数据库通信，这也是阻塞IO，你访问Redis或者ES，都是在走网络IO跟他们通信，都是属于阻塞式IO

一个线程每秒才处理510个请求，100个线程，500个请求1000个请求，4核8G的服务器的CPU负载就满了，没法处理更高的并发请求了

nginx是非阻塞的IO，把IO交给内核，自己就去处理别的请求了，等linux处理完请求了再主动通知nginx进程，这个linux内核工作的过程就叫做事务驱动模型，他并不是让nginx自己不停的轮询IO操作进度，而是linux内核主动通知他

linux内核提供的select、poll、epoll、kqueue都是做非阻塞IO的，进程可以快速处理请求，快速提交IO请求给linux内核，自己不用阻塞等待IO请求结果，所以进程是绝对可以高并发处理的，不会卡在一个IO上

这里的IO指的一般是请求后端的Tomcat服务器

select，他是说，针对关注的事件创建描述符集合，包括read、write和exception三种事件描述符集合，然后调用linux内核的select()函数，如果内核返回这个集合的时候，自己轮询三个集合里的事件描述符，不停的看事件是否发生

poll，也是先创建事件描述符集合，然后去轮询事件描述符集合，select要创建三个集合，poll只要创建一个集合

epoll，上面两个都需要进程自己轮询和管理描述符集合，epoll是完全交给内核去做，调用内核接口创建一个有N个描述符的事件列表，给描述符设置自己关注的事件，接着完全是内核自己轮询和管理，有事件发生就回调通知进程

一般都是用epoll

### 3.基于Nginx的Rewrite功能实现域名跳转和域名镜像

ngxin就会跟自己配置文件里的各个server做一个匹配，nginx里配置的每一个server都是一个独立的域名，但是不同的域名其实都可以解析到nginx这里来，只不过说nginx这里收到针对他的不同域名的请求之后，可以去匹配不同的server

```html
sever {
    listen 80;
    server_name view.website.zhss;
    rewrite ^/ http://www.zhss.com/;
}
```

请求http://view.webbsit.zhss/，域名解析到nginx上，nginx判断是自己这个server的，直接做一个域名跳转，最终请求是http://www.zhss.com/去反馈的

```html
server {
    listen 80;
    server_name view.website.zhss   view.website.info;
    if($host ~ website\.info) {
        rewrite ^(.*) http://view.website.zhss$1 parameter;
}
}
```

请求http://view.website.info/order，会跳转给http://view.website.zhss/order

```html
server {
    listen 80;
    server_name view1.website.zhss view2.website.zhss;
    if ($http_host ~* ^(.*)\.website\.zhss$) {
        rewrite ^(.*) http://view.webite.zhss$1;
        break;
}
}
```

请求http://view1.website.zhss/order，http://view2.website.zhss/order会跳转给http://view.website.zhss/order

```html
server {
    listen 80;
    server_name mirror1.webiste.zhss;
    rewrite ^(.*) http://view1.website.zhss$1 last;
}

server {
    listen 81;
    server_name mirror2.website.zhss;
    rewrite ^(.*) http://view2.website.zhss$1 last;
} 
```

域名镜像，多个站点互为主备

### 4.正向代理和反向代理到底指的是什么？

nginx两块应用：读取本地静态资源文件；域名跳转，但是有可能也会有，对老站点老域名跳转到新站点新域名去，多公司的多个二级域名可以把请求转发到公司内部的不同的系统上去；反向代理+负载均衡

正向代理，是局域网内的服务器访问外网的资源，一般很少用，不怎么用；nginx平时做的最多的，其实是反向代理，是服务器对外网提供服务，外网请求进来代理到局域网内的服务器

### 5.Nginx用upstream指令配置后端服务器组

```html
upstream backend_servers {
    server backend1.zhss.com weight=5;
    server backend2.zhss.com fail_timeout=30s;
    server backend3.zhss.com;
}

server {
    listen 80;
    server_name www.zhss.com;
    location / {
        proxy_pass  backend_servers;
}
}
```

weight是权重，max_fails默认是1，在fail_timeout时间范围内，请求失败次数超过max_fails就判定为down，同时down状态维持fail_timetou时间范围，默认就是round robin轮询算法去请求后端服务器

## DDD

### 1.限界上下文、核心域以及通用语言

限界上下文，其实说白了就应该是你们公司里的一个较为核心的系统，有独立的代码仓库，有一个独立的团队负责维护一个系统，就是工作在这个限界上下文里，然后在这个限界上下文里需要对各种核心概念定义一套通用的中文和英文的名词和解释，这就是通用语言，团队每个人对这些中文和英文名词的含义都有共识

一个团队可以同时负责维护多个系统，也就是多个限界上下文，但是多个团队不能在一个限界上下文里工作，也就是多个团队同时修改一个系统的代码，那是不可能的，一个限界上下文就是一个独立的完整的系统，有独立的代码仓库、数据库、测试代码，独立团队，独立通用语言

其实有点类似于国家，不同的国家就是不同的限界上下文，每个国家有自己的语言和发音，就是通用语言，比如同样一个发音，可能在一个国家是这个意思，换了一个国家是另外一个意思了

另外这个核心域的意思，其实就是说，如果你的一个限界上下文，也就是一个系统，是你的公司里极为核心的一个系统，就是一个核心系统吧，举个例子，一个电商平台里，商品、订单、库存、营销、仓储、物流、会员，每个大系统都可以是一个限界上下文，都是独立团队维护，都有自己内部的通用语言，然后他们都是公司最为核心的一些系统，所以这些限界上下文也可以叫做核心域

但是如果是一些非核心系统，比如说什么竞对数据爬虫系统、第三方比价系统、BI报表系统，类似这些，如果不支撑公司核心流程运转，主要是锦上添花的系统，那么他就不算是核心域

### 2.子域有哪几种类型？

DDD建模的时候，主要关注的就是域这个概念，子域，还有好几种类型，其实就是一个大系统；域之间需要做集成，大系统之间的集成；对每个域内部进行服务的划分

每一个限界上下文其实都是一个大平台里的完整子系统，所以对应来说，每一个限界上下文也都可以叫做一个子域，一般在做DDD建模的时候，如果简单一点，直接划分出多个子域，然后划分不同的子域类型就可以了，这其实是对一个大型平台或者大型系统进行建模的方法；各个域内部，各个子系统内部的通用语言建模，类建模，事件建模

必须提一点，即使以前没有DDD的时候，有经验的架构师只不过不用这个术语，然后业务系统建模过程跟DDD是一样的，首先就是对大系统划分各个子系统，各个子系统分派给不同的团队去维护，划分就是根据业务来划分的

子域有几种类型，一个是核心域，就是你的大系统里的最最很的几个子系统，通常我们认为是支撑你公司核心业务运转的那些系统就是不同的核心域，分配的是公司最多的研发资源，投入最大；

一个是支撑子域，这个说白了就是公司里的一些锦上添花的辅助系统，非核心系统，比如说什么爬虫系统、BI系统、竞对分析系统、社会化治理系统，这些系统可能会跟你的核心系统有交互，但是主要是辅助用的，甚至可能找外包来做，分配资源较少

最后一个是通用子域，类似什么HR系统、OA系统、CRM系统、权限系统、认证系统之类的，都有通用解决方案，可以直接找第三方厂商进行采购，然后进行集成，当然也可能是找外包做，或者内部做，但是投入的资源会很少很少1627098

## 数据库

### 1.MySQL

天生就不是用来抗高并发的

所以一般在互联网公司里用MySQL，一定会做这么几块架构：

（1）数据备份和恢复，一般是日备份、周备份，会设定几个级别

（2）高可用架构，也就是做master-slave主从架构，数据实时同步，读写分离开来，一定程度上扩展数据库的读QPS，同时可以做故障自动切换，当然也可以采用MHA之类的其他高可用架构

（3）读写分离：就是上面说的，如果读压力比较大，就多挂几个从库扩容读QPS

（4）分库分表：搞多台数据库服务器组成一个分库分表的集群，然后基于mycat、sharding-sphere之类的中间件去支持，这样可以对数据存储容量进行扩容，同时可以扩展数据库写入TPS

至于说业务场景，说实话，一般的系统，只要没特殊要求，刚开始就都用MySQL就行了，如果后续感觉有点瓶颈了，再用别的数据存储就行1627098499

### 2.NoSQL数据库

Redis（开启持久化，保证数据可能会丢失一点点，但是不会丢失太多），kv，kv读写，数据结构和基于数据结构的复杂操作，读写并发能力极为强悍，主要是基于内存来实现读写操作，轻松可以支持几万QPS，甚至10万QPS

数据存储主要是基于内存，虽然会基于磁盘做持久化，避免数据丢失，全量数据都是放在内存里的，他不适合海量数据的场景，kv存储，热点数据缓存

## 分布式id

### 1、数据库自增主键

1024表，不是依赖每一张表的自增主键，不同的表都从1开始累加id

专门搞一个库，搞一个表，专门用于生成全局唯一id，insert into插入一条数据，他会返回给你一个全局唯一id，然后你把这个id设置给数据，插入分表后的1024张表里去，全局唯一的

优点：超简单，落实起来非常方便，公司有一个统一的库和表，专门用于生成id；或者你自己的系统的库里你专门弄一张表，用来生成id

缺点：单库单表，并发抗不住，一旦达到每秒几千的高并发；不停的在表里插入数据获取id，表数据会越来越多，还得定期清理，很麻烦

适用场景：分库分表是因为数据量大，但是低并发低负载，而且数据库单机有高可用问题，必须上高可用方案，另外是单表数据一直增长也是个问题，一般不会直接投入生产，投入生产环境的时候会用下面说的flickr的数据库唯一id生成方案

### 2、UUID

JDK自带的一个UUID的API就可以生成一个唯一id，字符串，很长

优点：本地生成，没有所谓的并发压力

缺点：太长了！作为主键绝对是不靠谱的！数据库频繁页分裂问题！

适用场景：除数据库主键之外的其他唯一键场景，都适合，生成一个订单编号，或者是别的什么ID，不是数据库的唯一id主键，这个方案一般不考虑在分布式唯一ID生成里，在我们的主题里，其实可以忽略

### 3、Twitter开源的Snowflake方案

核心思想：64个bit位，最高位1个bit是0，41位放时间戳（到毫秒单位，最多使用69年），10位放机器标识（最多把snowflake程序部署在1024台机器上），12位放序号（每毫秒，每台机器，可以顺序生成4096个ID）

64个bit位，通过时间戳+机器id+序号 -> long类型的唯一id

snowflake程序分布式部署在多台机器上，每台机器生成的每个ID，都是这一毫秒、机器id、序号，每台机器每毫秒最多4096个ID，绝对够用了，分布式方案可以抗高并发，大不了加机器，最多1024台机器，纯基于内存生成，性能很高

优点：高性能，高并发，集群化，可伸缩，最多扩展1024台机器，ID绝对够用，高可用

缺点：光是开源算法还不用，还得考虑时钟回拨等一系列问题，如果要解决那堆问题，需要开发很多机制，开发完了还得独立部署，有独立部署和维护的成本

适用场景：中大型公司，有高并发生成唯一ID场景，基于snowflake算法自研，加入时钟回拨解决方案，多机房方案，等等，各种生产方案，有人力去维护，有少数大厂采用了这个方案，可以作为生产级方案，但是需要解决很多问题

### 4、Redis自增机制

核心思想：Redis单线程，绝对有序自增，incrby；集群部署，比如5台机器，那么每台机器的初始值依次为1、2、3、4、5，每台机器的自增步长是5，第1台机器就是1、6、11、16、21，第2台机器就是2、7、12、17、22，以此类推，直到第5台机器就是5、10、15、20、25

优点：不用额外开发，一般公司都提供redis集群，直接用就行，高性能，高并发，集群化，高可用，都可以实现，全局唯一

缺点：客户端需要自己封装，基于Jedis去封装，客户端里需要写死Redis机器数量，每次获取1个ID，都是找到一台机器，然后按步长去incrby，接着返回给系统；而且扩容麻烦，如果5台机器抗不住并发了怎么办？扩容的时候加机器，客户端需要修改代码，或者基于动态感知，这其实也有开发成本，另外扩容的时候，步长就会改变，那之前的ID怎么办？都得重新洗掉，全部从头开始计算，极为麻烦

适用场景：鉴于他的缺点，一般不用redis集群玩自增主键生成；分库分表了，然后每秒在万左右的高并发，但是可预见的不会达到几万以及十万级的并发，那么此时可以用Redis单机去生成自增主键，避免redis集群扩容的步长改变问题；但是还得部署Redis主从同步+哨兵高可用，可是主从同步是异步的，有id重复问题，所以最终生产一般不用

主节点：1 -> 6

从节点：1 -> 6

### 5、时间戳+业务id

时间戳 + 起点编号 + 车牌号，有可能会重复，两个人，在同一毫秒，同一个起点，打车

核心思想：比如打车软件，可以用时间戳+起点编号+车牌号作为一个id，业务组合上是不会有重复的，订单id、订单编号；比如电商订单，可以用时间戳+用户id，一个用户在1毫秒内一般最多就下一个订单，一般不会重复，除非用户基于程序刷单，否则手点的情况下，这个组合id一般没问题，还可以加个下单渠道、第一个商品id等其他业务id组合起来

优点：实现简单，没额外成本，没并发之类的扩容问题

缺点：有的业务场景（比如订单之类的），还可以用这种方案，但是有的业务场景可能根本没法通过业务来组合，而且始终担心有重复问题

适用场景：很多大厂都用这个方案，做订单编号这些，但是分库分表不光是订单，还有什么用户、账号以及各种其他的业务场景，所以部分适用于生产，推荐第一优先级先考虑这个方案

### 6、flickr（雅虎旗下的图片分享平台）公司的方案

```html
CREATE TABLE `uid_sequence` (  
  `id` bigint(20) unsigned NOT NULL auto_increment,  
  `stub` char(1) NOT NULL default '',  
  PRIMARY KEY  (`id`),  
  UNIQUE KEY `stub` (`stub`)  
) ENGINE=MyISAM;

REPLACE INTO uid_sequence (stub) VALUES ('test');  
SELECT LAST_INSERT_ID();  
```

replace into语法替代insert into，避免表行数过大，一张表就一行数据，然后再select获取这个表的最新id，last_insert_id()函数是connection级别的，就你这个连接的最近insert生成的id，多个客户端之间没影响

当然，其实也可以优化成这样，就是每次你一台机器要申请一个唯一id，你就REPLACE INTO uid_sequence (stub) VALUES ('192.168.31.226')，用你自己机器的ip地址去replace into，那么就你自己机器会有id不停自增，完了用select id from table where stub=机器地址，就可以了

最多如果你要考虑到多线程并发问题，那么就在机器地址后加入线程编号，这样一台机器的不同线程，都是对自己的id在自增

这个方案本质跟第一个方案没区别，唯一优化就是用replace into替代了insert into，避免表数据量过大，缺点也在于数据库并发能力不高，所以适用场景，就是分库分表的时候，低并发，用这个方案生成唯一id，低并发场景下可以用于生产

而且一般会部署数据库高可用方案，两个库设置不同的起始位置和步长，分别是1、3、5，以及2、4、6

### 7、基于flickr方案的高并发优化

有一种变种方案，是基于flickr方案的高并发优化，他核心问题在于每一次生成id都得找数据库，所以这就是并发瓶颈，所以这里可以把数据库优化为号段，而不是id号，什么意思呢？一起来看看

两台数据库，起始offset不同，步长一样，高可用性，先通过其中一台库来执行递增操作，replace into，select获取，客户端很重要

每台机器都引入一个自己封装的客户端，只要一旦服务启动，客户端就直接有一个线程采用flickr方案获取一个id，但是他仅仅代表的是一个号段，什么意思呢？比如说，一个服务启动，通过flickr方案的replace into拿到一个id，假设是1吧

写死，每个号段是10000个id号

此时你的号段可以配置为一个号段是10000个id号，那么此时你这个号段的起始id就是1 * 10000，然后可以把起始id设置到AtomicLong里去，还可以用volatile保存一下号段的最大id，也就是（n + 1） * 10000，就是2 * 10000，20000

volatile AtomicLong idGenerator = new AtomicLong(10000)

volatile long maxId = 20000

所以这个号段的id就是[10000, 20000，20000是不包含在内的

接着服务里如果要获取唯一id，直接找你封装的客户端，IdGenerator.next()，每次拿一个id，就是AtomicLong.incrementAndGet()，直接原子递增，这样你大部分的id获取，都是在内存里通过号段内递增实现的

高并发问题，解决了！！数据库仅仅用于维护号段罢了

高可用 -> 两台数据库（不同起始offset，相同步长）+ 故障自动转移

表数据量不会太大

支持多业务

高并发 + 高性能 -> 不需要伸缩和扩容

如果拿到了号段里最大id，此时对获取id的请求得阻塞住，只要拿到的id大于等于了最大id，请求全部自己陷入阻塞，比如大家都去while循环阻塞，过一会儿再次获取id，跟最大id比较

```html
volatile boolean needRefresh = false;

while(next() >= maxId) {
    needRefresh = true;
    sleep(10ms)
}

15

AtomicLong(150000)
maxId = 160000
```

发号器客户端的线程，定时轮询，needRefresh = true，此时一旦发现这个问题，此时就重新利用flickr方案获取一个新的号段，再次设置AtomicLong里的初始id以及更新最大id，在这个过程中别的任何一个线程来获取id都会发现AtomicLong自增值比最大id是大的

即使是发号器客户端线程，刚刚设置了AtomicLong的值，然后还没设置volatile的最大id值，此时别的线程在while循环过程中获取了id，AotmicLong自增值一定大于之前的最大id值，也会继续陷入阻塞的

只有 当发号器客户端线程更新了volatile最大id值之后，其他线程才会在while循环之后，发现AtomicLong自增值是小于最大id值的，此时就可以继续工作了，这种情况通常是很少的，所以大部分情况下，各个服务都是基于本地的号段在内存里获取id，而且全局上还是唯一的，没有高并发问题，数据库的并发也是很低的

这个方案的唯一缺点就是，每次重启服务，就会浪费一个号段里还没自增到的大量id，重启后又是新的号段了，但是如果要优化，可以在spring销毁事件里，发号器内部设置一个volatile标识，不允许获取id了，接着 把AtomicLong的值持久化到本地磁盘，下次服务重启后直接从本地磁盘里读取，就不会浪费了

高可用 -> 两台数据库（不同起始offset，相同步长）+ 故障自动转移

表数据量不会太大

支持多业务

高并发 + 高性能 -> 不需要伸缩和扩容

号段自动更新 + 号段本地磁盘持久化

其实这个优化以后的方案，就可以投入生产了，确实也有个别大厂是这么做的，也运行的很好。如果一定要说这个方案有什么弊端，那就是，归根结底，还是有一个数据库这么个外部依赖，其实如果方案真做好了，你还得考虑数据库的高可用方案这些东西，就是牵扯到了外部依赖，就容易做的很重

另外一个问题，就是对于这个方案，你还得去做步长的配置，那么到底允许多长的步长呢？是否允许用户自己配置呢？如果不允许，你固定一个步长，那个步长会不会在一些特殊高并发场景下，比如你1000作为步长，1000个号瞬间被秒光，一个服务每秒都得请求一次数据库获取新的号段，此时你有上千个服务实例，数据库不还是抗不住？

所以，这个方案适合一些没有特殊超高并发的场景，而且扩展性和灵活性不是很强，总是让人担心他的号段步长会出一些问题，但是在一些普通场景下，其实一般可能也没什么问题，所以有普通高并发场景的生产环境，还是可用的

基于数据库的方案就是flickr方案以及flickr高并发优化方案，但是没有snowflake生产级方案那么具备普适性，snowflake方案不涉及什么号段问题，也不会额外依赖数据库，不需要考虑数据库高可用之类的，他自己就是peer-to-peer的一个集群架构，随时可以扩容

时间戳+业务id，相当好用，推荐第一选择是他，能用时间戳+业务id的，就别搞分布式id生成，如果不行的，再考虑flickr方案或者snowflake方案

### 8.Snowflake生产方案：基于ZK来维护集群机器ID

flickr公布的基于数据库的一个方案，以及他的一个高并发变种方案（阿里开源了一个数据库中间件，TDDL，唯一ID生成方案，思想，号段思想），始终还是强依赖数据库去生成ID的，太重了

核心思想：64个bit位，最高位1个bit是0，41位放时间戳（到毫秒单位，最多使用69年），10位放机器标识（最多把snowflake程序部署在1024台机器上），12位放序号（每毫秒，每台机器，可以顺序生成4096个ID）

64位的long类型的ID里，就会包含上机房ID的概念，一个机房一台机器的每一毫秒可以生成4096个唯一ID

5个bit位放机房ID，5个bit位放机器ID

机器id从哪儿来？少量的机器可以硬编码直接在磁盘文件里写，但是这样非常的不灵活，意味着扩容缩容，都有很多手工成本

所以这块可以采用zk的持久化顺序节点来实现，每台机器启动都去zk指定目录下创建持久化的顺序节点，拿回来自己的顺序号，就是自己的机器id了，直接写入本地磁盘文件，下次就直接用了，不需要每次都访问zk，这就完美解决了，扩容的时候他会自动从zk里获取到自己的顺序号作为机器id

集群部署的注册、心跳与健康检查

两套方案，第一种，用Nginx负载均衡，服务可以跟nginx做心跳，请求都到nginx去，暴露出去的是http接口，但是不太喜欢这种；第二种，基于微服务架构，比如eureka、nacos，都可以，做个服务注册，保持心跳，然后调用的人引入依赖，直接服务发现，定时刷新服务列表，故障自动感知，接着请求就可以了

如果要做多机房，启动的时候，得zk的指定机房下去创建顺序节点获取序号，需要给每个机房里的机器都维护一个机房id，写死也是没问题的，一般给公司没几个机房，然后10个bit位的机器ID，拆分一下，5个bit位给机房ID，5个bit位给机器ID，这就可以了

阶段一，工程结构，maven profile的概念，多机房部署，针对prod profile，可以做两个，双机房部署的，机房A的prod profile，机房B的prod profile，不同的机房的prod profile的配置文件里会有一个自定义的配置，机房ID

然后不同机房一般都会部署独立的服务注册中心，你不同机房的业务系统都会访问机房内的snowflake集群，有机房ID作为标识，保证ID不会重复

### 9.Snowflake生产方案：时钟回拨问题解决思路

核心思想：64个bit位，最高位1个bit是0，41位放时间戳（到毫秒单位，最多使用69年），10位放机器标识（最多把snowflake程序部署在1024台机器上），12位放序号（每毫秒，每台机器，可以顺序生成4096个ID）

ID里必须包含时间戳，可是有个问题，那是依赖机器时间的，机器是有一个时钟回拨问题的，就是可能机器时间会往回拨，比如说假设你要是在做时钟同步，让每台服务器都跟一个时钟服务器进行时钟同步，那么就可能会出现时钟回拨，

此时肯呢个会出现重复时间，重复时间之后，就绝对有可能会出现重复ID

这实际上也是snowflake方案最大的生产问题

第一种办法，就是关闭时钟同步，避免产生时钟同步问题，不过这个不太现实，因为强依赖时间的系统，一般都得做时钟同步，避免时间严重错误，在虚拟机上部署一些东西，玩儿虚拟机，休眠，再次恢复之后往往虚拟机里的时间和宿主机的时间是不同步的

导致一些大数据的分布式系统会崩溃掉，节点之间通信会依赖时间戳进行比对，心跳过慢，就会导致节点挂掉

第二种办法，记录下来上一次生成ID的时间，如果发现本次生成ID的时候，时间戳小于上次的时间戳，说明时钟回拨了，此时就这个时间内不允许生成ID，一直等，等待到当前时间追上上一次生成时间，问题在于，万一回拨的时间太多了呢？可能要等很久，影响了系统的可用性，所以也不是特别好的办法

内存里可以存上一次生成唯一ID的时间戳，时钟回拨了，把当前时间戳会回拨到上次时间戳 之前，请求过来，要生成唯一ID，你不要直接就返回一个ID给他，你先做一个比较，如果你发现当前时间戳跟上一次生成唯一ID的时间戳想比，比他小

判定，时钟回拨，只要你生成ID，就有可能会发生ID的重复

可用性这么差的话，人家业务服务万一此时是要生成一个账单数据，申请一个ID，此时你好不容易等待了几百毫秒之后，你还告诉他你内部异常，没法获取到唯一ID，反复的重试，你会影响他的业务服务的运行

第三种办法，针对第二种办法的优化，如果发现时钟回拨太狠了，比如超过了1分钟，此时直接就报警，同时不再对外提供服务，把自己从集群里摘了，比如你要是基于微服务注册中心进行注册的，就得主动做一个下线

当你发现当前时间戳比上一次生成ID的时间戳要小，发现时钟回拨了，判断一下，回拨了多少毫秒/秒，比如说回拨时间在500ms以内，此时可以hang住请求，等待500ms，等到500ms之后，当前时间戳比上一次生成ID的时间戳要大了

此时就可以正常生成唯一ID返回给业务方了，对于业务方而言，仅仅是在个别少数的时钟回拨的情况之下，请求平时只要50ms，500ms，还在接受范围之内，所以说还是可以的，只不过请求慢了一些

如果你要是发现你当前时间戳和上一次生成唯一ID的时间戳想比，你一比较，就发现超过了500ms了，超过了500ms了，但是在5s之内，此时你可以返回一个异常状态+异常持续时间给客户端，不要说有问题，可以通知他自行进行重试

重试机制，最好不要让业务方自己去做，你完全可以去封装一个你的唯一ID生成服务的客户端，基于RPC请求你的接口，但是你在自己的客户端里封装一个自动重试的机制，他一旦发现某台服务器返回的响应说自己短时间内没法提供服务，他自动就去请求其他机器上的服务获取唯一ID了

如果要解决时钟回拨，一般是第二种和第三种结合在一起来用，但是被动等待甚至主动下线，总是影响系统可用性的，都不是特别好

服务端的时钟回拨检测机制 + 客户端自己封装

1s以内：阻塞请求等待，客户端的超时时间，应该也是1s，暴露1s内每一毫秒生成过的唯一ID最大的序号，根据当前时间戳的毫秒，定位到之前生成过ID的这一毫秒的最大ID序号，此时继续生成ID，直接在之前生成过的这一毫秒的最大ID序号基础上递增就可以了，优化之后，就可以保证不需要阻塞等待

1s~10s之间：返回异常码和异常持续时间，客户端在指定时间内不请求这台机器

10s以上：返回故障码，请求服务注册中心让自己下线，客户端收到故障码之后，就直接把这个机器从服务机器列表里剔除掉，不请求他了，后续等到那台机器部署的ID服务他发现自己的时间可能过了几秒钟，缓过来了，恢复了，可用了，就可以再次进行服务注册，你客户端刷新服务注册列表的时候，就会发现他，此时可以再次去请求他

第四种办法，要在内存里维护最近几秒内生成的ID值，一般时钟回拨都是几十毫秒到几百毫秒，很少会超过秒的，所以保存最近几秒的就行了，然后如果发生了时钟回拨，此时就看看回拨到了哪一毫秒，因为时间戳是毫秒级的，接着就看那一毫秒

从那一毫秒生产过的ID序号往后继续生成就可以了，后续每一毫秒都是依次类推，这样就可以完美避免重复问题，还不用等待

但是这里也得做一个兜底机制，就是比如你保留最近10s内每一毫秒生成的ID，那么万一时钟回拨碰巧超过了10s呢？此时这种概率很低，你可以跟二三两个方案结合，设置几个阈值，比如说，你保留最近10s的ID，回拨10s内都可以保证不重复，不停顿；如果超过10s，在60s内，可以有一个等待的过程，让他时间前进到你之前保留过的10s范围内去；如果回拨超过了60s，直接下线

上一次生成唯一ID的时间戳也没了，最近1s内每一毫秒的最大ID序号也没了，重启之后，出现了时间回拨，发现不了时间回拨问题，其次也没有办法继续按照之前的思路去生成不重复的唯一ID了

## Spring Boot

### 1.Spring Boot项目的核心运行原理介绍

直接运行main方法，main方法会通过SpringApplication来进行启动，此时必然会干的几个事儿包括了，启动内嵌的tomcat作为web容器，初始化spring容器，基于自动装配把第三方框架的bean都初始化好注入spring容器，spring容器把所有打了注解的自己写的bean都初始化好放到容器里，包括了spring mvc的controller，mybatis的mapper

而且往往会把自定义的bean跟第三方框架的bean进行自动注入

最后tomcat启动完毕，可以接收http请求，spring容器和你自定义的bean，第三方框架的bean，全部初始化好，依赖注入好，spring mvc到spring到mybatis到其他框架，随时可以正常工作

往tomcat发送http请求，系统run起来

### 2.Spring Boot到底是如何实现自动装配的

有一个核心的注解，@EnableAutoConfiguration，他是@SpringBootApplication注解给你带进来的，默认开启自动装配

很关键，他会扫描你的工程里集成的各个jar里面的spring.factories配置文件，这个配置文件是放在每个jar包的META-INF目录下的，里面就注册了这个框架自己的XXXAutoConfiguration

每个第三方框架的XXXAutoConfiguration类都有@Conditional注解指定他生效的条件，这个条件类似于是，比如你有没有引入指定的依赖，有没有给个什么配置，或者 有没有某个bean之类的

完事儿了以后，如果你符合生效条件，那么此时会对XXXAutoCofiguration中定义的bean进行实例化，读取你在application.properties文件里定义的一些框架的具体配置，就能把bean实例化好了，注入spring容器

## hadoop hdfs

### 1.埋点

在APP/网站的前端，要做一个东西，叫做埋点，在APP上，有人点击了一下iphone 10这个手机的商品，就要记录一条日志，发送到后台存储起来，如果有在APP上将iphone 10放入了购物车里面，APP也要记录一条日志，发送到后台存储起来

用户在APP手机上胡乱的操作，所有的你的用户行为日志，记录了用户在手机APP上的每一次操作的日志，都会从APP上上传到后台去，后台会将这些日志存储起来

用户行为日志是很多很多的，他只要点击了一次，就会有一条日志出来

100万 * 100次 = 1亿条用户行为日志

数据库，单表建议一般在1000万数据量以下就可以了

### 2.hadoop

hdfs：分布式存储系统，将庞大的数据分布式存储在很多台机器上，hadoop distributed filesystem，hadoop的分布式文件系统

大数据的本质，就是分布式系统，分布式存储系统，分布式资源调度系统，分布式计算系统，分布式流式处理系统，分布式作业调度系统，分布式搜索引擎，分布式NoSQL数据库，分布式数据仓库

各种各样的分布式系统

mapreduce：分布式计算系统，比如说你现在要对100亿条数据进行计算，但是这100亿条数据分布在10台机器上，你该怎么计算呢？难道先针对1台机器上的10亿数据，先算，算好了以后，再算第二台机器上的数据

yarn：分布式资源调度系统，yarn负责将你的计算任务给调度和分发到各个机器上去运行

mapreduce，一个一个的计算任务，你要定义好如何计算和处理每台机器上的数据，基于mapreduce的java api来写java代码的，写java代码还是挺慢的，尤其是出一些数据报表的时候

oracle，几百行的大SQL，很容易就可以写完出一份复杂报表的SQL

大数据技术，hdfs + yarn + mapreduce之后，我还得写java代码，我得用java代码来实现几百行大SQL的计算逻辑，所以现在几乎已经没有人写java代码来进行计算了

做数据分析、统计、出报表，一般都是用SQL的

hive：分布式数据仓库，依赖于mapreduce，干的事情只有一件，将SQL翻译为基于mapreduce的java代码，将你的SQL翻译为基于mapreduce java api的java代码，还是找yarn，提交计算任务，yarn负责将你的计算任务分发到各个机器上去执行，当时有了hive之后，真是解放了全人类，在最开始做大数据开发的时候，还做不了太复杂的报表，只能出一些简单的数据指标和报表，当时开发效率太差了，基于mapreduce来写java代码实现计算的逻辑

flume：分布式日志采集系统，手机APP、网站前端不是会发送大量的日志到后台么？后台接收到了这个日志之后，就需要将这个日志通过flume上传到hdfs上去

最早最早，其实就是用这样的一套东西，就可以支撑最最起码的，针对海量的数据，大量的数据，大数据，用各种各样的分布式系统，实现针对几十亿数据，几百亿数据，甚至是几千亿数据的一个数据分析和统计，产出各种各样的数据报表

大数据技术 = 分布式技术 = 大规模复杂的分布式系统架构

hadoop技术，就是针对大量的数据进行存储、调度和计算的一套分布式系统架构

hbase：分布式NoSQL数据库，他底层是基于hdfs分布式存储来实现的，但是他基于hdfs封装和开发了一套分布式NoSQL数据库，你可以基于hbase实现大量的NoSQL数据库的一些操作，毫秒级~秒级的增删改查

spark生态：分布式计算（替代以前的mapreduce，速度更快，性能更高），spark sql（支持你直接基于spark写大SQL，跑报表统计），spark streaming（针对源源不断过来的数据流，进行分布式的流式计算），spark mllib（基于分布式存储的数据，进行分布式的机器学习）

elasticsearch：分布式数据存储+搜索，基于es分布式存储一些数据，针对数据可以做类似于搜索引擎一样的搜索

kylin：分布式OLAP分析，写一些SQL去跑查询和统计

druid：分布式流式的分析和统计

flink：分布式计算，分布式流式数据的处理

### 3.hdfs，分布式存储

第一个作用，在离线计算里，作为基础的分布式数据存储，供每天凌晨批量计算昨天的数据

第二个作用，在实时计算里，作为基础的分布式数据存储，为hbase分布式NoSQL数据库提供支持，支持实时计算

就是一个分布式存储系统，主要的作用还是在于离线计算里面

**（1）支持超大数据集**

hdfs这种分布式存储，其实为啥要分布式存储呢？就是因为数据量太大了，比如说某个表，有30亿数据，你难道存在mysql里？就一台机器里？所以用了hdfs分布式存储，就是可以放在N多台机器上，每台机器放这个大数据集的一部分，比如就放300万条数据。

所以hdfs定位就是针对这种超大数据集的。

**（2）绝对能够应对硬件的故障**

大数据的理念，是说不要用那种商用的小型机，服务器，商用的存储设备

一遍来说大数据的系统都是部署在普通的机器上面的，一遍来说很有可能就是16核64G的物理机

因为就目前国内的大数据整体情况来看，一般那种外包类的大数据公司，给客户做个项目，大概也就是几十台机器，甚至很多小公司做所谓的大数据，可能就十几台机器；然后如果是中等规模的互联网公司，一般会是上百台机器的规模；如果是那种大型互联网公司，那么上千台机器规模就是很正常的了，甚至是几万台机器

但是一般大数据用的都是普通的机器，比如说那种16核64G的机器，一般不会用那种性能超级高的、稳定性巨好的服务器。所以说这种普通机器其实出故障的概率还是蛮高的，比如说磁盘故障，突然不能读写了，或者是网络故障

那hdfs第一个设计理念，就是可以自动探查到集群中某一台机器故障了，然后可以自动对故障进行恢复，而且速度要比较快一些，比1个小时才检测到故障

**（3）流式数据处理**

这个啥意思呢，就是说hdfs读写文件系统上的数据的时候，是基于流的一种概念来的，英文名词是：streaming access。你现在先别纠结这个是啥意思了，死记硬背就ok了，然后记住，hdfs用这个所谓的流式数据处理，其实主要就是为了保证高吞吐量的文件读写，而不是低延迟的文件读写。

hdfs是用在离线批处理场景的，尤其是数据仓库，数据分析这块。今天凌晨把昨天所有的数据都给在比如半小时内处理完毕。而不是数据来一条你就算一条。

分布式系统，相当于就是你自己用Java开发出来的系统，jvm进程

**（4）简化的数据一致性模型**

同时支持对文件的写和读，很麻烦的，大量的并发冲突问题

因为这个hdfs是为了支持超大数据集，分布式存储，离线批量处理的，所以说，他的数据一致性模型是简化的，在他这里的话，一个文件只能一次写入，然后之后就只能追加，不能随便改之前的数据了

他的理念就是，write-once，ready-many-times，一次写，然后多次读，这样就没有数据读写并发冲突，以及数据如何维护一致性的问题了。

**（5）尽量移动计算，但是不要移动数据**

这个意思就是说，如果你要对分布在多台机器上的数据，进行分布式计算，使用比如mapreduce或者是spark都可以，那么此时尽可能让你的计算任务是靠近这个数据，而不是说在集群里通过网络胡乱传输数据，那样会导致性能极差极差

移动数据

### 4.master-slave模式的分布式系统架构

在hdfs的架构里，有一个namenode进程，可以认为就是个master，就是主人的意思了，在一个普通的hdfs集群架构里，namenode记住只有一个，这个玩意儿你可以认为是整个集群的指挥中心

还有一个进程，叫做datanode进程，每台机器上都有一个datanode进程，负责对这台机器上的数据进行存储的

namenode里面主要放的是所谓的文件系统命名空间，filesystem namespace，说白了，这个东西就是举个例子啊，你在hdfs里的数据都是以目录和文件的形式来组织的

hdfs，分布式文件存储系统，存放的数据的格式都是目录->文件，文件里存放了几百GB的数据

然后呢，你肯定更有很多目录，每个目录下面有子目录，还有很多的文件，对不对啊，就是这个意思了，比如说包含/a，/b，/c三个根目录，/a下面还有/a/hello，/a/hi，之类的子目录，然后每个目录里还有/a/hello/ddd.txt这种文件

所以这套文件系统的目录的层级结构和文件对应关系，就是所谓的filesystem namespace了，然后这套东西就是放在namenode里的

1GB，hdfs分布式存储，把这个文件，拆分成好几个block，每个block是128mb，8个block，尽可能的将8个block放在不同的机器上面

然后还有一个角色叫做datanode，这个玩意儿，说白了，就是每台机器会部署一个datanode节点，然后每个datanode就负责管理自己这台机器上负责存储的数据啊，比如说一个大文件给拆分成了3个部分，每个部分叫做一个block，就是一个文件块，分别在机器01，机器02，机器03上都存了一部分。然后每台机器上都有datanode，就负责管理自己那部分文件啊

所以讲到这里，你还应该知道，那么在namenode里，其实还存储了说，每个文件对应几个block啊，每个block在哪个datanode上啊，所以你可以看到，namenode就是整个hdfs集群的一个大脑啊

比如说你要读取一个文件的数据，那么肯定会找namenode问一下啊，说兄弟我要读取XXX文件，你告诉我这个文件对应哪几个block啊，都在哪几个datanode上存储呢？然后namenode就会告诉你，接着你就要跟各个datanode通信读取他们那上面的block数据出来啊

### 5.文件系统元数据的管理机制

基本上来说，可以把hdfs当做是linux上的文件系统来操作，命令基本上都是差不多的

在hdfs上创建目录，hadoop fs -mkdir -p /user/dir01，创建一个目录层级结构

hadoop fs -rmr，删除目录，mv、cp

linux上是差不多的，hadoop fs -put可以上传本地的大文件到hdfs上去，hadoop fs -get可以将hdfs上的文件给下载下来

形成一系列的文件系统的元数据

目录层级结构，以及目录里有哪些文件，文件 -> block -> 在哪个datanode上面

元数据，是放在namenode上面

每个大文件实际的内容，会被拆分为多个block，放到各个datanode上面去分布式存储

hdfs说白了支持的数据结构，不是mysql那种关系型数据库的库表结构，他支持的是文件系统的层级结构，就是目录-子目录-文件的这种形式。当然其实hadoop生态必然是可以支持类似关系型数据库的库表结构的，但是那是基于hdfs的一个开源项目，hive，干的事儿了，他是针对大数据的数据仓库技术

所以说，基于hdfs就可以创建目录啊，创建文件啊，对文件读写数据啊，然后移动文件啊，删除文件啊，重命名文件啊，balabala的，你能在你win10电脑上的文件的操作，大部分都能在hdfs上干

而且人家hdfs还支持对文件进行quotas就是配额的限制，类似于说限制你某个目录最多只能占用多少磁盘空间了，就这个意思；还支持对文件的权限操作，比如说针对某个用户，对某个目录，可以读，但是不能写，这个文件权限后面讲吧，其实跟linux的文件权限是类似的

所以hdfs支持的文件系统的操作还是蛮丰富的，但是比如linux的一些hard link、soft link之类的概念是不支持的

然后呢，这一整套文件系统相关的元数据，就是目录层级结构，文件，文件和block对应关系，block和datanode对应关系，还有别的文件的一些quotas和权限之类的各种东东，都是存放在namenode里的，这就是所谓的文件系统元数据，英文是：filesystem metadata

你反正对文件的一些比如创建目录拉、删除文件了、重命名文件了，之类的涉及到元数据的操作，都是交给namenode来干的。那么你找人家namenode修改元数据的时候，人家是怎么管理元数据的呢

namenode里有一个东西叫做EditLog，就是编辑操作日志的概念，你比如说创建个目录，那么人家namenode必然往这个edits log里写入一条日志，然后你创建个文件，人家还会再写入一条日志，这个edit log是放在磁盘上的一个日志文件。然后呢，比如整个文件目录组织结构，以及block、datanode的映射关系啊，这些东西存储在FsImage文件里，这个fsimage也是放在磁盘上的文件

然后呢，namenode除了在fsimage文件里存放元数据，还会在内存里保存一份儿，要不然这种元数据，动不动读写文件，不是害死人了，性能绝对是很差的。然后呢，namenode每隔一段时间（这个时间间隔是自己配置的，一个threshold），就会读取磁盘里的edits log出来，全部应用到内存里的fsimage缓存里去，然后将fsimage重新写一份到磁盘里去，接着将edits log给给清空掉

这个操作叫做checkpoint操作，这个checkpoint的时间间隔自己可以配置的。然后在namenode启动的时候，人家也是会从磁盘上读取edits log和fsimage在内存里构造一份缓存数据的

这个checkpoint可以自己配置的，dfs.namenode.checkpoint.period，这个参数配置几秒钟执行一次checkpoint，还有一个，dfs.namenode.checkpoint.txns，这个参数配置当edits log里有多少条数据的时候，就执行一次checkpoint

### 6.hadoop 2.x中的双实例HA高可用机制

在集群里启动两个namenode，然后一个是active状态，一个是standby状态，一个是主，一个是备。所有的操作都是发送给active namenode的，然后standby namenode就是一个热备，不停的同步元数据

但是还要在集群里引入一组节点，叫做journal nodes，一般是启动3个journal nodes，这个journal是啥意思？就是日志的意思，叫做journal，顾名思义，肯定是用来保存edits log这种操作日志的了

每次namenode有一个元数据变更，就要将这个edits log发送给journal nodes里的大多数，什么叫做大多数呢？就是quorum，比如3台journal nodes，大多数就是3 / 2 + 1 = 2,2台就是大多数了，只要namenode发送edit log大多数的journal nodes之后，就认为这个元数据变更是安全的了

standby namenode就一直监控着journal nodes里的edits log变更，只要变更了就会读取edits log，同时应用到自己本地的内存里去，形成一个跟active namenode一致的fsiamge数据在内存里

然后如果说active namenode挂掉了，那么此时standby namenode立刻就会感知到的，然后他会确保自己从journal nodes读取了所有的edits log之后，内存的fsimage绝对是最新的之后，就会将自己切换为active namenode，形成主备切换。这个时候，namenode第一数据不会丢失，因为有journal nodes在里面用多台机器保存着，第二，namenode高可用，一台挂了，另外一台立马接管，数据都是一致的

而且所有的datanode都是配置了两台namenode的，那么datanode会将自己的block report汇报给主备两台namenode，确保他们都能感知到集群里的datanode的状态和block的情况啊。。

那么两台namenode是如何在故障的时候自动faillover的呢？靠的是ZKFC两个进程，就是每个namenode机器上都要跑一个ZKFailoverController的进程，简称之ZKFC，他们俩会不断的监控两个namenode，同时在zookeeper集群上（至少3个节点）维护namenode的状态

如果active namenode挂了，那么ZKFC里的也给HealthMonitor就会监控到，然后就会告诉ZKFC里的一个FailoverController通知说namenode挂了，接着FailoverContrller找ActiveStandbyElector组件说要主备重新选举

ActiveStandbyElector就会基于zk集群完成主备选举，这个过程就不说了，总之会选举出来standby namenode作为主的

然后zk会通知standby机器上的ZKFC中的ActiveStandbyElector组件，ActiveStandbyElector通知FailoverController要切换standby为active了，然后FailoverController再通知standby namenode切换为active namenode

而且journal nodes还仅仅只允许一台namenode给他写edits log，就是为了避免脑裂问题，两台namenode的网络环境不通了，他们俩都以为自己是active往journal nodes写数据，此时只能有一台写

### 7.hadoop 2.x中的HA双实例如何管理元数据

所以如果是hadoop 2.x的双实例HA机制里面，checkpoint是怎么执行的呢？

其实在standy namenode上，会运行一个CheckpointerThread后台线程，他默认是要么1小时一次，要么是有100万条edits log没有合并到fsimage去了，此时就会执行一个checkpoint操作

他执行checkpoint其实非常简单的，因为这个standby namenode有点儿像是hadoop 1.x中的backup node，所以说其实就是将内存中最新的那份fsimage写到磁盘文件上的fsimage文件里去，同时清空掉edits log不就得了

然后会将最新的fsimage文件发送到active namenode上去覆盖之前旧的fsimage，同时将active namenode的edtis logs给清空掉，不就ok了么

### 8.超大文件数据的分布式存储机制

你要是比如往一个文件里写数据，那么肯定就是会在namenode那里根据文件的大小，将这个文件拆分为多个block的，每个block存储一部分数据，每个block是有固定大小的，以前老版本的hdfs都是一个block 64mb的，那太小了，现在一般都是一个block是128mb（目前默认的），或者是256mb比较合适

然后人家namenode会规定好的，哪个block放到哪个datanode上去，他会尽量让各个datanode均衡点儿，然后实际上你的文件就会被hdfs的client拆分为多个block写到各个datanode上去了，datanode把每个block就在自己本地磁盘上存为一个文件就ok了

datanode肯定不会傻到说是把所有文件都放在一个目录里的，那会导致linux的文件读写出问题的，他会建立一个合适的子目录层级结构，建立很多的子目录，然后保证每个目录中的文件数量不会过多

datanode每次启动的时候，都会扫描文件系统里的数据然后生成一份自己本地保存了哪些block的list数据，然后报告给namenode，namenode会做一些同步比对、校验啊之类的事情的。

### 9.基于数据副本的容错机制

为了对集群中的各种机器的故障进行容错，有一个关键的机制，就是副本机制

所以说呢，你可以设置一个关键性的参数，叫做replication factor，号称是叫做复制因子，其实谁知道什么鬼因子的，说白了就是你的每个block要复制几份副本到其他的机器上去，那么如果某台机器挂了，这样好了啊，其他机器上有一模一样的block副本。这个replication factor可以整体设置一下，也可以对每个文件设置一下，然后后续还可以修改

那么在写文件的时候，假如说默认的每个block就是3副本，此时namenode会先根据一个复制算法挑选出来3个datanode，每个datanode放一个block，返回给客户端了。客户端先第一个datanode写入一个block，接着datanode将这个block复制给第二个datanode，然后第二个datanode再将block复制给第三个datanode。

rack aware

namenode在分配block到datanode时候，有一个关键性的机制，叫做机架感知特性，这啥意思呢？就是hdfs集群里的机器与机器之间不是肯定是要进行通信的么，然后一个机架上的机器之间通信速度，要比不同机架上的机器之间的通信速度快的多了。然后namenode比如默认一般一个block是3个副本，你就可以把2个副本放在一个机架上，然后第3个副本放在另外一个机架上。

这样的话，在一个机架里，同步复制2个副本，通信速度很好，仅仅只有一个副本是同步到另外一个机架上去的，确实会影响一点写的速度，但是总比你在三个机架上各方一个副本好吧；然后如果一个机架完全挂了，还有另外一个机架上有一个副本。

这个namenode呢，每隔一段时间就会从各个datanode那里获取一个heartbeat，这是用来确定那个datanode还活着的，所以叫做心跳；还有就是获取一份block report，就是每个datanode报告自己本地可用的block有哪些

这样的话，namenode就可以不断的知道整个集群中的block的情况啦，然后在新创建文件分配block给datanode的时候，不就可以根据各个datanode当前的block数量来均匀的分配了么

在读数据的时候，会优先找离自己最近的那个副本所在的机器，保证读取性能最高

### 10.安全模式到底是用来干什么的？

这个安全模式的机制，是在namenode刚启动的时候，就会进入一个模式，叫做安全模式，safe mode，在这个模式下，hdfs集群是不会进行block的复制的

这个时候namenode会等着从各个datanode获取心跳和block report，然后看看集群里的整体的block情况，以及每个block有几个副本，默认是要有3个副本的。如果一个block有3个副本，那么就ok了，安全了

如果一定比例（80%）的block都是有足够的3个副本的，那么namenode就会退出安全模式，namenode一直处于safe mode状态下，就是因为没有达到一定的比例，block是足够的3个副本的，只有50%的block是有3个副本的

此时如果发现有某个block副本数量不够（比如只有2个副本）的，就指示datanode复制足够的副本数量，那么就ok了

### 11.集群节点故障的容错机制

hdfs这样的一个架构下，集群如何保障某个节点故障时候的容错性呢？

（1）集群节点故障

比如说第一种故障情况：网络分区。啥叫做网络分区？英文就是network partition，说白了就是集群里网络故障了，一部分datanode跟namenode无法痛点了，此时网络环境不就相当于是分成了两块儿了，这就是所谓的网络分区。s

因为master-slave架构的分布式系统，一般都会设计心跳机制，就是datanode会定时发送心跳以及block report到namenode去，那如果网络分区了，namenode肯定会感知到的，因为一部分datanode心跳没发送过来了。

这个时候namenode就会将这些无法发送心跳的datanode标记为dead状态，已经死掉了，然后就不会再让hdfs客户端去读写那些datanode了。默认是10min接收不到心跳才会标记datanode死掉了。而且这个时候datanode上的一些block不就不可用了么？这个时候namenode会检测到，然后会发现一些block的replica副本就不够了，那么此时namenode就会让其他的datanode去复制一些replica保证3副本。

除了这种网络分区以外，还有别的一些故障，比如说datanode所在机器宕机了，或者datanode进程就挂了，或者是那个block对应的文件损坏了，都会让namenode感知到，此时namenode会自动在集群里复制block，保证每个block的三副本。

（2）数据破损

此外还有一种机制，就是hdfs的数据完整性校验机制，在一个客户端上传一个文件到hdfs的时候，其实是会基于文件内容算一个校验和出来的，就是checksum，放到一个隐藏文件里去，也是在hdfs里的。

然后在读取文件内容的时候，会对读取到的文件内容重新算一个校验和，与之前上传时的校验和比对一下，如果不一样说明文件破损了，此时他会尝试对某个block读取其他的副本。

（3）元数据文件损坏

fsimage和edits log都是非常关键的元数据，如果这些文件损坏了，那么hdfs可能就无法正常工作了，如果要保护这个namenode的可用性，可以使用namenode HA部署双机进行热备，出现故障自动切换namenode。

### 12.文件系统的权限模型

其实hdfs的文件系统权限模型，就是跟普通的linux上的文件权限模型是差不多的

说穿了，对任何一个目录和文件，其实都针对3种角色提供了3种权限，就是owner，group，还有others，3种权限是r（读），w（写），x（执行）

drwxr-xr-x，/user目录的权限

d：代表的是说这是一个directory，目录

rwx：针对owner，针对root这个用户，对于/user这个hdfs上的目录，可以读、写、执行（查看，创建文件）

r-x：针对group，supergroup这个权限组，可以读，可以执行，没有w写的权限

r-x：针对除了owner和group以外的其他的用户，也是有r和x两个权限

默认情况下来说，你创建一个文件或者目录的时候，owner就是执行命令的进程的用户，group就是父目录的group

而且后续你对文件或者目录执行操作的时候，hdfs就会检查你是否拥有这个权限

如果在根目录下创建目录或者文件，默认owner就是linux上的用户（root）；group就是supergroup；如果在某个目录里创建子目录或者文件，那么owner也是linux上的用户；group默认是上级目录的group

### 13.支持namenode横向扩展的hdfs联邦架构

如果你现在手头有几万台机器，里面存储了几百亿个目录和文件的元数据，元数据大小达到了几百G的话，那你的Namenode一台机器怎么可能放的下呢？

为了解决这个问题，hdfs后来也是推出了一个功能，federation联邦机制

大家发现一个问题没有，现在的话呢，namenode其实哪怕是HA架构，但是也是有问题的，因为hdfs所有的元数据实际上都是放在内存里的，大家已经发现这个问题了吧？所以说怎么办呢？

如果说hdfs集群规模超大，几万台机器，然后大量的目录和文件，元数据的量都达到了几百G，一台机器的内存足够吗？肯定是不够的

所以说hdfs后来出了一个federation联邦架构

这个大概什么意思呢？其实就是说，可以搞多个active namenode，然后每个active namenode可以放一部分元数据，这不就可以横向扩展namenode数量了么？然后每个active namenode再挂一个standby namenode，不是每个namenode同时也是高可用了么？

所以大概就是这么个架构，接下来图解，说一下federation联邦架构的原理

每个namenode都有一个block pool的概念，这里面就是这个namenode管理的所有的block，但是所有的block还是统一存放在datanode集群上的，datanode照样跟所有的namenode进行通信，汇报自己的情况，等等

一个namenode上管理的namespace（命名空间，你可以理解为就是一部分元数据吧），跟对应的block pool结合起来，称之为一个namespace volume。

至于具体的配置就在这里不做了，因为我们的时间有限，不可能每个技术都展开来讲解，这里我们还是专注在hdfs作为一个大规模分布式文件系统的内核源码的角度来讲解这个课程

你可以给namenode机器的配置特别好，物理机，32 core，128G内存，容纳的元数据已经很大了，大部分公司所谓的大数据集群，也不过就是几十台机器，几百台机器，几千台机器的大数据集群的公司不多了

### 14.分布式存储系统的架构

（1）hdfs集群的运行：master-slave架构，集群启动，注册与心跳

（2）元数据的管理：fsimage & edits log，创建目录等等大量的元数据的修改，如何管理

（3）大文件的上传：分布式存储，各种通信的细节，副本的复制

（4）集群的容错：block上报和管理，副本数量的监控，自动下发复制指令

（5）大文件的下载：分别依次下载block，最终组装成一个大文件

## kafka

### 1.吞吐量，延迟

写数据请求发送给kafka一直到他处理成功，你认为写请求成功，假设是1毫秒，这个就说明性能很高，延迟

kafka，每毫秒可以处理1条数据，每秒可以处理1000条数据，这个单位时间内可以处理多少条数据，就叫做吞吐量，1000条数据，每条数据10kb，10mb，吞吐量相当于是每秒处理10mb的数据

### 2.Kafka是如何利用顺序磁盘写机制实现单机每秒几十万消息写入的？

直接写入os的page cache中，文件，kafka仅仅是追加数据到文件末尾，磁盘顺序写，性能极高，几乎跟写内存是一样高的。磁盘随机写，你要随机在文件的某个位置修改数据，这个叫做磁盘随机写，性能是很低的，磁盘顺序写，仅仅追加数据到文件末尾

而且写磁盘的方式是顺序写，不是随机写，性能跟内存写几乎一样。就是仅仅在磁盘文件的末尾追加写，不能在文件随机位置写入

假设基于上面说的os cache写 + 磁盘顺序写，0.01毫秒，低延迟，高吞吐，每毫秒可以处理100条数据，每秒可以处理10万条数据，不需要依托类似spark straeming那种batch微批处理的机制

正是依靠了这个超高的写入性能，单物理机可以做到每秒几十万条消息写入Kafka

这种方式让kafka的写性能极高，最大程度减少了每条数据处理的时间开销，反过来就大幅度提升了每秒处理数据的吞吐量，一般kafka部署在物理机上，单机每秒写入几万到几十万条消息是没问题的

这种方式是不是就兼顾了低延迟和高吞吐两个要求，尽量把每条消息的写入性能压榨到极致，就可以实现低延迟的写入，同时对应的每秒的吞吐量自然就提升了

所以这是kafka非常核心的一个底层机制

而且这里很关键的一点，比如rabbitmq这种消息中间件，他会先把数据写入内存里，然后到了一定时候再把数据一次性从内存写入磁盘里，但是kafka不是这种机制，他收到数据直接写磁盘

只不过是写的page cache，而且是磁盘顺序写，所以写入的性能非常高，而且这样不需要让kafka自身的jvm进程占用过多内存，可以更多的把内存空间留给os的page cache来缓存磁盘文件的数据

只要能让更多的磁盘数据缓存在os cache里，那么后续消费数据从磁盘读的时候，就可以直接走os cache读数据了，性能是非常高的

### 3.Kafka是如何利用零拷贝和页缓存技术实现高性能读取的？

那么在消费数据的时候，需要从磁盘文件里读取数据后通过网络发送出去，这个时候怎么提升性能呢？

首先就是利用了page cache技术，之前说过，kafka写入数据到磁盘文件的时候，实际上是写入page cache的，没有直接发生磁盘IO，所以写入的数据大部分都是停留在os层的page cache里的

这个本质其实跟elasticsearch的实现原理是类似的

然后在读取的时候，如果正常情况下从磁盘读取数据，先尝试从page cache读，读不到才从磁盘IO读，读到数据以后先会放在os层的一个page cache里，接着会发生上下文切换到系统那边，把os的读缓存数据拷贝到应用缓存里

接着再次发生上下文二切换到os层，把应用缓存的数据拷贝到os的socket缓存中，最后数据再发送到网卡上

这个过程里，发生了好几次上下文切换，而且还涉及到了好几次数据拷贝，如果不考虑跟硬件之间的交互，起码是从os cache到用户缓存，从用户缓存到socket缓存，有两次拷贝是绝对没必要的

但是如果用零拷贝技术，就是linux的sendfile，就可以直接把操作交给os，os看page cache里是否有数据，如果没有就从磁盘上读取，如果有的话直接把os cache里的数据拷贝给网卡了，中间不用走那么多步骤了

对比一下，是不是所谓的零考贝了？

所以呢，通过零拷贝技术来读取磁盘上的数据，还有page cahce的帮助，这个性能就非常高了

### 4.Kafka的底层数据存储结构：日志文件以及offset

基本上可以认为每个partition就是一个日志文件，存在于某台Kafka服务器上，然后这个日志里写入了很多消息，每个消息在partition日志文件里都有一个序号，叫做offset，代表这个消息是日志文件里的第几条消息

但是在消费消息的时候也有一个所谓的offset，这个offset是代表消费者目前在partition日志文件里消费到了第几条消息，是两回事儿

### 5.Kafka是如何通过精心设计消息格式节约磁盘空间占用开销的？

kafka的消息格式如下：

crc32，magic，attribute，时间戳，key长度，key，value长度，value

kafka是直接通过NIO的ByteBuffer以二进制的方式来保存消息的，这种二级制紧凑保存格式可以比使用Java对象保存消息要节约40%的内存空间

然后这个消息实际上是封装在一个log entry里的，你可以认为是一个日志条目吧，在kafka里认为每个partition实际上就是一个磁盘上的日志文件，写到parttion里去的消息就是一个日志，所以log entry就是一个日志

这个日志条目包含了一个offset，一个消息的大小，然后是消息自身，就是上面那个数据结构，但是这里要注意的一点，就是这个message里可能会包含多条消息压缩在一起，所以可能找一条消息，需要从这个压缩数据里遍历搜索

而且这里还有一个概念就是消息集合，一个消息集合里包含多个日志，最新名称叫做RecordBatch

后来消息格式演化为了如下所示：

（1）消息总长度

（2）属性：废弃了，已经不用

（3）时间戳增量：跟RecordBatch的时间戳的增量差值

（4）offset增量：跟RecordBatch的offset的增量差值

（5）key长度

（6）key

（7）value长度

（8）value

（9）header个数

（10）header：自定义的消息元数据，key-value对

通过时间戳、offset、key长度等都用可变长度来尽可能减少空间占用，v2版本的数据格式比v1版本的数据格式要节约很多磁盘开销

### 6.如何实现TB量级的数据在Kafka集群中分布式的存储？

有一个很大的问题，就是不可能说把TB量级的数据都放在一台Kafka服务器上吧？这样肯定会遇到容量有限的问题，所以Kafka是支持分布式存储的，也就是说你的一个topic，代表了逻辑上的一个数据集

你大概可以认为一个业务上的数据集合吧，比如说用户行为日志都走一个topic，数据库里的每个表的数据分别是一个topic，订单表的增删改的变更记录进入一个topic，促销表的增删改的变更记录进入一个topic

每个topic都有很多个partition，你认为是数据分区，或者是数据分片，大概这些意思都可以，就是说这个topic假设有10TB的数据量需要存储在磁盘上，此时你给他分配了5个partition，那么每个partition都可以存放2TB的数据

然后每个partition不就可以放在一台机器上，通过这个方式就可以实现数据的分布式存储了，每台机器上都运行一个Kafka的进程，叫做Broker，以后大家记住，borker就是一个kafka进程，在一台服务器上就可以了

### 7.如何基于多副本冗余机制保证Kafka宕机时还具备高可用性？

这里就有一个问题了，如果此时Kafka某台机器宕机了，那么一个topic就丢失了一个partition的数据，此时不就导致数据丢失了吗？所以啊，所以对数据做多副本冗余，也就是每个parttion都有副本

比如最基本的就是每个partition做一个副本，副本放在另外一台机器上

然后呢kafka自动从一个partition的多个副本中选举出来一个leader partition，这个leader partition就负责对外提供这个partiton的数据读写，接收到写过来的数据，就可以把数据复制到副本partition上去

这个时候如果说某台机器宕机了，上面的leader partition没了，此时怎么办呢？通过zookeeper来维持跟每个kafka的会话，如果一个kafka进程宕机了，此时kafka集群就会重新选举一个leader partition，就是用他的某个副本partition即可

通过副本partition可以继续体统这个partition的数据写入和读取，这样就可以实现容错了，这个副本partition的专业术语叫做follower partition，所以每个partitino都有多个副本，其中一个是leader，是选举出来的，其他的都是follower partition

多副本冗余的机制，就可以实现Kafka高可用架构

### 8.保证写入Kafka的数据不丢失：ISR机制到底是什么意思？

光是依靠多副本机制能保证Kafka的高可用性，但是能保证数据不丢失吗？不行，因为如果leader宕机，但是leader的数据还没同步到follower上去，此时即使选举了follower作为新的leader，当时刚才的数据已经丢失了

ISR是：in-sync replica，就是跟leader partition保持同步的follower partition的数量，只有处于ISR列表中的follower才可以在leader宕机之后被选举为新的leader，因为在这个ISR列表里代表他的数据跟leader是同步的

如果要保证写入kafka的数据不丢失，首先需要保证ISR中至少有一个follower，其次就是在一条数据写入了leader partition之后，要求必须复制给ISR中所有的follower partition，才能说代表这条数据已提交，绝对不会丢失，这是Kafka给出的承诺

### 9.如何让Kafka集群处理请求的时候实现负载均衡的效果？

假如说很多partition的leader都在一台机器上，那么不就会导致大量的客户端都请求那一台机器？这样是不对的，kafka集群会自动实现负载均衡的算法，尽量把leader partition均匀分布在集群各个机器上

然后客户端在请求的时候，就会尽可能均匀的请求到kafka集群的每一台机器上去了，假如出现了partition leader的变动，那么客户端会感知到，然后下次就可以就可以请求最新的那个leader partition了

### 10.Partition的几个核心offset：高水位offset、LEO代表了什么？

实际上来说，每次leader接收到一条消息，都会更新自己的LEO，也就是log end offset，把最后一位offset + 1，这个大家都能理解吧？接着各个follower会从leader请求同步数据，这是持续进行的

offset = 0 ~ offset = 4，LEO = 5，代表了最后一条数据后面的offset，下一次将要写入的数据的offset，LEO，你一定要明白他的名词

然后follower同步到数据之后，就会更新自己的LEO

并不是leader主动推送数据给follower，他实际上是follower主动向leader尝试获取数据，不断的发送请求到leader来fetch最新的数据

然后对于接收到的某一条数据，所有follower的LEO都更新之后，leader才会把自己的HW（High Water Mark）高水位offset + 1，这个高水位offset表示的就是最新的一条所有follower都同步完成的消息

partition中最开始的一条数据的offset是base offset

LEO和HW分别是干什么的呢？

LEO很重要的一个功能，是负责用来更新HW的，就是如果leader和follower的LEO同步了，此时HW就可以更新

所有对于消费者来说，他只能看到base offset到HW offset之间的数据因为只有这之间的数据才表明是所有follower都同步完成的，这些数据叫做“已提交”的，也就是committed，是可以被消费到的

HW offset到LEO之间的数据，是“未提交的”，这时候消费者是看不到的

HW offset表示的是当前已经提交的数据offset，LEO表示的是下一个要写入的数据的offset

### 11.Leader与Follower上的LEO是如何更新的？

首先leader接收到数据字后就会更新自己的LEO值

接着follower会不断的向leader发送fetch请求同步数据，然后每次一条数据同步到follower之后，他的LEO就会更新，同时leader发送数据给follower的时候，在leader端会维护所有follower的LEO值

follower发送fetch请求给leader的时候会带上自己的LEO值，然后leader每次收到一个fetch请求就会更新自己维护的每个follower的LEO值

所以这里大家要知道的是，leader上是会保存所有follower的LEO值的，这个是非常关键和核心的一点

### 12.Leader与Follower上的高水位offset是如何更新的？

每次leader发送数据给follower的时候，都会发送自己的HW值，然后follower获取到leader HW之后，就会跟自己的LEO比较一下，取里面小的那个值作为自己的HW值，换句话说，如果follower的LEO比leader HW大了，那么follower的HW就是leader HW

但是如果follower的LEO比leader HW小，说明自己明显落后于leader，那么follower的HW就是自己的LEO值

然后leader上的HW就很明显了，那就是主要是他在接收follower的fetch请求的时候，就会在更新自己维护的所有follower的LEO之后，判断一下当前自己的LEO是否跟所有follower都保持一致，那么就会自动更新自己的HW值

这个leader的HW值就是partition的HW值，代表了从这个partition的哪个offset之前可以被消费数据

### 13.Leader与Follower的LEO与高水位如何更新

假设leader收到第一条数据，此时leader LEO = 1，HW = 0，因为他发现其他follower的LEO也是0，所以HW必须是0

接着follower来发送fetch请求给leader同步数据，带过去follower的LEO = 0，所以leader上维护的follower LEO = 0，更新了一下，此时发现follower的LEO还是0，所以leader的HW继续是0

接着leader发送一条数据给follower，这里带上了leader的HW = 0，因为发现leader的HW = 0，此时follower LEO更新为1，但是follower HW = 0，取leader HW

接着下次follower再次发送fetch请求给leader的时候，就会带上自己的LEO = 1，leader更新自己维护的follower LEO = 1，此时发现follower跟自己的LEO同步了，那么leader的HW更新为1

接着leader发送给follower的数据里包含了HW = 1，此时follower发现leader HW = 1，自己的LEO = 1，此时follower的HW有更新为1

5个数据：全部都要往前推进更新，需要2次请求，第一次请求是仅仅是更新两边的LEO，第二次请求是更新另外leader管理的follower LEO，以及两个HW

### 14.高水位机制可能导致leader切换时发生数据丢失问题

基于之前说的高水位机制，可能会导致一些问题，比如数据丢失

假如说生产者的min.insync.replicas设置为1，这个就会导致说生产者发送消息给leader，leader写入log成功后，生产者就会认为写成功了，此时假设生产者发送了两条数据给leader，leader写成功了

此时leader的LEO = 1，HW = 0，因为follower还没同步，HW肯定是0

接着follower发送fetch请求，此时leader发现follower LEO = 0，所以HW还是0，给follower带回去的HW也是0，然后follower开始同步数据也写入了两条数据，自己的LEO = 1，但是HW = 0，因为leader HW为0

接着follower再次发送fetch请求过来，自己的LEO = 1，leader发现自己LEO = 1，follower LEO = 1，所以HW更新为1，同时会把HW = 1带回给follower，但是此时follower还没更新HW的时候，HW还是0

这个时候假如说follower机器宕机了，重启机器之后，follower的LEO会自动被调整为0，因为会依据HW来调整LEO，而且自己的那两条数据会被从日志文件里删除，数据就没了

这个时候如果leader宕机，就会选举follower为leader，此时HW = 0，接着leader那台机器被重启后作为follower，这个follower会从leader同步HW是0，此时会截断自己的日志，删除两条数据

这种场景就会导致数据的丢失

非常极端的一个场景，数据可能会莫名其妙的丢失

### 15.高水位机制可能导致leader切换时发生数据不一致问题

假设min.insync.replicas = 1，那么只要leader写入成功，生产者而就会认为写入成功

如果leader写入了两条数据，但是follower才同步了一条数据，第二条数据还没同步，假设这个时候leader HW = 2，follower HW = 1，因为follower LEO小于leader HW，所以follower HW取自己的LEO

这个时候如果leader挂掉，切换follower变成leader，此时HW = 1，就一条数据，然后生产者又发了一条数据给新leader，此时HW变为2，但是第二条数据是新的数据。接着老leader重启变为follower，这个时候发现两者的HW都是2

所以他们俩就会继续运行了

这个时候他们俩数据是不一致的，本来合理的应该是新的follower要删掉自己原来的第二条数据，跟新leader同步的，让他们俩的数据一致，但是因为依赖HW发现一样，所以就不会截断数据了

### 16.Kafka为Partition维护ISR列表的底层机制是如何设计的？

很多公司比较常用的一个kafka的版本，是0.8.2.x系列，这个系列的版本是非常经典的，在过去几年相当大比例的公司都是用这个版本的kafka。当然，现在很多公司开始用更新版本的kafka了，就是0.9.x或者是1.x系列的

我们先说说在0.9.x之前的版本里，这个kafka到底是如何维护ISR列表的，什么样的follower才有资格放到ISR列表里呢？

在之前的版本里，有一个核心的参数：replica.lag.max.messages。这个参数就规定了follower如果落后leader的消息数量超过了这个参数指定的数量之后，就会认为follower是out-of-sync，就会从ISR列表里移除了

咱们来举个例子好了，假设一个partition有3个副本，其中一个leader，两个follower，然后replica.lag.max.messages = 3，刚开始的时候leader和follower都有3条数据，此时HW和LEO都是offset = 2的位置，大家都同步上来了

现在来了一条数据，leader和其中一个follower都写入了，但是另外一个follower因为自身所在机器性能突然降低，导致没及时去同步数据，follower所在机器的网络负载、内存负载、磁盘负载过高，导致整体性能下降了，此时leader partition的HW还是offset = 2的位置，没动，但是LEO变成了offset = 3的位置

依托LEO来更新ISR的话，在每个follower不断的发送Fetch请求过来的时候，就会判断leader和follower的LEO相差了多少，如果差的数量超过了replica.lag.max.messages参数设置的一个阈值之后，就会把follower给踢出ISR列表

但是这个时候第二个follower的LEO就落后了leader才1个offset，还没到replica.lag.max.messages = 3，所以第二个follower实际上还在ISR列表里，只不过刚才那条消息没有算“提交的”，在HW外面，所以消费者是读不到的

而且这个时候，生产者写数据的时候，如果默认值是要求必须同步所有follower才算写成功的，可能这个时候会导致生产者一直卡在那儿，认为自己还没写成功，这个是有可能的

一共有3个副本，1个leaderr，2个是follower，此时其中一个follower落后，被ISR踢掉了，ISR里还有2个副本，此时一个leader和另外一个follower都同步成功了，此时就可以让那些卡住的生产者就可以返回，认为写数据就成功了

min.sync.replicas = 2，ack = -1，生产者要求你必须要有2个副本在isr里，才可以写，此外，必须isr里的副本全部都接受到数据，才可以算写入成功了，一旦说你的isr副本里面少于2了，其实还是可能会导致你生产数据被卡住的

假设这个时候，第二个follower fullgc持续了几百毫秒然后结束了，接着从leader同步了那条数据，此时大家LEO都一样，而且leader发现所有follower都同步了这条数据，leader就会把HW推进一位，HW变成offset = 3

这个时候，消费者就可以读到这条在HW范围内的数据了，而且生产者认为写成功了

但是要是此时follower fullgc一直持续了好几秒钟，此时其他的生产者一直在发送数据过来，leader和第一个follower的LEO又推进了2位，LEO offset = 5，但是HW还是停留在offset = 2，这个时候HW后面的数据都是消费不了的，而且HW后面的那几条数据的生产者可能都会认为写未成功

现在导致第二个follower的LEO跟leader的LEO差距超过3了，此时触发阈值，follower认为是out-of-sync，就会从ISR列表里移除了

一旦第二个follower从ISR列表里移除了，世界清静了，此时ISR列表里就leader和第一个follower两个副本了，此时leader和第一个follower的LEO都是offset = 5，是同步的，leader就会把HW推进到offset = 5，此时消费者就可以消费全部数据了，生产者也认为他们的写操作成功了

那如果第二个follower后来他的fullgc结束了，开始大力追赶leader的数据，慢慢LEO又控制在replica.lag.max.messages限定的范围内了，此时follower会重新加回到ISR列表里去

上面就是ISR的工作原理和机制，一般导致follower跟不上的情况主要就是以下三种：

（1）follower所在机器的性能变差，比如说网络负载过高，IO负载过高，CPU负载过高，机器负载过高，都可能导致机器性能变差，同步 过慢，这个时候就可能导致某个follower的LEO一直跟不上leader，就从ISR列表里移除了

我们生产环境遇到的一些问题，kafka，机器层面，某台机器磁盘坏了，物理机的磁盘有故障，写入性能特别差，此时就会导致follower，CPU负载太高了，线程间的切换太频繁了，CPU忙不过来了，网卡被其他的程序给打满了，就导致网络传输的速度特别慢

（2）follower所在的broker进程卡顿，常见的就是fullgc问题

kafka自己本身对jvm的使用是很有限的，生产集群部署的时候，他主要是接收到数据直接写本地磁盘，写入os cache，他一般不怎么在自己的内存里维护过多的数据，主要是依托os cache（缓存）来提高读和写的性能的

（3）kafka是支持动态调节副本数量的，如果动态增加了partition的副本，就会增加新的follower，此时新的follower会拼命从leader上同步数据，但是这个是需要过程的，所以此时需要等待一段时间才能跟leader同步

replica.lag.max.messages主要是解决第一种情况的，还有一个replica.lag.time.max.ms是解决第二种情况的，比如设置为500ms，那么如果在500ms内，follower没法送请求找leader来同步数据，说明他可能在fullgc，此时就会从ISR里移除

### 17.Kafka在磁盘上是如何采用分段机制保存日志的？

每个分区对应的目录，就是“topic-分区号”的格式，比如说有个topic叫做“order-topic”，那么假设他有3个分区，每个分区在一台机器上，那么3台机器上分别会有3个目录，“order-topic-0”，“order-topic-1”，“order-topic-2”

每个分区里面就是很多的log segment file，也就是日志段文件，每个分区的数据会被拆分为多个段，放在多个文件里，每个文件还有自己的索引文件，大概格式可能如下所示：

00000000000000000000.index

00000000000000000000.log

00000000000000000000.timeindex



00000000000005367851.index

00000000000005367851.log

00000000000005367851.timeindex



00000000000009936472.index

00000000000009936472.log

00000000000009936472.timeindex

这个9936472之类的数字，就是代表了这个日志段文件里包含的起始offset，也就说明这个分区里至少都写入了接近1000万条数据了

kafka broker有一个参数，log.segment.bytes，限定了每个日志段文件的大小，最大就是1GB，一个日志段文件满了，就自动开一个新的日志段文件来写入，避免单个文件过大，影响文件的读写性能，这个过程叫做log rolling

正在被写入的那个日志段文件，叫做active log segment

### 18.引入索引文件之后如何基于二分查找快速定位数据？

日志段文件，.log文件会对应一个.index和.timeindex两个索引文件

kafka在写入日志文件的时候，同时会写索引文件，就是.index和.timeindex，一个是位移索引，一个是时间戳索引，是两种索引

默认情况下，有个参数log.index.interval.bytes限定了在日志文件写入多少数据，就要在索引文件写一条索引，默认是4KB，写4kb的数据然后在索引里写一条索引，所以索引本身是稀疏格式的索引，不是每条数据对应一条索引的

而且索引文件里的数据是按照位移和时间戳升序排序的，所以kafka在查找索引的时候，会用二分查找，时间复杂度是O(logN)，找到索引，就可以在.log文件里定位到数据了

.index

44576 物理文件（.log位置）

57976 物理文件（.log位置）

64352 物理文件（.log位置）

offset = 58892 => 57976这条数据对应的.log文件的位置

接着就可以从.log文件里的57976这条数对应的位置开始查找，去找offset = 58892这条数据在.log里的完整数据

.timeindex是时间戳索引文件，如果要查找某段时间范围内的时间，先在这个文件里二分查找找到offset，然后再去.index里根据offset二分查找找对应的.log文件里的位置，最后就去.log文件里查找对应的数据

### 19.磁盘上的日志文件是按照什么策略定期清理腾出空间的？

大家可以想，不可能说每天涌入的数据都一直留存在磁盘上，本质kafka是一个流式数据的中间件，不需要跟离线存储系统一样保存全量的大数据，所以kafka是会定期清理掉数据的，这里有几个清理策略

kafka默认是保留最近7天的数据，每天都会把7天以前的数据给清理掉，包括.log、.index和.timeindex几个文件，log.retention.hours参数，可以自己设置数据要保留多少天，你可以根据自己线上的场景来判断一下

只要你的数据保留在kafka里，你随时可以通过offset的指定，随时可以从kafka楼出来几天之前的数据，数据回放一遍，下游的数据，有多么的重要，如果是特别核心的数据，在kafka这个层面，可以保留7天，甚至是15天的数据

下游的消费者消费了数据之后，数据丢失了，你需要从kafka里楼出来3天前的数据，重新来回放处理一遍

在大数据的实时分析的项目里，其实就会涉及到这个东西的一个使用，如果你今天实时分析的一些数据出错了，此时你就需要把过去几天的数据重新楼出来回放一遍，重新来算一遍。实时数据分析的结果和hadoop离线分析的结果做一个比对

你每天都会从kafka里搂出来几天前的数据，算一下，跟离线数据的结果做一个比对

kafka broker会在后台启动线程异步的进行日志清理的工作

### 20.Kafka是如何自定义TCP之上的通信协议以及使用长连接通信的

kafka的通信主要发生于生产端和broker之间，broker和消费端之间，broker和broker之间，这些通信都是基于TCP协议进行的，大家自己看看网络课程，底层基于TCP连接和传输数据，应用层的协议，是Kafka自己自定义的

所谓自定义协议，就是定好传输数据的格式，请求格式、响应格式，这样大家就可以统一按照规定好的格式来封装、传输和解析数据了

生产端发送数据到kafka broker来，此时发送的数据是这样子的：

sent data: 一大串数据

kafka broker直接就从sent data:截取一大段数据就可以用了，如果你没有自定义一套完整的协议，是没办法进行通信的

http协议，生产端也可以发送http协议的数据给kafka broker，http请求，http响应。应用层的协议，规定了数据请求和响应的种种复杂的格式，大家全部按照这个格式和规范来走，不要乱来

request v1.1

isCache: true

一大串数据

对于生产端和broker，消费端和broker来说，还会基于TCP建立长连接（具体见网络课程），也就是维护一批长连接，然后通过固定的连接不断的传输数据，避免频繁的创建连接和销毁连接的开销

broker端会构造一个请求队列，然后不停的获取请求放入队列，后台再搞一堆的线程来获取请求进行处理

### 21.roker是如何基于Reactor模式进行多路复用请求处理的？

每个broker上都有一个acceptor线程和很多个processor线程，可以用num.network.threads参数设置processor线程的数量，默认是3，client跟一个broker之间只会创建一个socket长连接，他会复用

然后broker就用一个acceptor来监听每个socket连接的接入，分配这个socket连接给一个processor线程，processor线程负责处理这个socket连接，监听socket连接的数据传输以及客户端发送过来的请求，acceptor线程会不停的轮询各个processor来分配接入的socket连接

proessor需要处理多个客户端的socket连接，就是通过java nio的selector多路复用思想来实现的，用一个selector监听各个socket连接，看其是否有请求发送过来，这样一个processor就可以处理多个客户端的socket连接了

processor线程会负责把请求放入一个broker全局唯一的请求队列，默认大小是500，是queued.max.requests参数控制的，所以那几个processor会不停的把请求放入这个请求队列中

接着就是一个KafkaRequestHandler线程池负责不停的从请求队列中获取请求来处理，这个线程池大小默认是8个，由num.io.threads参数来控制，处理完请求后的响应，会放入每个processor自己的响应队列里

每个processor其实就是负责对多个socket连接不停的监听其传入的请求，放入请求队列让KafkaRequestHandler来处理，然后会监听自己的响应队列，把响应拿出来通过socket连接发送回客户端

### 22.如何对Kafka集群进行整体控制：Controller是什么东西？

不知道大家有没有思考过一个问题，就是Kafka集群中某个broker宕机之后，是谁负责感知到他的宕机，以及负责进行Leader Partition的选举？如果你在Kafka集群里新加入了一些机器，此时谁来负责把集群里的数据进行负载均衡的迁移？

包括你的kafka集群的各种元数据，比如说每台机器上有哪些partition，谁是leader，谁是follower，是谁来管理的？如果你要删除一个topic，那么背后的各种partition如何删除，是谁来控制？

还有就是比如kafka集群扩容加入一个新的broker，是谁负责监听这个broker的加入？如果某个broker崩溃了，是谁负责监听这个broker崩溃？

这里就需要一个kafka集群的总控组件，Controller。他负责管理整个kafka集群范围内的各种东西

### 23.如何基于Zookeeper实现Controller的选举以及故障转移

在kafka集群启动的时候，会自动选举一台broker出来承担controller的责任，然后负责管理整个集群，这个过程就是说集群中每个broker都会尝试在zk上创建一个/controller临时节点

zk的一些基础知识和临时节点是什么，百度一下zookeeper入门

但是zk会保证只有一个人可以创建成功，这个人就是所谓controller角色

一旦controller所在broker宕机了，此时临时节点消失，集群里其他broker会一直监听这个临时节点，发现临时节点消失了，就争抢再次创建临时节点，保证有一台新的broker会成为controller角色

### 24.创建Topic时Kafka Controller是如何完成Leader选举的呢？

如果你现在创建一个Topic，肯定会分配几个Partition，每个partition还会指定几个副本，这个时候创建的过程中就会在zookeeper中注册对应的topic的元数据，包括他有几个partition，每个partition有几个副本，每个partition副本的状态，此时状态都是：NonExistentReplica

然后Kafka Controller本质其实是会监听zk上的数据变更的，所以此时就会感知到topic变动，接着会从zk中加载所有partition副本到内存里，把这些partition副本状态变更为：NewReplica，然后选择的第一个副本作为leader，其他都是follower，并且把他们都放到partition的ISR列表中

比如说你创建一topic，order_topic，3个partition，每个partition有2个副本，写入zk里去

/topics/order_topic

partitions = 3, replica_factor = 2

[partition0_1, partition0_2]

[partition1_1, partition1_2]

[partition2_1, partition2_2]

从每个parititon的副本列表中取出来第一个作为leader，其他的就是follower，把这些东西给放到partition对应的ISR列表里去

每个partition的副本在哪台机器上呢？会做一个均匀的分配，把partition分散在各个机器上面，通过算法来保证，尽可能把每个leader partition均匀分配在各个机器上，读写请求流量都是打在leader partition上的

同时还会设置整个Partition的状态：OnlinePartition

接着Controller会把这个partition和副本所有的信息（包括谁是leader，谁是follower，ISR列表），都发送给所有broker让他们知晓，在kafka集群里，controller负责集群的整体控制，但是每个broker都有一份元数据

### 25.删除Topic时又是如何通过Kafka Controller控制数据清理？

如果你要是删除某个Topic的话，Controller会发送请求给这个Topic所有Partition所在的broker机器，通知设置所有Partition副本的状态为：OfflineReplica，也就是让副本全部下线，接着Controller接续将全部副本状态变为：ReplicaDeletionStarted

然后Controller还要发送请求给broker，把各个partition副本的数据给删了，其实对应的就是删除磁盘上的那些文件，删除成功之后，副本状态变为：ReplicaDeletionSuccessful，接着再变为NonExistentReplica

而且还会设置分区状态为：Offline

### 26.每日10亿数据会对Kafka集群造成多大压力

电商平台假设有每日10亿数据，此时我们的生产环境的kafka集群应该如何来规划和部署

10亿数据，他对kafka集群造成的并发请求会有多少，24小时，电商平台，其中有12个小时，是承担了大部分的流量，比如说晚上12点过后，到第二天的早上8点，这之间可能没什么流量过来

16小时 -> 有数据的，但是其中高峰期，可能就20%的时间，`16 * 0.2 = 3小时

8亿，80%的数据会集中在16小时内涌入，8亿时间里的80%的请求会集中在3小时的高峰时间段，8 * 0.8 = 6.4亿数据

大概是每秒钟有6万请求，会涌入你的kafka集群，整体kafka的集群需要抗住高峰期每秒6万的QPS

kafka集群默认是保留最近7天的数据，假设我们就用默认的配置

每天是进来10亿条数据，但是每条数据做几个副本？每个topic都可以设置副本因子，平均都是2个副本，每天在kafka磁盘上需要保留10亿* 2 = 20亿条数据，集群磁盘空间需要保留最近7天的20亿 * 7 = 140亿条数据

每条数据大概有多大？算大点，平均每条数据是1kb，140亿kb -> 整个kafka集群的磁盘空间至少需要容纳13TB的数据，就是最近7天的数据量

### 27.Kafka集群生产规划：需要部署几台物理机？

10亿数据，高峰期6万QPS，集群容纳的数据量是13TB

部署Kafka，Hadoop，MySQL，大数据核心分布式系统，一般建议大家直接采用物理机，不建议用一些低配置的虚拟机自己瞎搞

QPS这个东西，不可能是说，你只要支撑6万QPS，你的集群就刚好支撑6万QPS就可以了。假如说你只要支撑6w QPS，2台物理机绝对绝对够了，单台物理机部署kafka支撑个几万QPS是没问题的

但是这里有一个问题，我们通常是建议，公司预算充足，尽量是让高峰QPS控制在集群能承载的总QPS的30%左右

你的kafka集群能承载的总QPS给他搞成20万~30万，是非常安全的

大体上来说，需要5~7台物理机来部署，基本上就很安全了，每台物理机要求吞吐量在每秒几万条数据就可以了，物理机的配置和性能也不需要特别高

硬盘容量这块，每台物理机硬盘空间起码有个几个TB，所以如果是6台物理机的话，起码可以支撑个十几TB的数据，你到底需要不需要保留最近7天的数据，也可以根据你的需求场景减小这个时间间隔

保留最近3天的数据，6TB左右

如果你kafka集群的硬盘容量总共加起来有个十几TB，或者是20TB，都可以来支撑

### 28.Kafka集群生产规划：到底该不该用SSD？

10亿，6w/s的吞吐量，12TB的数据量，6台物理机，2块1TB的SAS盘

CPU、内存、硬盘、网路、参数，各种环节应该如何来规划

SSD固态硬盘，还是普通机械硬盘

比如说我们在规划和部署线上系统的MySQL集群的时候，一般来说必须用SSD性能可以提高很多，MySQL可以承载的并发请求量也会高很多，而且SQL语句执行的性能也会提高很多

SSD，固态硬盘，快，比机械硬盘要快，到底是快在哪里呢？快主要是快在磁盘随机读写，就要对磁盘上的随机位置来读写的时候，SSD比机械硬盘要快。像比如说是MySQL这种系统，就应该使用SSD了

Kafka集群，物理机是用昂贵的SSD呢？还是用普通的机械硬盘呢？写磁盘的时候，他是怎么来写的？磁盘顺序写的，压测，机械硬盘顺序写的性能机会跟内存读写的性能是差不多的，SSD做顺序写的性能

SSD主要是随机读写的性能要比机械硬盘随机读写的性能高很多倍

他在使用硬盘的时候，最核心的一个思想就是仅仅允许追加数据在每个日志段文件的末尾，不支持在磁盘文件里随机写，磁盘随机写

其实就没必要使用SSD了，会贵很多，增加很大的机器成本；顺序写，每台物理机给配置个常规的2块机械硬盘就可以，就足够了

每天多少条消息，每条消息几个备份，保留几天的数据，总共需要多大容量，对应到每台机器需要多大容量

### 29.Kafka集群生产规划：硬盘空间应该给多大？

10亿数据，6w QPS，12TB，6台物理机，2块1TB的机械硬盘

最近7天一共是12TB的数据量的角度而言，大概就是每台物理机搞2块机械硬盘，每块盘就是1TB好像就够了

很多是从mysql同步的binlog数据过来的，那种数据很多是到不了1kb的，几十个字节，几百个字节，也算是比较大了，用户行为日志，也不一定就可以到达1kb一条，一两百个字节，具体看你们公司采集的数据，看一看，估算一下平均每条数据有多大

有一个经验值，1亿条用户行为日志，也就几个GB，几个TB，也就差不多了

未来给机器扩容硬盘也是可以的，继续加硬盘，或者把小容量的硬盘换成大容量的盘，运维工程师会协助你来做的，偏硬件一些的，给服务器加硬盘，挂载，等等，诸如此类的一些事情

很多公司，每天其实就几千万条数据采集到大数据平台里来的话，根本不算是什么大数据，几百MB，1GB以内，没多少数据量

### 30.Kafka集群生产规划：充分利用os cache提高性能

10亿数据，6w QPS，12TB，6台物理机，2块1TB的机械硬盘

接下来看看，内存这块到底应该怎么来弄，kafka部署的时候内存的规划是很有讲究的，你一定要明白他底层的原理，才能知道应该如何来规划kafka的内存空间

kafka写数据基本上优先让数据写入os cache，后面来消费数据的时候，就可以从os cache里读取数据出来，写和读基本上都是依托于操作系统的缓存来执行的，我们在规划这个内存空间的时候

kafka本身是scala语言开发的，是基于jvm的，jvm代表了进程使用的内存空间，是多少，jvm堆内存，机器上留给os cache的内存应该有多大。kafka jvm堆内存，你觉得需要很大吗？你其实听懂了kafka原理之后

kafka并没有在自己的jvm堆内存里放入过多的数据，rabbitmq是不一样的，数据过来优先写入jvm堆内存里去缓冲一下，一定时间之后，rabbitmq再一次性把jvm堆内存里的缓冲一批数据给刷入磁盘中

导致jvm堆内存中存放大量的数据，需要给jvm堆内存开辟比较大的空间了

但是kafka正好相反的，他接收到了这个数据之后不是直接写jvm堆内存的，而是采用自己的二进制紧凑的数据格式，给写入到磁盘文件里去，是先写入os cache（操作系统管理的一块内存缓冲空间）

kafka并没有使用过多的jvm堆内存空间，不需要给kafka jvm堆内存分配过大的空间，基本上来说几个G就够了

在kafka部署的机器上，你需要比较大的空间应该是os cache这块，如果这块空间越大，那么你其实就可以在os cache内存里存放越多的数据，就可以保证说，人家在消费的时候，就可以从os cache里去读取数据了

os cache这块空间起码要有多大，在底层磁盘文件这块，其实是每个分区的数据是分段存的，每个分区的数据有多个分段日志文件，人家消费的时候比较频繁的需要读取的，一般是最新的这个正在写入的分段日志文件

起码你应该让这台机器上的broker管理的每个parition的最新正在写的日志段文件的数据都可以驻留在os cache中，这样可以保证每个parition正在写的数据，最有可能被消费的数据，就可以直接从os cache里来读了

假设100个topic，每个topic是6个partition，每个partiton是2个副本，一共100 * 6 =600个leader partition，平均到6台机器上去，假设每台机器是放100个partition，每个partition的最新正在写的日志段文件的大小是默认的1GB

所以说单台机器上，最新的正在写的日志段文件的大小100个partition * 1GB的日志段文件 = 600GB。如果最佳的情况，单台机器可以有600GB的内存的给os cache的话，就可以每个partiton最新的数据都在os cache里，比如说一个日志段文件有1GB，可能都对应几千万条数据了

没必要说一定要几千万的数据都在os cache里才可以，日志段文件3000万条数据，其实人家消费比较频繁的，就是最近的10万条数据，2GB的数据可以保留在os cache中，最新写入的2GB的数据驻留在os cache中，就可以让人家从内存里消费到最新的数据了

给os cache可以分配的内存空间绝对是不止2GB，几十个GB，每个partition的最新日志段文件里的最新写入的10%的数据，都可以驻留在os cache中，让人家对最新的数据都可以从os cache里读取到

你必须保证最新的10%的数据都在os cache里，人家消费大部分的消费请求可以走os cache来读取就可以了

### 31.Kafka集群生产规划：内存空间如何规划？

kafka自身的jvm是用不了过多堆内存的，因为kafka设计就是规避掉用jvm对象来保存数据，避免频繁fullgc导致的问题，所以一般kafka自身的jvm堆内存，分配个6G左右就够了，剩下的内存全部留给os cache

32G以上的内存，尽量是64G~128G的内存空间

比如一台物理机，有64GB的内存空间，那么50多G都是给os cache的

然后要看看每个日志段的大小，每个分区都有一个日志段是当前正在写入的，这个大家都懂了，所以此时这个正在写入日志段的数据，就是消费者读取最频繁的数据，主要让这台机器上每个partition副本的正在写的日志段，都可以放在os cache里

那么基本上80%~90%的消费行为，都可以直接从os cache里读到数据了，如果你真的按照课程的思路和讲解，来推算和规划你的kafka生产集群，把的内存规划设置的很好的话，基本上可以做到

整个人家kafka的读写吞吐量都很大，性能很高，延迟很低

### 32.Kafka集群生产规划：为什么需要16核CPU？

10亿数据，6w QPS，12TB，6台物理机，2块1TB的机械硬盘，64GB内存（6GB给JVM，剩余给os cache），16核CPU

CPU规划，主要是看你的这个进程里会有多少个线程，线程主要是依托多核CPU来执行的，如果你的线程特别多，但是CPU核很少，就会导致你的CPU负载很高，会导致你的整体工作线程执行的效率不太高

acceptor线程负责去接入客户端的连接请求，但是他接入了之后其实就会把连接分配给多个processor，默认是3个，但是说实话一般生产环境的话呢 ，建议大家还是多加几个，整体可以提升kafka的吞吐量

比如说你可以增加到6个，或者是9个

另外就是负责处理请求的线程，是一个线程池，默认是8个线程，在生产集群里，建议大家可以把这块的线程数量稍微多加个2倍~3倍，其实都正常，比如说搞个16个工作线程，24个工作线程

他后台会有很多的其他的一些线程，比如说定期清理7天前数据的线程，Controller负责感知和管控整个集群的线程，后台线程在工作

每个broker可能都会有上百个起码，一两百个线程繁忙的在工作

CPU给到4核，一般来说几十个线程，在高峰期CPU几乎都快打满了，8核，也就能够比较宽裕的支撑几十个线程繁忙的工作，一般是建议16核，靠谱，基本上可以hold住一两百线程的工作

broker一般都会启动几十个甚至上百个线程，大家看过broker端的原理了，各种处理请求的线程，后台线程，几十个线程频繁工作，一般都建议是16核CPU，甚至32核CPU

### 33.Kafka集群生产规划：千兆网卡还是万兆网卡？

10亿数据，6w QPS，12TB，6台物理机，2块1TB的机械硬盘，64GB内存（6GB给JVM，剩余给os cache），16核CPU，千兆网卡

生产环境的机器规划，无论是MySQL、Redis、RocketMQ、Elasticsearch、Kafka、Hadoop、Flink，Yarn，规划的思路都是类似的，从技术本质和底层的原理出发来考虑，请求量有多大、数据量有多大、内存应该分配多大（底层工作机制）、线程数量有多少、网络数据传输量有多大

现在一般就是千兆网卡（1GB / s），还有万兆网卡（10GB / s）

你要计算一下，kafka集群之间，broker和broker之间是会做数据同步的，因为leader要同步数据到follower上去，他们是在不同的broker机器上的，broker机器之间会进行频繁的数据同步，传输大量的数据

每秒两台broker机器之间大概会传输多大的数据量？高峰期每秒大概会涌入6万条数据，每秒就是60mb/s的数据量，他会在broker之间来传输，你就算多估算一些，每秒大概也就传输个几百mb/s的数据，就足够了

针对千兆网卡来算一下，假如每台物理机的网卡带宽都是1GB / s

实际上每台机器能用的网卡的带宽还达不到极限，因为kafka只能用其中一部分的带宽资源，比如700mb / s，但是一般不能允许kafka占用这么多带宽，因为避免说占用这么多带宽，万一再多一点，就容易把网卡打满

所以说，一般限制kafka每秒带宽资源就是300mb / s，如果你给物理机使用的千兆网卡，那么其实他每秒最多传输数据是几百mb，是够了，几十mb，或者一两百mb，基本上都够了，可以足够传输

假如说现在每秒要传输7万条数据，每条数据是平均1kb，那么就是70mb / s，这样的话，是可以轻松抗住的

如果是万兆网卡，那么就更加轻松了

### 34.Kafka集群生产规划：线上机器典型配置

10亿数据，6w/s的吞吐量，12TB的数据量

6台物理机

硬盘：2块机械硬盘，每块1TB，7200转

内存：64GB，JVM分配6G，剩余的给os cache

CPU：16核

网络：千兆网卡

### 35.生产环境中的Kafka集群参数设置：内核参数

自己可能都或多或少哪怕是虚拟机环境的kafka都搭建过

broker.id=0，这个是每个broker都必须自己设置的一个唯一id

log.dirs，这个极为重要，kafka的所有数据就是写入这个目录下的磁盘文件中的，如果说机器上有多块物理硬盘，那么可以把多个目录挂载到不同的物理硬盘上，然后这里可以设置多个目录，这样kafka可以数据分散到多块物理硬盘，多个硬盘的磁头可以并行写，这样可以提升吞吐量

zookeeper.connect，同样很重要，这个是连接kafka底层的zookeeper集群的

listeners，这是broker监听客户端发起请求的端口号

unclean.leader.election.enable，默认是false，意思就是只能选举ISR列表里的follower成为新的leader，1.0版本后才设为false，之前都是true，允许非ISR列表的follower选举为新的leader

delete.topic.enable，默认true，允许删除topic

log.retention.hours，可以设置一下，要保留数据多少个小时，这个就是底层的磁盘文件，默认保留7天的数据，根据自己的需求来就行了

log.retention.bytes，这个设置如果分区的数据量超过了这个限制，就会自动清理数据，默认-1不按照这个策略来清理，这个一般不常用

min.insync.replicas，这个跟acks=-1配合起来使用，意思就是说必须要求ISR列表里有几个follower，然后acks=-1就是写入数据的时候，必须写入这个数量指定的follower才可以，一般是可以考虑如果一个leader两个follower，三个副本，那么这个设置为2，可以容忍一台机器宕机，保证高可用，但是写入数据的时候必须ISR里有2个副本，而且必须副本都写入才算成功

如果你就一个leader和follower，双副本，min.insync.replicas = 2。如果有一台机器宕机，导致follower没了，此时ISR列表里就一个leader的话，你就不能写入了，如果你只有一个副本了，此时还可以写入数据的话，就会导致写入到leader之后，万一leader也宕机了，此时数据必然丢失

一般来说为了避免数据占用磁盘空间过大，一般都是kafka设置双副本，一个leader和一个follower就够了，设置的三副本的话，数据在集群里乘以3倍的空间来存放，非常耗费磁盘空间，对你的整体集群的性能消耗也会更大

min.insync.replicas=1，acks=-1（一条数据必须写入ISR里所有副本才算成功），你写一条数据只要写入leader就算成功了，不需要等待同步到follower才算写成功。但是此时如果一个follower宕机了，你写一条数据到leader之后，leader也宕机，会导致数据的丢失。

一般来说双副本的场景下，我们为了避免数据丢失，min.insync.replicas=2，acks=-1，每次写入必须保证ISR里2个副本都写成功才可以，如果其中一个副本没了，会导致你就没法写入，必须阻塞等待kafka恢复

这样就可以保证数据的不丢失

你是要计算为客户准备的财务数据报表，非常严格的数据必须精准的话，精准到每一分钱，你还是得设置成2

num.network.threads，这个是负责转发请求给实际工作线程的网络请求处理线程的数量，默认是3，高负载场景下可以设置大一些

num.io.threads，这个是控制实际处理请求的线程数量，默认是8，高负载场景下可以设置大一些

要自己做一些压测，在不同的线程数量的条件下，对整体的生产和消费的吞吐量分别是多少，还得看一下线程越多的时候，对CPU的复杂有多大，整体看一下，如果增加一些线程，吞吐量提升很多，而且CPU负载还能接受

message.max.bytes，这个是broker默认能接受的消息的最大大小，默认是977kb，太小了，可以设置的大一些，一般建议设置大一些，很多大消息可能大到几mb，这个设置个10mb，可以考虑

log.flush.interval.messages

log.flush.interval.ms

线上的常用的一个配合，高负载高吞吐的情况下，建议设置为1分钟

### 36.生产环境中的Kafka集群参数设置：JVM以及GC参数

修改bin/kafka-start-server.sh中的jvm设置

export KAFKA_HEAP_OPTS=”-Xmx6g -Xms6g -XX:MetaspaceSize=96m -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 -XX:G1HeapRegionSize=16M -XX:MinMetaspaceFreeRatio=50 -XX:MaxMetaspaceFreeRatio=80”

### 37.生产环境中的Kafka集群参数设置：操作系统参数

文件描述符限制：kafka会频繁的创建和修改文件，大约是分区数量 * （分区总大小 / 日志段大小） * 3，比如一个broker上大概有100个分区，每个分区大概是10G的数据，日志段大小是默认的1G，那么就是100 * 10（分区里的日志段文件数量） * 3 = 3000个文件

ulimit -n 100000，这个可以设置很大的描述符限制，允许创建大量的文件

磁盘flush时间：默认是5秒，os cache刷入磁盘，可以设置为几分钟，比如1分钟才刷入磁盘，这样可以大幅度提升单机的吞吐量

sysctl -a | grep dirty

vm.dirty_background_bytes = 0

vm.dirty_background_ratio = 5

vm.dirty_bytes = 0

vm.dirty_expire_centisecs = 3000

vm.dirty_ratio = 10

vm.dirty_writeback_centisecs = 500

vm.dirty_writeback_centisecs：每隔5秒唤醒一次刷磁盘的线程

vm.dirty_expire_centisecs：os cache里的数据在3秒后会被刷入磁盘

可以设置大一些，1分钟~2分钟都可以，特别大规模的企业和公司，如果你可以接收机器宕机的时候，数据适当可以丢失一些，kafka里的数据可以适当丢失一些，但是为了提升集群的吞吐量的话

大数据分析类的应用的话，主要是出一些数据报表，不要求数据100%精准的话，允许适当丢一些数据，此时的话，这里给他调大一些是没问题的

### 38. 在生产环境中如何正确的启动和关闭Kafka集群？

如果你是作为一个大数据平台工程师，你负责在生产环境部署一套kafka集群，选择对应的物理机，在物理机上部署kafka就可以了，接下来其实你作为一个平台工程师，你要做到五大块的事情：

（1）你需要去支持业务团队的需求：Topic的创建、管理、扩容

（2）对kafka集群进行监控：机器监控->broker监控->JVM监控，方方面面的监控

（3）日常运维和管理的：集群扩容、版本升级、管理工作

（4）从生产消息->broker处理消息->消费消息，整个链路都可能会出问题，异常报错，kafka技术大牛，精通这个技术的人，你需要能够处理kafka相关的所有的异常报错

（5）对常见一些生产技术方案，解决一些需求和问题：事务、消息幂等、顺序、0丢失、回溯、消息积压

集群如何启动，如何关闭，小的细节需要注意一下的，需要在每台机器上都依次去执行一个脚本来启动这台机器的broker，他启动之后，自然而然就会去注册自己到zk，controller就会发现这个broker

controller会负责去把最新的集群的元数据同步给所有的broker

JMX_PORT=9997 bin/kafka-server-start.sh -daemon /server.properties

一定要用后台方式来启动kafka，这里可以在启动的时候设置好JMX端口号，这个是用来后面对Kafka的数据进行监控的

bin/kafka-server-stop.sh

这个是关闭kafka的脚本，需要使用这个脚本来关闭

### 39.作为Kafka集群管理员如何对根据业务需求管理Topic？

手头已经有了一套生产集群了，都部署好了，压力测试过后集群整体抗个每秒几十万的请求都可以做到了，支撑几十TB的数据量都可以了

平时作为kafka平台工程师，你需要协助业务团队来维护topic，各个业务团队，小公司，主要就是一个后端技术团队，或者是大数据技术团队，你自己本身也是大数据技术团队里面的一个人，只不过你的leader专门让你来负责维护kafka集群

比如说你们团队里，有的哥儿们是做实时计算这块的，他需要把实时的数据流引入到kafka里去，接着他会需要去使用flink、spark streaming、storm，这种实时计算技术，来从kafka里消费数据，接着继续去运算，做实时的一些分析

风控技术团队，推荐技术团队，他们可能也需要将一些实时的数据流引入到kafka，或者是人家直接从你这里获取实时的数据流，进行风控，或者是实时的个性化推荐，可能性都有，所以他们就是你的业务方

bin/kafka-topics.sh --create --zookeeper localhost:2181 --partitions 6 --replication-factor 2 --topic test01

创建topic其实主要是指定这个topic的分区数量，具体来说你要综合考虑Kafka集群的整体规模，有几台机器，还有就是这个topic最近7天的数据量会有多大。举个例子，某个topic每天要放用户行为日志

每天大概是1GB的数据量，最近7天就需要保留7GB的数据量，还有两个副本因子，那么就是一共14GB的数据量。现在假设Kafka集群有4台物理机，你觉得应该给这个Topic分配多少个分区？

很明显了，就4个分区就足够了，每台机器会放一个leader partition，然后都有一个follower partition，这样这个topic的数据会均匀分散在4台机器上，而且对这个topic的读写请求都均匀分散在4台机器上了

假设说你对这个topic每秒写入并发是10万条，4个分区，写入的时候会写入4个分区，在4台机器上有leader partition，均匀的分散在4台机器上，每台机器其实就是大概每秒写入2.5万个请求

那如果你的Kafka物理集群有20台机器呢？这个时候初始分区数量可以设置为7，把7个分区分散在其中的7台机器上，这样的好处，就是对这个Topic的读写请求会均匀分散在7台机器上上，对Topic的读写吞吐量是不是会更高？

所以在创建Topic的时候，大家一定要考虑好这一点，至于说副本因子的话，其实一般就是2就足够了，因为双副本可以保证一定的数据容错性，哪怕一台机器宕机了，还有其他副本保证数据不丢失，可以继续使用

如果你设置为3副本，那当然更好了，最多允许2台机器宕机不会丢数据，但是问题是你的数据存储空间会triple一下，那你的机器资源就会耗费更多了，所以这里要权衡一下。如果希望数据严格不丢失

那么min.insync.replicas，那个参数可以设置为2，要求比如ISR里有2个副本，才能写入成功，acks=-1，就是必须写入2个副本才行，这样可以保证写成功了一条数据，绝对一般是数据不会丢的

对于大数据的场景，要求的是吞吐量，而不是数据不丢失

但是如果要求更高的吞吐量，那么就设置min.insync.replicas，这个参数就是设置为1就可以了，只要有1个副本就可以写入，写入1个副本就算写成功，也就是写入leader就够了，可能数据会丢失，但是吞吐量很高，因为写入不需要等待副本同步成功

通常情况下建议采取高吞吐的策略，不要为了数据0丢失牺牲掉吞吐量，除非是极为核心的业务数据，比如说广告计费的数据

bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic test01，可以删除topic

如果要删除topic，需要设置delete.topic.enable为true，允许用户删除topic，删除之后是后台异步执行的，要过很长时间才能删除掉topic

bin/kafka-topics.sh --zookeeper localhost:2181 --list，可以查看topic列表，通过这个命令可以快速查看当前有哪些topic，还有就是可以看看要删除的topic删除掉了没有，平时这个命令管理员用的是很多的

bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test01，可以查看topic详情，这个命令其实相当的实用，因为平时肯定要经常看看一个topic的具体情况，每个partition的leader在哪台机器上，副本在哪些机器上，ISR列表

### 40.某个Topic的数据量太大了需要扩容partition怎么做

如果说某个topic一开始数据量很小，比如每天就几百MB的数据，那你不需要给他分配过多的分区，因为你要是搞10个分区，分散在10台机器上，每台机器就几十MB的数据，有什么意义呢

所以一般建议生产环境采取的策略是刚开始就是按照预估的数据量给合理的分区数即可，通常来说，你可以限制每个分区在几个GB到10个GB，或者最多20个GB左右，都可以，具体要看你们公司的Kafka集群的机器资源情况

那么如果后来业务不停的发展，发现topic数据量太大了，当前的几个分区所在机器有点压力了，需要扩容增加更多的topic呢？这个时候你就可以动态扩容分区了，这样就可以让新的数据慢慢分散到更多的分区，更多的机器上去

bin/kafka-topics.sh --alter --zookeeper localhost:2181 --partitions 10 --topic test-topic

### 41.如果某台broker机器承载了过多leader partition怎么办

现在各个业务方可以自行申请创建topic，分区数量都是自动分配和后续动态调整的，kafka本身会自动把leader partition均匀分散在各个机器上，这样可以保证每台机器的读写吞吐量都是均匀的

但是也有例外，那就是如果某些broker宕机，会导致leader partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压力过高，其他宕机的broker重启之后都是follower partition，读写请求很低，造成集群负载不均衡

有一个参数，auto.leader.rebalance.enable，默认是true，每隔300秒（leader.imbalance.check.interval.seconds）会执行一次preferred leader选举，如果一台broker上的不均衡的leader超过了10%，leader.imbalance.per.broker.percentage，就会对这个broker进行选举

也可以手动执行，bin/kafka-preferred-replica-election.sh，但是不建议手动执行，让他自动执行就好了

topic创建自助的，分区扩容自动的，leader partition均匀分散也是自动的

### 42.应该如何对你的Kafka集群设计生产级监控方案？

如何支撑业务这块，基本上你就已经思路比较清晰了，其实接下来这个业务方就会大量的写入数据到kafka以及从kafka消费数据出去，对你来说，你是kafka数据平台的工程师，你需要干的事情就是监控好这个集群

作为一个kafka管理员，在部署好了生产集群之后，要干的一个非常核心的事情，就是对集群设计一整套监控方案，基于开源工具完成部署，每天都对集群进行监控，所以这里就要先搞明白需要监控哪些东西

（1）Broker集群的运行状态：包括每个broker上管理了多少个partition，有多大的数据量，磁盘使用情况，物理机的CPU、内存、磁盘、网络的监控，比如CPU负载，内存使用率，磁盘IO负载，网络IO负载，JVM GC的情况

（2）ZooKeeper集群的运行状态：同理，跟上面是类似的，主要是磁盘使用率，然后物理机的CPU、内存、磁盘、网络的监控，这个东西一般来说可以先排除在外，可能不是你同时在维护的zk集群

（3）Topic的状态：这个你需要每天知道集群里有多少Topic，每个Topic有多少分区，有多大数据量，每个分区的副本在哪些机器上，ISR列表，等等

（4）后台定是运行的作业：比如说partition负载均衡自动迁移数据，Leader partition的重新选举，等等

（5）Kafka、生产、消费、集群是否有异常报错日志

### 43.如何对Kafka Broker所在机器的CPU、内存、网络进行监控

一般来说如果你要对类似kafka这种集群进行监控，建议采用开源的工具，kafka-manager，kafka eagle，都可以使用，人家都做好了会通过图表的形式来展现出来你的broker所在机器的CPU、网络、磁盘、内存的一些负载

就是一个小的公司，也可以直接基于linux的命令进行监控

使用top命令就可以查看CPU的负载，使用free命令就可以查看内存的使用情况，使用iostat -d -x -k 1 5来查看磁盘的使用率

### 44.Kafka Broker有哪些核心的运行指标是值得去监控的？

下面的JMX指标，都可以基于JConsole去连接到kafka的JMX端口来监控查看，也可以基于kafka自己提供的一个工具来监控

bin/kafka-run-class.sh kafka.tools.JmxTool --object-name kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec --jmx-url service:jmx:rmi:///jndi/rmi://:9997/jmxrmi --date-format “YYYY-MM-dd HH:mm:ss” --attributes FifteenMinuteRate --reporting-interval 5000

上面的命令就是每隔5秒去监控过于15分钟的消息接收速率，kafka的JMX的指标，特别特别的多，官网去查一下，成百上千个JMX指标

（1）消息接收/发送速率：监控每个broker的负载压力

这个就是说leader broker接收消息的速率，以及follower broker接收消息的速率；还有就是leader broker发送给follower broker的速率

kafka.server:type=BrokerTopicMetrics,name=BytesInPerSec,topic=test

（2）controller是否存活：监控controller是否存活

kafka.controller:type=KafkaController,name=ActiveControllerCount

（3）副本不足的分区数：某个分区的副本不足了

kafka.server:type=ReplicaManager,name=UnderReplicatedPartitions

（4）leader parttion在各个broker上的数量：确认集群的各个broker负载是均衡的

kafka.server:type=ReplicaManager,name=LeaderCount

（5）ISR变化速率：监控ISR不能变化太快

kafka.server:type=ReplicaManager,name=isExpandsPerSec

kafka.server:type=ReplicaManager,name=IsrShrinksPerSec

（6）Broker IO工作线程空闲率

kafka.server:type=KafkaRequestHandlerPool,name=RequestHandlerAvgIdlePercent

（7）Broker网络处理线程空闲率

kafka.network:type=SocketServer,name=NetworkProcessorAvgIdlePercent

这个JMX指标是非常非常多的，大家可以自己上官网去找，平时作为一个运维人员，需要经常对核心的一些指标看一看，这样你可以对kafka集群当前的运行情况了解的很清晰，特别是在一些故障发生的时候

### 45.如何基于JMX对Kafka集群的JVM和GC进行监控？

kafka他的设计理念就是不要过度的依赖于通过jvm内存来进行数据管理，避免说过多的数据驻留在kafka jvm内存里面，会导致过多的gc

java.lang:type=GarbageCollector,name=G1 Old Generation

java.lang:type=GarbageCollector,name=G1 Young Generation

就是对垃圾回收进行监控

### 46.集群、业务、监控

（1）监控资源的使用率：对于kafka来说，就是磁盘资源的使用率，当前集群保存了多大的数据量；每台机器的吞吐量，JMX来看到，broker接收数据的速率，每秒接收多少条消息，接收多少字节的数据

如果说你本来一个集群有4台机器，总共可以放20TB的数据，随着磁盘资源的使用率的攀升，可能你们的业务在不断的增长，会可能导致你们的机器就不够了，因为马上20TB的磁盘资源就要用满了

就需要进行broker机器的扩容，多增加一些broker机器，集群有更多的磁盘空间

每个broker的吞吐量，如果最多每台机器每秒可以接收10万条消息，每秒接收500mb的数据，现在发现每台broker在高峰期的时候，吞吐量几乎都应快要打了，此时就说明你需要扩容了

就需要多增加一些broker机器，让每个broker所在的节点承载更小的并发请求量，保证集群的健康稳定的运行

（2）集群里的负载倾斜：如果说某几台broker承载的数据量特别大，或者是承载的吞吐量特别大，此时你就应该手动进行一下数据的迁移，可以把这些broker上的partition迁移一些到负载比较轻的机器上去

（3）异常报错、JVM GC频繁：解决报错的问题，那是非常考验你的技术功底的，Kafka源码有比较深入的研究，你后续才能在他就是说有报错的时候，可以去通过源码的分析，看他到底为什么报错

### 47.如何对Kafka集群进行动态扩容加入更多的Broker节点？

之前大家了解过原理了，现在都知道，其实扩容增加broker是很容易的，只要配置好这个broker，然后穷，他会自动在zk里加入自己的节点，然后这个时候Controller会感知到他的加入，同步给其他所有的broker

而且Controller还会自动把集群元数据同步给这个新的broker，就是有哪些topic，每个topic有多少partitioin，每个partition有几个副本，以及对应的ISR

但是刚启动的broker不会自动被负载均衡迁移一些partiton，需要手动进行partiton在集群里的负载均衡，这样让每台broker机器管理均匀的数据量，同时分配leader partition承载均匀的读写请求流量

比如说现在你有3个topic，每个topic有5个partition，每个partitino有2个副本，一共有partition副本数量有30个，比如原来有3台broker，每台broker有10个partition副本，现在假如了第四台broker了

partition概念，资源都集中在partition里面了，数据是在partition作为单位来存放的，读写负载也是针对leader partition来进行的

### 48.Kafka Producer怎么把消息发送给Broker集群的？

需要指定把消息发送到哪个topic去

首先需要选择一个topic的分区，默认是轮询来负载均衡，但是如果指定了一个分区key，那么根据这个key的hash值来分发到指定的分区，这样可以让相同的key分发到同一个分区里去，还可以自定义partitioner来实现分区策略

producer.send(msg); // 用类似这样的方式去发送消息，就会把消息给你均匀的分布到各个分区上去

producer.send(key, msg); // 订单id，或者是用户id，他会根据这个key的hash值去分发到某个分区上去，他可以保证相同的key会路由分发到同一个分区上去

知道要发送到哪个分区之后，还得找到这个分区的leader副本所在的机器，然后跟那个机器上的Broker通过Socket建立连接来进行通信，发送Kafka自定义协议格式的请求过去，把消息就带过去了

如果找到了partition的leader所在的broker之后，就可以通过socket跟那台broker建立连接，接着发送消息过去

Producer（生产者客户端），起码要知道两个元数据，每个topic有几个分区，每个分区的leader是在哪台broker上，会自己从broker上拉取kafka集群的元数据，缓存在自己client本地客户端上

kafka核心原理、集群部署、运维管理 -> 初步玩儿起来一套kafka集群

kafka使用者的层面来考虑一下，我如果要把数据写入kafka集群，应该如何来做，怎么把数据写入kafka集群，以及他背后的一些原理还有使用过程中需要设置的一些参数，到底应该怎么来弄

### 49.Producer发送消息的内部实现原理

每次发送消息都必须先把数据封装成一个ProducerRecord对象，里面包含了要发送的topic，具体在哪个分区，分区key，消息内容，timestamp时间戳，然后这个对象交给序列化器，变成自定义协议格式的数据

接着把数据交给partitioner分区器，对这个数据选择合适的分区，默认就轮询所有分区，或者根据key来hash路由到某个分区，这个topic的分区信息，都是在客户端会有缓存的，当然会提前跟broker去获取

接着这个数据会被发送到producer内部的一块缓冲区里

然后producer内部有一个Sender线程，会从缓冲区里提取消息封装成一个一个的batch，然后每个batch发送给分区的leader副本所在的broker

### 50.发送消息的缓冲区应该如何优化来提升发送的吞吐量？

buffer.memory：设置发送消息的缓冲区，默认值是33554432，就是32MB

如果发送消息出去的速度小于写入消息进去的速度，就会导致缓冲区写满，此时生产消息就会阻塞住，所以说这里就应该多做一些压测，尽可能保证说这块缓冲区不会被写满导致生产行为被阻塞住

compression.type，默认是none，不压缩，但是也可以使用lz4压缩，效率还是不错的，压缩之后可以减小数据量，提升吞吐量，但是会加大producer端的cpu开销

### 51.消息批量发送的核心参数batch.size是如何优化吞吐量？

batch.size，设置meigebatch的大小，如果batch太小，会导致频繁网络请求，吞吐量下降；如果batch太大，会导致一条消息需要等待很久才能被发送出去，而且会让内存缓冲区有很大压力，过多数据缓冲在内存里

默认值是：16384，就是16kb，也就是一个batch满了16kb就发送出去，一般在实际生产环境，这个batch的值可以增大一些来提升吞吐量，可以自己压测一下

还有一个参数，linger.ms，这个值默认是0，意思就是消息必须立即被发送，但是这是不对的，一般设置一个100毫秒之类的，这样的话就是说，这个消息被发送出去后进入一个batch，如果100毫秒内，这个batch满了16kb，自然就会发送出去

但是如果100毫秒内，batch没满，那么也必须把消息发送出去了，不能让消息的发送延迟时间太长，也避免给内存造成过大的一个压力

### 52.如何根据业务场景对消息大小以及请求超时进行合理的设置？

max.request.size：这个参数用来控制发送出去的消息的大小，默认是1048576字节，也就1mb，这个一般太小了，很多消息可能都会超过1mb的大小，所以需要自己优化调整，把他设置更大一些

你发送出去的一条大数据，超大的JSON串，超过1MB，就不让你发了

request.timeout.ms：这个就是说发送一个请求出去之后，他有一个超时的时间限制，默认是30秒，如果30秒都收不到响应，那么就会认为异常，会抛出一个TimeoutException来让我们进行处理

### 53.acks参数到底是干嘛的

acks参数，其实是控制发送出去的消息的持久化机制的

如果acks=0，那么producer根本不管写入broker的消息到底成功没有，发送一条消息出去，立马就可以发送下一条消息，这是吞吐量最高的方式，但是可能消息都丢失了，你也不知道的，但是说实话，你如果真是那种实时数据流分析的业务和场景，就是仅仅分析一些数据报表，丢几条数据影响不大的

会让你的发送吞吐量会提升很多，你发送弄一个batch出，不需要等待人家leader写成功，直接就可以发送下一个batch了，吞吐量很大的，哪怕是偶尔丢一点点数据，实时报表，折线图，饼图

acks=all，或者acks=-1：这个leader写入成功以后，必须等待其他ISR中的副本都写入成功，才可以返回响应说这条消息写入成功了，此时你会收到一个回调通知

min.insync.replicas = 2，ISR里必须有2个副本，一个leader和一个follower，最最起码的一个，不能只有一个leader存活，连一个follower都没有了

acks = -1，每次写成功一定是leader和follower都成功才可以算做成功，leader挂了，follower上是一定有这条数据，不会丢失

retries = Integer.MAX_VALUE，无限重试，如果上述两个条件不满足，写入一直失败，就会无限次重试，保证说数据必须成功的发送给两个副本，如果做不到，就不停的重试，除非是面向金融级的场景，面向企业大客户，或者是广告计费，跟钱的计算相关的场景下，才会通过严格配置保证数据绝对不丢失

acks=1：只要leader写入成功，就认为消息成功了，默认给这个其实就比较合适的，还是可能会导致数据丢失的，如果刚写入leader，leader就挂了，此时数据必然丢了，其他的follower没收到数据副本，变成leader

### 54.基于Consumer Group的消费者组的模型

每个consumer都要属于一个consumer.group，就是一个消费组，topic的一个分区只会分配给一个消费组下的一个consumer来处理，每个consumer可能会分配多个分区，也有可能某个consumer没有分配到任何分区

分区内的数据是保证顺序性的

group.id = “membership-consumer-group”

如果你希望实现一个广播的效果，你的每台机器都要消费到所有的数据，每台机器启动的时候，group.id可以是一个随机生成的UUID也可以，你只要让不同的机器的KafkaConsumer的group.id是不一样的

如果consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他，这个就是所谓的消费者rebalance的过程

### 55. 消费者offset的记录方式以及基于内部topic的提交模式

每个consumer内存里数据结构保存对每个topic的每个分区的消费offset，定期会提交offset，老版本是写入zk，但是那样高并发请求zk是不合理的架构设计，zk是做分布式系统的协调的，轻量级的元数据存储，不能负责高并发读写，作为数据存储

所以后来就是提交offset发送给内部topic：__consumer_offsets，提交过去的时候，key是group.id+topic+分区号，value就是当前offset的值，每隔一段时间，kafka内部会对这个topic进行compact

也就是每个group.id+topic+分区号就保留最新的那条数据即可

而且因为这个__consumer_offsets可能会接收高并发的请求，所以默认分区50个，这样如果你的kafka部署了一个大的集群，比如有50台机器，就可以用50台机器来抗offset提交的请求压力，就好很多

### 56.Kafka感知消费者故障是通过哪三个参数来实现的？

heartbeat.interval.ms：consumer心跳时间，必须得保持心跳才能知道consumer是否故障了，然后如果故障之后，就会通过心跳下发rebalance的指令给其他的consumer通知他们进行rebalance的操作

session.timeout.ms：kafka多长时间感知不到一个consumer就认为他故障了，默认是10秒

max.poll.interval.ms：如果在两次poll操作之间，超过了这个时间，那么就会认为这个consume处理能力太弱了，会被踢出消费组，分区分配给别人去消费，一遍来说结合你自己的业务处理的性能来设置就可以了

### 57.对消息进行消费时有哪几个参数需要注意以及设置呢？

fetch.max.bytes：获取一条消息最大的字节数，一般建议设置大一些

max.poll.records：一次poll返回消息的最大条数，默认是500条

connection.max.idle.ms：consumer跟broker的socket连接如果空闲超过了一定的时间，此时就会自动回收连接，但是下次消费就要重新建立socket连接，这个建议设置为-1，不要去回收

### 58.消费者offset相关的参数设置会对运行产生什么样的影响？

auto.offset.reset：这个参数的意思是，如果下次重启，发现要消费的offset不在分区的范围内，就会重头开始消费；但是如果正常情况下会接着上次的offset继续消费的

enable.auto.commit：这个就是开启自动提交唯一

### 59.Group Coordinator是什么以及主要负责什么？

生产者和消费者的基本原理，使用，核心参数，这一周的课，我们就是对kafka的生产者、消费者、协议，底层的原理做一些更加深入的理解

每个consumer group都会选择一个broker作为自己的coordinator，他是负责监控这个消费组里的各个消费者的心跳，以及判断是否宕机，然后开启rebalance的，那么这个如何选择呢？

就是根据group.id来进行选择，他有内部的一个选择机制，会给你挑选一个对应的Broker，总会把你的各个消费组均匀分配给各个Broker作为coordinator来进行管理的

他负责的事情只要就是rebalance，说白了你的consumer group中的每个consumer刚刚启动就会跟选举出来的这个consumer group对应的coordinator所在的broker进行通信，然后由coordinator分配分区给你的这个consumer来进行消费

coordinator会尽可能均匀的分配分区给各个consumer来消费

### 60. 为消费者选择Coordinator的算法是如何实现的？

首先对groupId进行hash，接着对**consumer_offsets的分区数量取模，默认是50，可以通过offsets.topic.num.partitions来设置，找到你的这个consumer group的offset要提交到**consumer_offsets的哪个分区

比如说：groupId，“membership-consumer-group” -> hash值（数字）-> 对50取模 -> 就知道这个consumer group下的所有的消费者提交offset的时候是往哪个分区去提交offset，大家可以找到__consumer_offsets的一个分区

__consumer_offset的分区的副本数量默认来说1，只有一个leader

然后对这个分区找到对应的leader所在的broker，这个broker就是这个consumer group的coordinator了，接着就会维护一个Socket连接跟这个Broker进行通信

### 61.Coordinator和Consume Leader如何协作制定分区方案？

每个consumer都发送JoinGroup请求到Coordinator，然后Coordinator从一个consumer group中选择一个consumer作为leader，把consumer group情况发送给这个leader，接着这个leader会负责制定分区方案，通过SyncGroup发给Coordinator

接着Coordinator就把分区方案下发给各个consumer，他们会从指定的分区的leader broker开始进行socket连接以及消费消息

### 62.rebalance的三种策略分别有哪些优劣势？

这里有三种rebalance的策略：range、round-robin、sticky

0~8

order-topic-0

order-topic-1

order-topic-2

range策略就是按照partiton的序号范围，比如partitioin02给一个consumer，partition35给一个consumer，partition6~8给一个consumer，默认就是这个策略；

round-robin策略，就是轮询分配，比如partiton0、3、6给一个consumer，partition1、4、7给一个consumer，partition2、5、8给一个consumer

但是上述的问题就在于说，可能在rebalance的时候会导致分区被频繁的重新分配，比如说挂了一个consumer，然后就会导致partition0-4分配给第一个consumer，partition5~8分配给第二个consumer

这样的话，原本是第二个consumer消费的partition3~4就给了第一个consumer，实际上来说未必就很好

最新的一个sticky策略，就是说尽可能保证在rebalance的时候，让原本属于这个consumer的分区还是属于他们，然后把多余的分区再均匀分配过去，这样尽可能维持原来的分区分配的策略

consumer1：0~2 + 6~7

consumer2：3~5 + 8

### 63.Consumer内部单线程处理一切事务的核心设计思想

其实就是在一个while循环里不停的去调用poll()方法，其实是我们自己的一个线程，就是我们自己的这个线程就是唯一的KafkaConsumer的工作线程，新版本的kafka api，简化，减少了线程数量

Consumer自己内部就一个后台线程，定时发送心跳给broker；但是其实负责进行拉取消息、缓存消息、在内存里更新offset、每隔一段时间提交offset、执行rebalance这些任务的就一个线程，其实就是我们调用Consumer.poll()方法的那个线程

就一个线程调用进去，会负责把所有的事情都干了

为什么叫做poll呢？因为就是你可以监听N多个Topic的消息，此时会跟集群里很多Kafka Broker维护一个Socket连接，然后每一次线程调用poll()，就会监听多个socket是否有消息传递过来

可能一个consumer会消费很多个partition，每个partition其实都是leader可能在不同的broker上，那么如果consumer要拉取多个partition的数据，就需要跟多个broker进行通信，维护socket

每个socket就会跟一个broker进行通信

每个Consumer内部会维护多个Socket，负责跟多个Broker进行通信，我们就一个工作线程每次调用poll()的时候，他其实会监听多个socket跟broker的通信，是否有新的数据可以去拉取

### 64.自动提交offset的语义以及导致消息丢失和重复消费的问题

默认是自动提交

auto.commit.inetrval.ms：5000，默认是5秒提交一次

如果你提交了消费到的offset之后，人家kafka broker就可以感知到了，比如你消费到了offset = 56987，下次你的consumer再次重启的时候，就会自动从kafka broker感知到说自己上一次消费到的offset = 56987

这次重启之后，就继续从offset = 56987这个位置继续往后去消费就可以了

他的语义是一旦消息给你poll到了之后，这些消息就认为处理完了，后续就可以提交了，所以这里有两种问题：

第一，消息丢失，如果你刚poll到消息，然后还没来得及处理，结果人家已经提交你的offset了，此时你如果consumer宕机，再次重启，数据丢失，因为上一次消费的那批数据其实你没处理，结果人家认为你处理了

poll到了一批数据，offset = 65510~65532，人家刚好就是到了时间提交了offset，offset = 65532这个地方已经提交给了kafka broker，接着你准备对这批数据进行消费，但是不巧的是，你刚要消费就直接宕机了

其实你消费到的数据是没处理的，但是消费offset已经提交给kafka了，下次你重启的时候，offset = 65533这个位置开始消费的，之前的一批数据就丢失了

第二，重复消费，如果你poll到消息，都处理完毕了，此时还没来得及提交offset，你的consumer就宕机了，再次重启会重新消费到这一批消息，再次处理一遍，那么就是有消息重复消费的问题

poll到了一批数据，offset = 65510~65532，你很快的处理完了，都写入数据库了，结果还没来得及提交offset就宕机了，上一次提交的offset = 65509，重启，他会再次让你消费offset = 65510~65532，一样的数据再次重复消费了一遍，写入数据库

重启kafka consumer，修改了他的代码

### 65.什么情况下会导致Consumer Group之间的重平衡？

其实最主要的就是consumer所在服务比如重启了，或者宕机了，或者新部署了，此时coordinator感知到了consumer group内的变化，就会触发rebalance的操作，或者是如果动态给topic增加了分区，也会触发rebalance

也或者是这个消费组订阅了更多的topic，也会触发rebalance进行新订阅topic的分区分配给各个consumer来处理

### 66.如何实现Consumer Group的状态机流转机制？

刚开始Consumer Group状态是：Empty

接着如果部分consumer发送了JoinGroup请求，会进入：PreparingRebalance的状态，等待一段时间其他成员加入，这个时间现在默认就是max.poll.interval.ms来指定的，所以这个时间间隔一般可以稍微大一点

接着如果所有成员都加入组了，就会进入AwaitingSync状态，这个时候就不能允许任何一个consumer提交offset了，因为马上要rebalance了，进行重新分配了，这个时候就会选择一个leader consumer，由他来制定分区方案

然后leader consumer制定好了分区方案，SyncGroup请求发送给coordinator，他再下发方案给所有的consumer成员，此时进入stable状态，都可以正常基于poll来消费了

所以如果说在stable状态下，有consumer进入组或者离开崩溃了，那么都会重新进入PreparingRebalance状态，重新看看当前组里有谁，如果剩下的组员都在，那么就进入AwaitingSync状态

leader consumer重新制定方案，然后再下发

### 67.rebalance分代机制可以有什么作用？

大家设想一个场景，在rebalance的时候，可能你本来消费了partition3的数据，结果有些数据消费了还没提交offset，结果此时rebalance，把partition3分配给了另外一个cnosumer了，此时你如果提交partition3的数据的offset，能行吗？

必然不行，所以每次rebalance会触发一次consumer group generation，分代，每次分代会加1，然后你提交上一个分代的offset是不行的，那个partiton可能已经不属于你了，大家全部按照新的partiton分配方案重新消费数据

consumer group generation = 1

consumer group generation = 2

### 68.Producer的缓冲区内部数据结构是什么样子的？

producer会创建一个accumulator缓冲区，他里面是一个HashMap数据结构，每个分区都会对应一个batch队列，因为你打包成出来的batch，那必须是这个batch都是发往同一个分区的，这样才能发送一个batch到这个分区的leader broker

{

“order-topic-0” -> [batch1, batch2],

“order-topic-1” -> [batch3]

}

batch.size

每个batch包含三个东西，一个是compressor，这是负责追加写入batch的组件；第二个是batch缓冲区，就是写入数据的地方；第三个是thunks，就是每个消息都有一个回调Callback匿名内部类的对象，对应batch里每个消息的回调函数

每次写入一条数据都对应一个Callback回调函数的

### 69.消息缓冲区满的时候是阻塞住还是抛出异常？

max.block.ms，其实就是说如果写缓冲区满了，此时是阻塞住一段时间，然后什么时候抛异常，默认是60000，也就是60秒

### 70.负责IO请求的Sender线程是如何基于缓冲区发送数据的？

Sender线程会不停的轮询缓冲区内的HashMap，看batch是否满了，或者是看linger.ms时间是不是到了，然后就得发送数据去，发送的时候会根据各个batch的目标leader broker来进行分组

因为可能不同的batch是对应不同的分区，但是不同的分区的Leader是在一个broker上的，<Node, List<ProducerBatch>>，接着会进一步封装为<Node, Request>，每个broker一次就是一个请求，但是这里可能包含很多个batch，接着就是将分组好的batch发送给leader broker，并且处理response，来反过来调用每个batch的callback函数

发送出去的Request会被放入InFlighRequests里面去保存，Map<NodeId, Deque<Request>>，这里就代表了发送出去的请求，但是还没接收到响应的

### 71.同时可以接受有几个发送到Broker的请求没收到响应？

Map<NodeId, Deque<Request>> => 给这个broker发送了哪些请求过去了？

max.in.flight.requests.per.connection：5

这个参数默认值是5，默认情况下，每个Broker最多只能有5个请求是发送出去但是还没接收到响应的，所以这种情况下是有可能导致顺序错乱的，大家一定要搞清楚这一点，先发送的请求可能后续要重发

### 72.盘点一下在Broker内部有哪些不同场景下会有延时任务？

比如说acks=-1，那么必须等待leader和follower都写完才能返回响应，而且有一个超时时间，默认是30秒，也就是request.timeout.ms，那么在写入一条数据到leader磁盘之后，就必须有一个延时任务，到期时间是30秒

延时任务会被放到DelayedOperationPurgatory，延时操作管理器中

这个延时任务如果因为所有follower都写入副本到本地磁盘了，那么就会被自动触发苏醒，那么就可以返回响应结果给客户端了，否则的话，这个延时任务自己指定了最多是30秒到期，如果到了超时时间都没等到，那么就直接超时返回异常了

还有一种是延时拉取任务，也就是说follower往leader拉取消息的时候，如果发现是空的，那么此时会创建一个延时拉取任务，然后延时时间到了之后，就会再次读取一次消息，如果过程中leader写入了消息那么也会自动执行这个拉取任务

### 73.Broker端

kafka全链路架构，broker端、生产端、消费端

生产集群规划和部署，监控和管理，生产服务，消费服务，各个端的参数应该如何来设置，我们的一个驱动的场景，电商场景驱动，数据量，10亿消息量的场景下，要存储多大量的数据，要支撑多高的并发

broker端机器数量和配置，生产端的机器数量和配置，消费端的机器数量和配置

（1）集群架构：Controller -> zk -> broker

（2）元数据管理：Controller，Topic -> Partition -> Leader & Follower -> Broker

（3）分布式架构：Topic逻辑数据集合 -> 物理上的多个Partition -> 分布在多台Broker

（4）broker端的多路复用模型的请求处理架构，自定义二进制协议

（5）磁盘存储，os cache，零拷贝，索引文件，日志文件，定期清理文件

（6）高可用架构：多副本冗余机制，Leader & Follower角色分配，leader -> follower的副本同步机制，LEO & HW的更新，ISR机制，Broker宕机后如何由Controller感知以及触发Leader重新选举

（7）负载均衡架构：所有partition物理的均匀分散在broker集群，leader partition也是均匀分散在broker集群

（8）延时处理机制：时间轮实现

### 74.生产端

（1）元数据拉取机制：Topic -> Partition -> Leader & Follower -> Broker

（2）分区机制，默认的分区策略，hash分区策略

（3）缓冲区：数据结构，每个分区有多个batch

（4）Sender线程 + batch批量发送，按照broker来聚合多个batch作为request

（5）同步和异步

（6）核心参数：batch.size、缓冲区大小、acks、超时时间

### 75.消费端的架构原理

（1）消费模型：consumer group，每个分区就给一个consumer，queue & PUB/SUB

（2）分区分配机制：coordinator -> __consumer_offsets，JoinGroup -> leader consumer -> 下发分区方案 -> 状态机，三种分区策略

（2）消费方式：poll()调用，单线程干所有的事情

（3）offset内存数据结构更新，定时提交offset，内部topic（__consumer_offsets）

（4）故障感知机制：核心参数，心跳参数、会话超时、消费过慢

（5）老版本api的high-level和low-level，简单的认知就可以了，新版本

### 76.Kafka集群部署

需求场景 -> 请求量 -> 数据量 -> 高峰并发量

kafka集群部署：多少台物理机、磁盘规划（容量和类型）、内存规划（os cache & jvm）、CPU、网卡，10亿请求的场景，需要一个多大规模的kafka集群

kafka运维管理：支撑业务（topic创建和维护、可视化平台）、集群监控（可视化平台、开源工具）、资源使用率 -> 集群扩容 / topic扩容、机器负载率 -> 负载均衡、异常监控（报错 / jvm fullgc）、运维管理（多集群同步、安全认证、版本升级）

### 77.生产服务部署

生产端机器部署：可能是你的java系统在生产消息，也可能是flume日志采集，canal数据库binlog采集，爬虫，如果你的机器就是每天1000万~2000万，数据往kafka里写入，没其他的数据库访问或者是别的线程和操作，4核8G的虚拟机要2台正好，高峰期的时候，CPU和内存的负载都到50%了，10亿 -> 40台4核8G虚拟机 -> 10台~20台左右16核32G的高配置虚拟机，也可以抗住每天生产10亿条数据的负载

### 78.消费服务部署

消费端机器部署：flink、spark streaming、自己写的java系统，4核8G虚拟机，单线程消费出来 -> 线程池来处理（60），每秒钟消费吞吐量大概可以到个几百，一两千~两三千，对应的是说，他需要对数据库进行很多增删改查的操作，16核32G，每秒消费和处理5000条数据，10多台机器，spark streaming他每秒要消费和处理几万条数据，那么需要多少的资源，cpu core、内存，集群是运行在多少台机器上的集群，spark streaming，集群规模有30，480核 + 640G，160核 + 320G

### 79.Kafka集群参数

kafka集群部署好，生产者代码写好 + 部署好，消费者代码写好 + 部署好，基本上已经可以run起来了，可以抗住每秒几万的并发请求，一天10亿的数据量流过kafka在处理，对其中的一些细节进行参数设置

数据保留几天，默认是7天，min.insync.replicas配合ISR + 数据不丢失，topic默认的分区数量，分区默认的副本数量，__consumer_offsets的分区数量和副本数量，processor线程数量，Handler线程池的大小，jvm参数的设置（堆大小 & G1垃圾回收器）

### 80.生产服务参数

生产端参数：缓冲区、batch、超时时间、acks

### 81.消费服务参数

消费端参数：offset提交、poll拉取消息、心跳、超时、拉取过慢

### 82.问题

Kafka全链路数据丢失风险分析

万一在producer缓冲区的时候，直接就生产服务就挂了，此时你写出去的数据不就丢失了吗？

acks = 1，那么只要leader写入成功了，就可以认为是成功，但是如果数据刚刚写入leader成功，客户端也认为成功了，但是follower还没同步数据，此时leader宕机了，必然会导致数据的丢失

acks = -1，leader + follower，leader和follower都写成功了，才算是成功，此时任何一个副本宕机，都不会导致数据的丢失；如果min.insync.replicas = 1，此时如果follower先宕机了，导致ISR里就一个leader了

此时acks = -1，ISR里的副本都写入成功，leader写入成功，就算成功了，结果leader也挂了，此时数据还是会丢失的

如果你消费到数据，poll到了数据，还没来得及处理，人家就自动提交offset了，此时kafka就认为你已经成功处理了这批数据，但是此时你consumer直接宕机了，数据丢失了，但是offset已经提交了

就是按照这个kafka课程，你如果上了生产，其实会经常发现丢数据的情况的，订单系统支付成功以后就会发送订单到kafka，会员系统需要来增加积分，如果丢失一些订单，会导致很多人支付以后，会员积分没有累加

为什么线上数据总是莫名其妙出现重复

数据重复这个问题其实也是挺正常，全链路都有可能会导致数据重复

生产端是有重试机制，发现你有一些网络抖动，在底层的网络环节，其实消息发送出去了，结果收到了一个NetworkException，此时会重发消息

消费端，重复的问题，很频繁，如果你是用自动offset提交，一定会每次重启consumer服务的时候，一定会重复消费消息，刚刚接收到一批消息，poll出来的，处理完毕了，自动提交offset还没来得及执行，你就重启了

会从上一次提交offset的地方重新拉取消息再次执行一遍，消息重复

kafka，同步订单，结果每天都发现有重复的订单同步的现象，支付了一个订单，应该累加积分是1000，结果订单重复同步了一次，导致人家积分增加了2000

MySQL binlog数据同步顺序为何不能出错

消息可能会乱序的一个问题

导致乱序的原因还是重试，<NodeId, Deque<Request>>，最多允许同时发送出去5个请求，忍受5个请求都发出去，但是没有收到响应，如果1和2两个请求都成功了，3这个请求失败了，4和5也成功了

对请求3重试，此时就算成功，他的数据也会排在4和5请求的后面了

消费者，一个consumer对应一个或者多个分区，分区内的消息一定是有顺序的，单线程消费各个分区的数据，所以单线程消费到的消息一定都是在分区内有顺序的，消费到的时候还是有顺序的

如果你把消息，每个消息提交一个任务给线程池异步处理，消息1~10分别分配给10个线程来并发的处理，但是此时可能先处理完消息10，然后处理完消息6，最后是处理完消息2，你的消息被处理的顺序完全不是按照顺序来的

比如你要从业务数据库，监听他的mysql binlog的变化，增删改，INSERT、UPDATE、DELETE相关的语句，对同一条数据的三个mysql bilog是：insert、update、delete。结果这个消息写入kafka是有顺序的

消费到了3条消息，提交给3个线程并发处理，他需要把这些操作同步到es里去，先在es里插入一条数据，然后更新，接着是删除，先执行delete，然后是update，接着是insert，最后反而es里有一条数据

线上消息队列百万消息积压怎么处理

比较致命的一个问题

（1）下游的消费者，比如说他是依赖于MySQL、NoSQL之类的系统，但是现在就是说MySQL他的性能突然出现了很大的问题，比如说一个表有几千万条数据，有个同学在高峰期做了一个DDL，导致对数据库的增删改查非常的慢，性能急剧下降几十倍，瞬间导致kafka里大量的积压了很多很多的消息，几百万条消息积压在里面

（2）依赖的ES突然宕机了，ES集群突然故障了，无法访问了，机房故障，机房的冷却系统坏了，温度过高，机器都故障了，下游的消费者就不工作了，积压几百万的消息

（3）你怎么来处理，应对

如何配合分布式事务方式实现消息事务支持

可靠消息最终一致性的事务方案，基于MQ来实现的，可靠消息服务，上游服务的本地事务成功了，必须保证消息投递出去到MQ上去，可以由MQ自己来支持和实现，RocketMQ就实现了一套机制

提供了事务相关的支持，数据库事务 + 消息，封装在一个事务里，数据库事务成功了，消息也必须投递成功，如果要跟分布式事务来整合的话，一般用的不是Kafka，RocketMQ来支持就最好

消息的过期时间（TTL）如何实现

有的时候其实是希望对消息设置一个过期时间，TTL，就是如果在kafka里积压了一段时间，TTL过期时间，还没被消费和处理，那么就直接过期掉他，就不要继续去处理了，可以跟百万消息积压的方案结合起来来使用

比如说现在kafka里积压了100万消息，TTL（30秒），此时如果下游的消费者恢复了，可以继续消费了，此时他发现这些消息都到TTL了，就可以直接丢弃掉这些消息，不要慢吞吞的来处理

你可以把TTL + 死信队列来实现一套生产方案，过期的消息直接放到另外一个独立的特殊的队列里去，那个队列专门是用来处理一些长时间过期的消息的，有专门的后台的一套系统和机制来处理

如何实现延迟队列的效果

举这么一个场景，你在生产消息的时候，如果说发现某个队列现在压力很大，或者是下游消费者压力很大，你是不是可以不要继续把消息拼命的往下游发送去执行，你可以不可以让消息进入特殊的延迟队列

你进入kafka之后，我指定你延迟30秒后才能被消费到，DelayQueue

不同的消息如何实现多优先级队列

消息写入kafka的时候，可以指定消息的优先级，就是优先级越高的数据应该越是先被消费出来，消息可以按照优先级来排序，优先级高的先被消费出来，你可能在方那哦数据过去的时候，有些数据是大客户的数据，优先级可以指定的高一些

针对链路故障的死信队列应该如何实现

如果你的某个消息此时发送到kafka之后，比如说他在正常的topic里无法被处理，不管怎么说，下游的消费者整个就挂掉了，此时这些消息可以进入一个队列，特殊的队列，死信队列，处理失败的消息，放入特殊的队列中，后续可以用特殊的机制来进行处理

假设我们给消息设置了TTL，然后消息进入了kafka topic，结果下游消费者故障，导致百万消息积压了，消费者一旦恢复，对这些过期的消息，直接就不处理，放入到一个死信队列里去

后面可以用一些特殊的机制对死信队列中的消息进行处理

消费服务故障场景下的重试队列

下游消费者整个的就是故障了，没办法继续消费了，此时可以结合TTL，死信队列，针对一些异常故障的场景来进行处理，下游消费者是正常的，结果呢，不知道为什么，在消费以及处理某一条消息的时候，就是失败了

比如说消费服务在对MySQL操作的时候，突然出现一个dead lock，抛异常，此时就可以把这个消息放入一个特殊的队列，叫做重试队列，后面可以重新消费一遍再次处理

下游数据计算错误时如何进行消息回溯

比如说消费者服务里的一些代码逻辑有bug，他对消息的处理是错误的，此时如果你发现这个问题之后，首先应该把错误的数据给删除掉，对那些数据，是不是要进行回溯，从kafka里重新读取某个offset~某个offset的一段数据，重新这个流程来一遍

就是重新对这些数据做一遍处理

不同的业务数据如何实现消息路由

topic里，可能也细分为不同的数据，同步订单

有的订单是正常情况下支付的，就是按照正常的流程来增加积分就可以了

但是有的订单是采用的是特殊的折扣优惠的场景，说明了是无积分累加的，此时对这种特殊的订单是否可以打一个标签

特殊订单和正常订单都在一个topic里，但是下游的消费服务获取到了消息，可以进行路由，也就是仅仅路由出来正常的订单给后续的逻辑来处理，特殊订单就是不予以处理就可以了，对消息打上不同的标签，消息路由

如何对消息流转链路进行消息轨迹监控

很多常见的一些应用，实时数据仓库，可能是从kafka里消费到数据，处理一下，写入到下一个kafka topic，再有人消费出来，再处理一下，再写入到下一个kafka topic，他是一个链路的场景

消息流转链路，面向B端的场景里，就是说你有一个链路，比如在哪个程序里消费到了一条消息，如何如何处理，写入到了下一个kafka topic去，又是哪一个程序获取到了这条消息，如何如何处理，再次写入到了下一个kafka topic

程序A -> Topic A -> 程序B -> Topic B -> 程序C -> Topic C

对消息质量是否正常进行监控

你需要对所有的消息去进行一个监控汇总，每天一共流转过去多少条消息，10亿条，其中链路完整流转完整的消息占比多少，链路不完整处理错误的占比多少，诸如此类，你需要对你每天综合性的统计一下你的消息处理的情况